<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>BewareMyPower的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="BewareMyPower的博客">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="BewareMyPower的博客">
<meta property="og:locale">
<meta property="article:author" content="XYZ, aka BewareMyPower">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="BewareMyPower的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">BewareMyPower的博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Kafka源码阅读06-Produce请求-1-写入本地日志" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/06/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB06-Produce%E8%AF%B7%E6%B1%82-1-%E5%86%99%E5%85%A5%E6%9C%AC%E5%9C%B0%E6%97%A5%E5%BF%97/" class="article-date">
  <time datetime="2019-11-06T10:43:19.000Z" itemprop="datePublished">2019-11-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/06/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB06-Produce%E8%AF%B7%E6%B1%82-1-%E5%86%99%E5%85%A5%E6%9C%AC%E5%9C%B0%E6%97%A5%E5%BF%97/">Kafka源码阅读06: Produce请求(1): 写入本地日志</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>前一节介绍了<code>Message</code>的格式及其实现，本来是继续阅读<code>MessageSet</code>，但后来发现在Kafka 0.11.0之后<code>Message</code>和<code>MessageSet</code>（消息集）发生了较大改变，详细参考<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-Messagesets">Kafka Protocol - Messagesets</a>，实际和生产者消费者交互的是<code>RecordBatch</code>而非<code>MessageSet</code>，原来的<code>MessageSet</code>只是简单地在若干<code>Message</code>之前加入offset字段和消息数量字段，现在的<code>RecordBatch</code>多了不少字段，比如<code>ProducerId</code>&#x2F;<code>ProducerEpoch</code>等。目前脱离了对API协议的实际处理过程去看这些数据结构的实现很难明白其实际意义，因此先阅读API请求。</p>
<p>本文就先阅读生产者的请求，其类型为<strong>Produce</strong>，对应<code>KafkaApis.handle()</code>中的下列分支：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">PRODUCE</span> =&gt; handleProduceRequest(request)</span><br></pre></td></tr></table></figure>

<h2 id="Produce协议"><a href="#Produce协议" class="headerlink" title="Produce协议"></a>Produce协议</h2><p>本节参考<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-ProduceAPI">Produce API</a>。Produce API使用通用的消息集格式，由于在发送时无法确定消息的offset，因此生产者可以随意填充该字段。</p>
<h3 id="请求格式"><a href="#请求格式" class="headerlink" title="请求格式"></a>请求格式</h3><p>Kafka 1.1使用的Produce请求是v2（实际上和v0及v1相同）：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ProduceRequest</span> =&gt; RequiredAcks Timeout [TopicName [Partition MessageSetSize MessageSet]]</span><br><span class="line">  <span class="attr">RequiredAcks</span> =&gt; int16</span><br><span class="line">  <span class="attr">Timeout</span> =&gt; int32</span><br><span class="line">  <span class="attr">Partition</span> =&gt; int32</span><br><span class="line">  <span class="attr">MessageSetSize</span> =&gt; int32</span><br></pre></td></tr></table></figure>

<p>这种描述格式是Kafka wiki的标准请求格式，<code>field =&gt; type</code>代表字段<code>field</code>是<code>type</code>类型，<code>field =&gt; [type]</code>代表<code>field</code>字段包含若干个<code>type</code>类型，也就是<code>[]</code>代表数组。</p>
<p>因此这里的消息请求的格式，可以看作包含1个2字节整型<code>RequiredAcks</code>，1个4字节整型<code>Timeout</code>，接下来是N个结构，每个结构都有1个<code>TopicName</code>，以及若干个子结构，每个子结构由1个<code>Partition</code>&#x2F;<code>MessageSetSize</code>&#x2F;<code>MessageSet</code>组成。</p>
<p>然后介绍官方对上述参数的定义：</p>
<ul>
<li><p><code>RequiredAcks</code>（下文简称acks）</p>
<p>指定服务端在响应请求之前应该受到多少确认（ack）:</p>
<ul>
<li>0：服务器不发送任何响应（这是服务器不回复请求的唯一情况）；</li>
<li>1：服务器在等待数据写入本地日志后才会发送响应；</li>
<li>-1：服务器在等待所有同步副本提交消息之后才发送响应。</li>
</ul>
<p>0和1很好理解，0就是生产者发完就不管了，1就是等待消息被写入本地日志之后再返回，这里涉及到<strong>同步副本（isr，in-sync replicas）</strong>这个概念。这里简单介绍下。用Kafka自带脚本创建topic时会指定<code>--replication-factor</code>，也就是消息日志的复制数量，此时会创建多个<strong>副本（replicas）</strong>来保存消息日志，在<strong>Leader</strong>写入消息日志到本地时，副本也会从Leader取得消息，写入到自己的消息日志。暂且不提其同步过程，可以认为目前存活且消息写入跟上Leader的副本就是同步副本。</p>
</li>
<li><p><code>Timeout</code></p>
<p>服务器可以等待<code>RequiredAcks</code>指定数量的确认所用的最长时间，单位：ms。这个参数并不是请求时间的确切限制，因为：</p>
<ol>
<li>网络传输延迟不包含在内；</li>
<li>计时器在处理请求时才开始，因此如果很多请求正在排队等待处理，那么这个等待时间不包含在内；</li>
<li>我们不会终止本地写操作，因此如果本地写入时间超时，将不予考虑，要获得这种类型的超时，客户端应该使用socket的超时。</li>
</ol>
</li>
<li><p><code>TopicName</code>：发布数据的目标主题；</p>
</li>
<li><p><code>Partition</code>：发布数据的目标分区；</p>
</li>
<li><p><code>MessageSetSize</code>：紧接着的<code>MessageSet</code>字段的字节数；</p>
</li>
<li><p><code>MessageSet</code>：消息集的标准格式，参考<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-Messagesets">Protocol - Messagesets</a>，注意Kafka 1.1使用的是v2版本的RecordBatch。</p>
</li>
</ul>
<h3 id="响应格式"><a href="#响应格式" class="headerlink" title="响应格式"></a>响应格式</h3><p>Kafka 1.1使用的是0.10.0后支持的v2版本，因此v0版本和0.9.0后支持的v1版本就先无视了。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ProduceResponse</span> =&gt; [TopicName [Partition ErrorCode <span class="literal">Off</span>set Timestamp]] ThrottleTime</span><br><span class="line">  <span class="attr">TopicName</span> =&gt; string</span><br><span class="line">  <span class="attr">Partition</span> =&gt; int32</span><br><span class="line">  <span class="attr">ErrorCode</span> =&gt; int16</span><br><span class="line">  <span class="attr">Offset</span> =&gt; int64</span><br><span class="line">  <span class="attr">Timestamp</span> =&gt; int64</span><br><span class="line">  <span class="attr">ThrottleTime</span> =&gt; int32</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>Topic</code>：响应对应的主题；</p>
</li>
<li><p><code>Partition</code>：响应对应的分区；</p>
</li>
<li><p><code>ErrorCode</code>：当前分区的错误码；</p>
<p>错误码是基于分区的，因为指定分区可能不可用或者无法在其他主机上维护而其他分区可能成功接受了Produce请求；</p>
</li>
<li><p><code>Offset</code>：赋值给消息集中第1条消息的offset；</p>
</li>
<li><p><code>Timestamp</code>：从UTC epoch至今的毫秒数，根据时间戳类型有不同的设定：</p>
<ul>
<li>时间戳类型为<code>LogAppendTime</code>，则为broker赋值给该消息集的时间戳，消息集内的所有内部消息都拥有同一个时间戳；</li>
<li>时间戳类型为<code>CreateTime</code>，则该字段总是-1。</li>
</ul>
<p>如果没有错误码返回，那么生产者可以认为Produce请求的时间戳已被broker接受。</p>
</li>
<li><p><code>ThrottleTime</code>：由于超过了quota（限额）而导致请求被限流的时间间隔，单位：毫秒。</p>
</li>
</ul>
<h2 id="handleProduceRequest"><a href="#handleProduceRequest" class="headerlink" title="handleProduceRequest"></a>handleProduceRequest</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleProduceRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">  <span class="comment">// 将 ByteBuffer 类型的请求解析成 ProduceRequest 类型</span></span><br><span class="line">  <span class="keyword">val</span> produceRequest = request.body[<span class="type">ProduceRequest</span>]</span><br><span class="line">  <span class="comment">// 取得请求的总字节数, 包含 header 和 body</span></span><br><span class="line">  <span class="keyword">val</span> numBytesAppended = request.header.toStruct.sizeOf + request.sizeOfBodyInBytes</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中<code>header</code>和<code>sizeofBodyInBytes</code>在<code>network.RequestChannel</code>类中定义</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Request</span>(<span class="params">/* ... */</span></span></span><br><span class="line"><span class="params"><span class="class">              val context: <span class="type">RequestContext</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">              /* ... */</span></span></span><br><span class="line"><span class="params"><span class="class">              @volatile private var buffer: <span class="type">ByteBuffer</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">              /* ... */</span>) <span class="keyword">extends</span> <span class="title">BaseRequest</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> bodyAndSize: <span class="type">RequestAndSize</span> = context.parseRequest(buffer)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">header</span></span>: <span class="type">RequestHeader</span> = context.header</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sizeOfBodyInBytes</span></span>: <span class="type">Int</span> = bodyAndSize.size</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>请求头之前在<a target="_blank" rel="noopener" href="https://bewaremypower.github.io/2019/09/23/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB03-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8BRequestChannel/">网络层阅读之RequestChannel</a>中提过，这里简单回顾下。<code>RequestHeader</code>为Java类，定义在<code>org.apache.kafka.common.requests</code>包中，包含以下字段</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ApiKeys apiKey;    <span class="comment">// 请求类型</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">short</span> apiVersion;  <span class="comment">// API版本</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String clientId;   <span class="comment">// 用户指定的客户端ID</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> correlationId; <span class="comment">// 用户提供的整数值，将和响应一起返回</span></span><br></pre></td></tr></table></figure>

<p>对应<a target="_blank" rel="noopener" href="https://kafka.apache.org/protocol.html#protocol_messages">消息协议</a>的Headers：</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Request Header <span class="operator">=</span>&gt; api_key api_version correlation_id client_id </span><br><span class="line">  api_key <span class="operator">=</span>&gt; INT16</span><br><span class="line">  api_version <span class="operator">=</span>&gt; INT16</span><br><span class="line">  correlation_id <span class="operator">=</span>&gt; INT32</span><br><span class="line">  client_id <span class="operator">=</span>&gt; NULLABLE_STRING</span><br></pre></td></tr></table></figure>

<p>在<code>Processor</code>处理客户端的请求字节序列时，会调用<code>RequestHeader.parse</code>方法构造请求头，然后和字节序列<code>buffer</code>一起发送给<code>RequestChannel</code>，<code>Handler</code>线程从中取得请求发送给<code>KafkaApis</code>处理。</p>
<p>后面是一些认证相关的代码，调用了<code>authorize</code>方法，由于不影响主要流程，所以暂且跳过，最后会进入以下分支：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> internalTopicsAllowed = request.header.clientId == <span class="type">AdminUtils</span>.<span class="type">AdminClientId</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// call the replica manager to append messages to the replicas</span></span><br><span class="line"><span class="comment">// 传入replicaManager来添加消息到副本上</span></span><br><span class="line">replicaManager.appendRecords(</span><br><span class="line">  timeout = produceRequest.timeout.toLong, <span class="comment">// Produce请求的timeout字段</span></span><br><span class="line">  requiredAcks = produceRequest.acks, <span class="comment">// Produce请求的acks字段</span></span><br><span class="line">  internalTopicsAllowed = internalTopicsAllowed, <span class="comment">// client id是否为__admin_client</span></span><br><span class="line">  isFromClient = <span class="literal">true</span>, <span class="comment">// 这里是处理客户端的Produce请求，所以为true</span></span><br><span class="line">  entriesPerPartition = authorizedRequestInfo, <span class="comment">// 通过认证的请求信息</span></span><br><span class="line">  responseCallback = sendResponseCallback, <span class="comment">// 发送响应的回调函数</span></span><br><span class="line">  processingStatsCallback = processingStatsCallback) <span class="comment">// 处理stats的回调函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// if the request is put into the purgatory, it will have a held reference and hence cannot be garbage collected;</span></span><br><span class="line"><span class="comment">// hence we clear its data here in order to let GC reclaim its memory since it is already appended to log</span></span><br><span class="line">produceRequest.clearPartitionRecords() <span class="comment">// 简单将Produce请求的partitionRecords置为null</span></span><br></pre></td></tr></table></figure>

<p>留意最后的操作，提到了<strong>purgatory</strong>这个概念：如果请求被放入purgatory，那么就会被（purgatory）持有引用，因此将其置为<code>null</code>防止被垃圾收集。也是之后涉及再看。</p>
<p>其中，<code>entriesPerPartition</code>是之前认证过程得到的信息：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> authorizedRequestInfo = mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>]()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从 produceRequest.partitionRecords 取得所有 TopicPartiton 和 MemoryRecords</span></span><br><span class="line"><span class="comment">// ***OrFail 方法仅仅检查 partitionRecords 字段是否为 null, 若为 null 则抛出异常</span></span><br><span class="line"><span class="keyword">for</span> ((topicPartition, memoryRecords) &lt;- produceRequest.partitionRecordsOrFail.asScala) &#123;</span><br><span class="line">  <span class="keyword">if</span> (!authorize(request.session, <span class="type">Write</span>, <span class="keyword">new</span> <span class="type">Resource</span>(<span class="type">Topic</span>, topicPartition.topic)))</span><br><span class="line">    unauthorizedTopicResponses += topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">TOPIC_AUTHORIZATION_FAILED</span>)</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (!metadataCache.contains(topicPartition.topic))</span><br><span class="line">    nonExistingTopicResponses += topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>)</span><br><span class="line">  <span class="keyword">else</span> <span class="comment">// 通过了 authorize 方法认证, 并且 metadataCache 包含该 topic</span></span><br><span class="line">    authorizedRequestInfo += (topicPartition -&gt; memoryRecords)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Idea调试"><a href="#Idea调试" class="headerlink" title="Idea调试"></a>Idea调试</h3><p>追根刨底去看<code>metadataCache</code>的构造和读取略麻烦，而且偏离了我们这篇文章的核心目的（了解Kafka怎么处理Produce请求）这里就利用Intellij Idea调试先看看里面到底是什么，也是阅读源码以来第1次调试。</p>
<p>首先<code>zkServer</code>命令启动Zookeeper服务端，然后在Idea中在定义<code>authorizedRequestInfo</code>处设断点，调试模式启动Kafka的core模块（即Kafka服务端），然后启动Kafka客户端，向<code>test</code>主题发送字符串<code>hello</code>，此时可以看到<code>metadataCache</code>的结构：</p>
<ul>
<li><code>brokerId</code> &#x3D; 0</li>
<li><code>cache</code> &#x3D; “HashMap” size &#x3D; 2<ul>
<li>0 &#x3D; …<ul>
<li>_1 &#x3D; “__consumer_offsets”<ul>
<li><code>value</code> &#x3D; {char[18]@5303}</li>
<li><code>hash</code> &#x3D; -970371369</li>
</ul>
</li>
<li>_2 &#x3D; “HashMap” size &#x3D; 50</li>
</ul>
</li>
<li>1 &#x3D; …<ul>
<li>_1 &#x3D; “test”<ul>
<li><code>value</code> &#x3D; {char[4]@5410}</li>
<li><code>hash</code> &#x3D; 3556498</li>
</ul>
</li>
<li>_2 &#x3D; “HashMap” size &#x3D; 1</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>可见其<code>cache</code>字段为<code>HashMap</code>类型，包含了所有的topic，一个是我们创建的<code>test</code>主题，一个是用来管理消费者提交的offset的<code>__consumer_offsets</code>。</p>
<p>因此保证了<code>authorizedRequestInfo</code>，也就是传入<code>appendRecords</code>的<code>entriesPerPartition</code>参数，它的topic都是目前现有的。</p>
<h2 id="ReplicaManager-appendRecords"><a href="#ReplicaManager-appendRecords" class="headerlink" title="ReplicaManager.appendRecords"></a>ReplicaManager.appendRecords</h2><blockquote>
<p>将消息添加到分区的首领副本，等待它们被复制到其他副本。无论是timeout或者acks的条件被满足，都会触发回调函数。如果回调函数本身已经在某个对象上被同步，那么传递这个对象来避免死锁。</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                  requiredAcks: <span class="type">Short</span>,</span><br><span class="line">                  internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                  isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                  entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                  responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span><br><span class="line">                  delayedProduceLock: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span>,</span><br><span class="line">                  processingStatsCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">RecordsProcessingStats</span>] =&gt; <span class="type">Unit</span> = _ =&gt; ()) &#123;</span><br><span class="line">  <span class="keyword">if</span> (isValidRequiredAcks(requiredAcks)) &#123; <span class="comment">// acks只能为-1，0，1</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// acks 在可接受的范围外, 则客户端肯定出错了, 仅仅返回错误, 而不用处理请求</span></span><br><span class="line">    <span class="comment">// 具体处理: 对每个 TopicPartition 对象, 构造相应的 PartitionResponse 对象组成新的 Map</span></span><br><span class="line">    <span class="comment">//  其中包含 error, baseOffset, logAppendTime, logStartOffset 等字段,</span></span><br><span class="line">    <span class="comment">//  除了 error 字段标明为 acks不合法 外, 其余字段都随意设置</span></span><br><span class="line">    <span class="keyword">val</span> responseStatus = entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, _) =&gt;</span><br><span class="line">      topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">INVALID_REQUIRED_ACKS</span>,</span><br><span class="line">        <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.firstOffset, <span class="type">RecordBatch</span>.<span class="type">NO_TIMESTAMP</span>, <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.logStartOffset)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 调用传入的回调 responseCallback 将返回值发送回去</span></span><br><span class="line">    responseCallback(responseStatus)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>先看else分支，可以得知，传入的<code>entriesPerPartition</code>为<code>TopicPartition</code>到<code>MemoryRecords</code>（消息）的<code>Map</code>而传入的<code>responseCallback</code>为发送响应给客户端的回调函数，响应类型也是<code>Map</code>，key也是<code>TopicPartition</code>，只不过value变成了<code>PartitionResponse</code>。也就是说，无论是请求还是响应，都是以分区为单位的，对于错误的响应，只有<code>error</code>字段起作用，而正确的响应是包含<code>baseOffset</code>，<code>logAppendTime</code>和<code>logStartOffset</code>等字段，前2个字段在上一篇<a target="_blank" rel="noopener" href="https://bewaremypower.github.io/2019/10/14/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB05-%E6%B6%88%E6%81%AF%E5%8D%8F%E8%AE%AE%E9%98%85%E8%AF%BB%E4%B9%8BMessage/">消息协议阅读</a>中简单提过，分别是消息日志中第1个offset以及发送的消息被写入消息日志的时间戳，现在具体阅读acks合法时的处理流程。</p>
<h3 id="time字段"><a href="#time字段" class="headerlink" title="time字段"></a>time字段</h3><p>首先取得毫秒级的<code>time</code>：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sTime = time.milliseconds</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中<code>time</code>为<code>replicaManager</code>的构造参数，而<code>replicaManager</code>也是<code>KafkaApis</code>的构造参数：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplicaManager</span>(<span class="params">val config: <span class="type">KafkaConfig</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     metrics: <span class="type">Metrics</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     time: <span class="type">Time</span>,</span></span></span><br><span class="line"><span class="params"><span class="class"></span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaApis</span>(<span class="params">val requestChannel: <span class="type">RequestChannel</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                val replicaManager: <span class="type">ReplicaManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class"></span></span></span><br></pre></td></tr></table></figure>

<p><code>KafkaApis</code>对象是在<code>KafkaServer</code>的<code>startup</code>方法中创建的，层层追溯如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apis = <span class="keyword">new</span> <span class="type">KafkaApis</span>(socketServer.requestChannel, replicaManager, <span class="comment">/* ... */</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">replicaManager = createReplicaManager(isShuttingDown)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">createReplicaManager</span></span>(isShuttingDown: <span class="type">AtomicBoolean</span>): <span class="type">ReplicaManager</span> =</span><br><span class="line">  <span class="keyword">new</span> <span class="type">ReplicaManager</span>(config, metrics, time, <span class="comment">/* ... */</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaServer</span>(<span class="params">val config: <span class="type">KafkaConfig</span>, time: <span class="type">Time</span> = <span class="type">Time</span>.<span class="type">SYSTEM</span>,</span></span></span><br><span class="line"><span class="params"><span class="class"></span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Time</span> &#123;</span><br><span class="line">    <span class="type">Time</span> <span class="variable">SYSTEM</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SystemTime</span>();</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可见<code>time</code>的<code>SystemTime</code>对象，作为计时器，包含以下常用方法：</p>
<ul>
<li><code>milliseconds</code>：取得毫秒级时间戳；</li>
<li><code>nanoseconds</code>：取得纳秒级时间戳；</li>
<li><code>sleep(long ms)</code>：当前线程休眠指定毫秒数。</li>
</ul>
<p>因此Kafka中一切用到计时器的类都会使用该对象，回过头看<code>appendRecords</code>代码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sTime = time.milliseconds <span class="comment">// 取得当前毫秒级时间戳</span></span><br><span class="line"><span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">  isFromClient = isFromClient, entriesPerPartition, requiredAcks)</span><br><span class="line"><span class="comment">// 调试信息: 再次取得时间戳, 相减得到 appendToLocalLog 的用时</span></span><br><span class="line">debug(<span class="string">&quot;Produce to local log in %d ms&quot;</span>.format(time.milliseconds - sTime))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>也就是说首先会调用<code>appendToLocalLog</code>方法</p>
<h3 id="appendToLocalLog"><a href="#appendToLocalLog" class="headerlink" title="appendToLocalLog"></a>appendToLocalLog</h3><blockquote>
<p>将消息添加到本地副本日志中</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendToLocalLog</span></span>(internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                             isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                             entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                             requiredAcks: <span class="type">Short</span>): <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">LogAppendResult</span>] = &#123;</span><br><span class="line">  trace(<span class="string">s&quot;Append [<span class="subst">$entriesPerPartition</span>] to local log&quot;</span>)</span><br><span class="line">  <span class="comment">// 遍历所有客户端请求写入的 topicPartition 以及对应消息 records</span></span><br><span class="line">  entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, records) =&gt;</span><br><span class="line">    <span class="comment">// 更新topicStats，暂时略去不看</span></span><br><span class="line">    brokerTopicStats.topicStats(topicPartition.topic).totalProduceRequestRate.mark()</span><br><span class="line">    brokerTopicStats.allTopicsStats.totalProduceRequestRate.mark()</span><br><span class="line">    <span class="keyword">if</span> (<span class="type">Topic</span>.isInternal(topicPartition.topic) &amp;&amp; !internalTopicsAllowed) &#123;</span><br><span class="line">      <span class="comment">// topic是内部主题: __consumer_offsets 或 __transaction_state, 且 internalTopicsAllowed 为 false</span></span><br><span class="line">      <span class="comment">//  (在 KafkaApis.handleProduceRequest 中, 只有请求的 clientId 为 AdminClientId 时才为 true)</span></span><br><span class="line">      <span class="comment">// 也就是如果不是 Admin 客户端, 尝试写入内部主题则会返回 写入不合法 的 LogAppendResult</span></span><br><span class="line">      (topicPartition, <span class="type">LogAppendResult</span>(</span><br><span class="line">        <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>,</span><br><span class="line">        <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">InvalidTopicException</span>(<span class="string">s&quot;Cannot append to internal topic <span class="subst">$&#123;topicPartition.topic&#125;</span>&quot;</span>))))</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// 非内部主题, 可以写入</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// 异常处理(略)，会将处理客户端请求的异常信息写入返回结果中</span></span><br><span class="line">        <span class="comment">// 注意，对于用于流程控制的Throwable异常，会单独处理，这里后面再看</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>首先是区分了消费主题是否为内部主题，比如<code>__consumer_offsets</code>，这种主题并不是存储生产&#x2F;消费的消息的，因此只允许Admin客户端读写。至于<code>brokerTopicStats</code>也是度量指标相关的，暂且略过。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从内部的 allPartitions 中找到 topicPartition, PS: allPartitions 是从本地消息日志中读取的</span></span><br><span class="line"><span class="keyword">val</span> partitionOpt = getPartition(topicPartition)</span><br><span class="line"><span class="keyword">val</span> info = partitionOpt <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Some</span>(partition) =&gt;</span><br><span class="line">    <span class="comment">// 找到的是 OfflinePartition (当前broker不在分区的ISR列表上) 则会(通过异常处理)返回错误信息</span></span><br><span class="line">    <span class="comment">// https://issues.apache.org/jira/browse/KAFKA-6796 在 Kafka 2.0 中对这种行为进行了修复</span></span><br><span class="line">    <span class="comment">// 比如在分区重分配期间, 客户的Produce请求在本地副本被删除后到达, 此时不应该返回分区不存在的错误</span></span><br><span class="line">    <span class="comment">// 因此2.0中抛出的是 NotLeaderForPartitionException, 会强制让客户端更新元数据来找到新的分区位置</span></span><br><span class="line">    <span class="keyword">if</span> (partition eq <span class="type">ReplicaManager</span>.<span class="type">OfflinePartition</span>)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaStorageException</span>(<span class="string">s&quot;Partition <span class="subst">$topicPartition</span> is in an offline log directory on broker <span class="subst">$localBrokerId</span>&quot;</span>)</span><br><span class="line">    <span class="comment">// 添加记录到leader副本上</span></span><br><span class="line">    partition.appendRecordsToLeader(records, isFromClient, requiredAcks)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 若找不到目标 topicPartition, 则代表生产者向一个未知的分区生产消息, 返回表示分区不存在的结果</span></span><br><span class="line">  <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnknownTopicOrPartitionException</span>(<span class="string">&quot;Partition %s doesn&#x27;t exist on %d&quot;</span></span><br><span class="line">    .format(topicPartition, localBrokerId))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 略去更新brokerTopicStats的代码</span></span><br><span class="line"></span><br><span class="line">(topicPartition, <span class="type">LogAppendResult</span>(info))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>处理了2种错误：分区是离线的（Offline）和分区是未知，而对于已知分区，则是将<code>appendRecordsToLeader</code>方法返回的<code>info</code>来构造该分区对应的<code>LogAppendResult</code>作为返回结果。</p>
<p>这里通过<code>getPartition</code>返回的<code>partition</code>类型是<code>Partition</code>，位于<code>cluster</code>包中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Partition</span>(<span class="params">val topic: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                val partitionId: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                time: <span class="type">Time</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                replicaManager: <span class="type">ReplicaManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                val isOffline: <span class="type">Boolean</span> = false</span>)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>除了主题名<code>topic</code>和分区号<code>partitionId</code>外，还会引用<code>replicaManager</code>用于将信息写入副本中。还通过<code>isOffline</code>来区分分区是否在副本broker上。</p>
<h3 id="Partition-appendRecordsToLeader"><a href="#Partition-appendRecordsToLeader" class="headerlink" title="Partition.appendRecordsToLeader"></a>Partition.appendRecordsToLeader</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecordsToLeader</span></span>(records: <span class="type">MemoryRecords</span>, isFromClient: <span class="type">Boolean</span>, requiredAcks: <span class="type">Int</span> = <span class="number">0</span>): <span class="type">LogAppendInfo</span> = &#123;</span><br><span class="line">  <span class="comment">// 用读锁保护, 可以多线程添加记录到 leader副本 上, 但是如果ISR更新过程会获取写锁, 此时要等待ISR更新完毕</span></span><br><span class="line">  <span class="keyword">val</span> (info, leaderHWIncremented) = inReadLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">    <span class="comment">// 若leader副本的id为本地的broker id, 则返回对应的 Replica对象</span></span><br><span class="line">    leaderReplicaIfLocal <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(leaderReplica) =&gt; <span class="comment">// leader副本</span></span><br><span class="line">        <span class="keyword">val</span> log = leaderReplica.log.get <span class="comment">// append-only的Log对象</span></span><br><span class="line">        <span class="keyword">val</span> minIsr = log.config.minInSyncReplicas <span class="comment">// min.insync.replicas 配置</span></span><br><span class="line">        <span class="keyword">val</span> inSyncSize = inSyncReplicas.size <span class="comment">// ISR数量</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// acks为-1时, 客户端会等待所有ISR确认收到消息时才返回, 此时配置 min.insync.replicas</span></span><br><span class="line">        <span class="comment">// 指定了这个ISR的最小数量, 因此ISR数量不够时会抛出ISR副本太少的异常</span></span><br><span class="line">        <span class="keyword">if</span> (inSyncSize &lt; minIsr &amp;&amp; requiredAcks == <span class="number">-1</span>) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotEnoughReplicasException</span>(<span class="string">&quot;Number of insync replicas for partition %s is [%d], below required minimum [%d]&quot;</span></span><br><span class="line">            .format(topicPartition, inSyncSize, minIsr))</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将消息集写入日志, 分配 offsets 和 分区leader的epoch</span></span><br><span class="line">        <span class="keyword">val</span> info = log.appendAsLeader(records, leaderEpoch = <span class="keyword">this</span>.leaderEpoch, isFromClient)</span><br><span class="line">        <span class="comment">// probably unblock some follower fetch requests since log end offset has been updated</span></span><br><span class="line">        <span class="comment">// 因为 LEO(log end offset) 已经更新了, 所以某些 follower 的 fetch请求可能解除阻塞了, 于是</span></span><br><span class="line">        <span class="comment">// replicaManager.delayedFetchPurgatory 尝试完成该分区的延迟的fetch请求, 因为 LEO(log end offset)已经跟新</span></span><br><span class="line">        replicaManager.tryCompleteDelayedFetch(<span class="type">TopicPartitionOperationKey</span>(<span class="keyword">this</span>.topic, <span class="keyword">this</span>.partitionId))</span><br><span class="line">        <span class="comment">// 因为 ISR 可能只剩1个, 因此可能需要增加HW (high watermark)</span></span><br><span class="line">        (info, maybeIncrementLeaderHW(leaderReplica))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">// 非leader副本</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotLeaderForPartitionException</span>(<span class="string">&quot;Leader not local for partition %s on broker %d&quot;</span></span><br><span class="line">          .format(topicPartition, localBrokerId))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// some delayed operations may be unblocked after HW changed</span></span><br><span class="line">  <span class="comment">// 一些延迟操作可能因为 HW 的改变而解除阻塞, 因此尝试完成这些延迟请求</span></span><br><span class="line">  <span class="keyword">if</span> (leaderHWIncremented)</span><br><span class="line">    tryCompleteDelayedRequests()</span><br><span class="line"></span><br><span class="line">  info <span class="comment">// log.AppendAsLeader返回的结果</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里有几个方法暂时没看细节，将其列出（对于<code>server</code>包之外的标注包名），之后有可能的话单独阅读：</p>
<ul>
<li><code>log.Log.appendAsLeader</code>：将消息集，分配的offset，leader副本的epoch写入本地消息日志；</li>
<li><code>DelayedOperation.checkAndComplete(key: Any)</code>：检查某些**延迟操作(delayed operations)**用给定的key能否完成，若能则完成；</li>
<li><code>cluster.Partition.maybeIncrementLeaderHW</code>：检查并且可能增加分区的HW，仅当分区ISR改变或者任意副本的LEO改变时才更新。</li>
</ul>
<p>由于本小节涉及到分区的操作，来回顾一些基本概念，每个分区都有多个broker来保存，实现消息的冗余备份，这些broker称为该分区的<strong>副本（replica）</strong>。对每个分区，存在唯一的<strong>leader副本</strong>（通过选举产生），与客户端进行直接读写，而其他副本为<strong>follower</strong>，不断地从leader复制最新的消息。与leader保持同步的follower被称为**ISR(in-sync replica)**，而某些follower会因为某些原因复制速度较慢或者和leader断开连接（通过某种规则判断），此时会从ISR中移除，直到重新跟上进度会重新加入ISR。</p>
<p><strong>HW(high watermark, 高水位)<strong>即最新</strong>已提交的（committed）</strong>消息的offset，即所有ISR的分区日志上都写入了该消息，消费者无法拉取比HW更大的offset，从而保证leader一旦不可用，消费者之前消费的消息存在于任意ISR的消息日志中。</p>
<p>**LEO(log end offset)**是所有副本都会维护的offset，即当前副本最后一个消息的offset+1，也就是如果有新的消息写入，那么它的offset即之前的LEO，而副本将消息写入消息日志后，LEO会递增。</p>
<p>至于<strong>epoch</strong>这个概念是Kafka 0.11引入的，暂时还不清楚具体功能，之后再提。</p>
<h2 id="appendToLocalLog总结"><a href="#appendToLocalLog总结" class="headerlink" title="appendToLocalLog总结"></a>appendToLocalLog总结</h2><p>在之前将客户端发送的请求解析成了<strong>分区</strong>到<strong>消息集</strong>的映射，而返回值是<strong>分区</strong>到<code>LogAppendResult</code>的映射，因此只对遍历整个<code>Map</code>，对每对分区消息集进行处理得到<code>LogAppendResult</code>即可：</p>
<ol>
<li>对<code>__consumer_offsets</code>这样的内部主题，验证请求头的client id是否为管理员（admin）的id，否则返回<em>Cannot append to internal topic</em>的错误；</li>
<li>在<code>ReplicaManager</code>维护的当前broker上的分区列表中找到对应的分区；</li>
<li>若查找失败则返回*Partition … doesn’t exist on …*的错误；</li>
<li>若分区不可用，则返回*Partition … is in an offline log directory on broker …*的错误；</li>
<li>若当前broker不是分区的leader，则返回*Leader not local for partition … on broker …*的错误；</li>
<li>若acks字段为-1，且ISR数量小于<code>min.insync.replicas</code>配置的数量，则返回<em>Number of insync replicas for partition … is … below required minimum</em>的错误；</li>
<li>将消息集写入本地日志，并给当前分区分配offsets和leader epoch；</li>
<li>处理延后处理的Fetch请求，可能更新HW；</li>
<li>若更新HW，则处理延后处理的请求。</li>
</ol>
<p>前面的流程都是一些合法性判断，主要是7~9这几步，待深入阅读的内容：</p>
<ol>
<li>对指定分区，写入日志后如何分配offsets和leader epoch？</li>
<li>延后处理是怎么实现的？</li>
</ol>
<p>关于延后处理，主要是<code>ReplicaManager</code>的以下字段</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> delayedProducePurgatory: <span class="type">DelayedOperationPurgatory</span>[<span class="type">DelayedProduce</span>],</span><br><span class="line"><span class="keyword">val</span> delayedFetchPurgatory: <span class="type">DelayedOperationPurgatory</span>[<span class="type">DelayedFetch</span>],</span><br><span class="line"><span class="keyword">val</span> delayedDeleteRecordsPurgatory: <span class="type">DelayedOperationPurgatory</span>[<span class="type">DelayedDeleteRecords</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>都是<code>Purgatory</code>（炼狱），在辅助构造器中进行默认构造：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DelayedOperationPurgatory</span>[<span class="type">DelayedProduce</span>](</span><br><span class="line">  purgatoryName = <span class="string">&quot;Produce&quot;</span>, brokerId = config.brokerId,</span><br><span class="line">  purgeInterval = config.producerPurgatoryPurgeIntervalRequests),</span><br><span class="line"><span class="type">DelayedOperationPurgatory</span>[<span class="type">DelayedFetch</span>](</span><br><span class="line">  purgatoryName = <span class="string">&quot;Fetch&quot;</span>, brokerId = config.brokerId,</span><br><span class="line">  purgeInterval = config.fetchPurgatoryPurgeIntervalRequests),</span><br><span class="line"><span class="type">DelayedOperationPurgatory</span>[<span class="type">DelayedDeleteRecords</span>](</span><br><span class="line">  purgatoryName = <span class="string">&quot;DeleteRecords&quot;</span>, brokerId = config.brokerId,</span><br><span class="line">  purgeInterval = config.deleteRecordsPurgatoryPurgeIntervalRequests),</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>都是泛型类<code>DelayedOperationPurgatory</code>，类型参数不同。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇开始阅读Produce请求的处理，首先从官网阅读了Kafka 1.1对应的Produce请求和响应协议，然后阅读<code>KafkaApis</code>类的处理方法<code>handleProduceRequest</code>。</p>
<p>跳过了加密&#x2F;认证的部分，实际上是由<code>ReplicaManager</code>来处理，调用<code>appendRecords</code>方法，接受了客户端Produce请求中的acks和timeout两个关键字段。</p>
<p>首先验证acks是否合法（-1, 0 or 1），对不合法acks发送<code>INVALID_REQUIRED_ACKS</code>响应。</p>
<p>然后调用<code>appendToLocalLog</code>方法，也是本篇主要阅读的部分。</p>
<p>之后的处理，以及<code>appendRecords</code>接收的回调函数（比如如何发送响应）的实现，日志的写入，分区的offsets和leader epoch的更新，以及如何延迟处理将在之后进行阅读。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/11/06/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB06-Produce%E8%AF%B7%E6%B1%82-1-%E5%86%99%E5%85%A5%E6%9C%AC%E5%9C%B0%E6%97%A5%E5%BF%97/" data-id="cl1qn407w00314c1u3xquazbr" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Kafka源码阅读05-消息协议阅读之Message" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/10/14/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB05-%E6%B6%88%E6%81%AF%E5%8D%8F%E8%AE%AE%E9%98%85%E8%AF%BB%E4%B9%8BMessage/" class="article-date">
  <time datetime="2019-10-14T04:42:36.000Z" itemprop="datePublished">2019-10-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/14/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB05-%E6%B6%88%E6%81%AF%E5%8D%8F%E8%AE%AE%E9%98%85%E8%AF%BB%E4%B9%8BMessage/">Kafka源码阅读05-消息协议阅读之Message</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>之前阅读了网络层和API层，在阅读API层支持的Kafka协议之前，首先得明确Kafka的消息概念。Kafka服务器被称为<strong>broker</strong>，与其交互的是客户端，分为<strong>生产者（Producer）</strong>和<strong>消费者（Consumer）</strong>，客户端与服务端通过消息进行交互。</p>
<p>Kafka使用日志文件（下文称为<strong>消息日志</strong>）来保存消息，通过<code>log.dirs</code>配置指定日志文件的存放目录。注意这里的日志文件不同于Kafka本身的日志（记录运行时的一些信息）。而对于每个分区，都会在<code>log.dirs</code>下创建一个子目录来存放消息日志，其命名为<code>&lt;topic&gt;-&lt;partition&gt;</code>，在该目录下会有像这样的文件：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls</span><br><span class="line"><span class="number">00000000000000000020.</span><span class="keyword">index</span>  <span class="number">00000000000000000020.</span><span class="keyword">log</span>  <span class="number">00000000000000000020.</span>timeindex  leader-epoch-<span class="keyword">checkpoint</span></span><br></pre></td></tr></table></figure>

<p>同一分区的不同消息是通过offset来唯一标识的，注意它并不是消息在消息日志中实际存储位置的偏移量，而是类似id一样的概念，从0开始递增，表示分区内第offset条消息。</p>
<p>消息日志的命名规则是<code>[baseOffset].log</code>，比如这里的20就是该日志的第<strong>baseOffset</strong>，即消息日志中的第1条消息的offset。相应地，有同名的<code>.index</code>文件，为消息建立了索引方便查询消息，但并没有对每条消息都建立了索引。</p>
<p>因此首先看看Kafka的消息实现，即<code>message</code>包，本文主要讲<code>Message</code>类。</p>
<h2 id="消息格式"><a href="#消息格式" class="headerlink" title="消息格式"></a>消息格式</h2><p><code>Message</code>类的注释给出了格式说明，如下图所示：</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">字节数 |<span class="string">   4   </span>|<span class="string">   1   </span>|<span class="string">     1     </span>|<span class="string">     8     </span>|<span class="string">   4    </span>|<span class="string">  K  </span>|<span class="string">  4  </span>|<span class="string">    V    </span>|</span><br><span class="line">字段名 |<span class="string"> CRC32 </span>|<span class="string"> magic </span>|<span class="string"> attribute </span>|<span class="string"> timestamp </span>|<span class="string"> keylen </span>|<span class="string"> key </span>|<span class="string"> len </span>|<span class="string"> payload </span>|</span><br><span class="line">                         /     \</span><br><span class="line">             |<span class="string"> 7 </span>|<span class="string"> 6 </span>|<span class="string"> 5 </span>|<span class="string"> 4 </span>|<span class="string"> 3 </span>|<span class="string"> 2 </span>|<span class="string"> 1 </span>|<span class="string"> 0 </span>|</span><br><span class="line">                0~2: 压缩类型；3: 时间戳类型 </span><br></pre></td></tr></table></figure>

<p>补充说明：</p>
<ul>
<li><code>magic</code>代表消息格式，其值为0代表v0，为1代表v1；</li>
<li>v0版本的消息使用绝对offset，且不包含<code>timestamp</code>字段，<code>attribute</code>第3位不使用；</li>
<li>v1版本的消息使用相对offset，且包含<code>timestamp</code>字段，<code>attribute</code>第3位为时间戳类型；</li>
<li><code>K</code>是字段<code>keylen</code>的值，<code>V</code>是字段<code>len</code>的值。</li>
</ul>
<h2 id="外部消息和内部消息"><a href="#外部消息和内部消息" class="headerlink" title="外部消息和内部消息"></a>外部消息和内部消息</h2><p>看看消息的主构造器</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Message</span>(<span class="params">val buffer: <span class="type">ByteBuffer</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">              private val wrapperMessageTimestamp: <span class="type">Option</span>[<span class="type">Long</span>] = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">              private val wrapperMessageTimestampType: <span class="type">Option</span>[<span class="type">TimestampType</span>] = <span class="type">None</span></span>)</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>buffer</code>：消息的字节缓冲区；</li>
<li><code>wrapperMessageTimestamp</code>：外部消息的时间戳；</li>
<li><code>wrapperMessageTimestampType</code>：外部消息的时间戳类型；</li>
</ul>
<p>这里的<code>wrapperMessage</code>指的是外部消息，因为Kafka会对多个消息一起进行压缩提高压缩率，所以将N个消息压缩后的消息称为<strong>外部消息</strong>，而这N个消息则称为<strong>内部消息</strong>。</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">外部消息offset |<span class="string"> 100 </span>|<span class="string">     105    </span>|<span class="string"> 106 </span>|<span class="string"> 107 </span>|<span class="string"> ...</span></span><br><span class="line"><span class="string">                         /   \ </span></span><br><span class="line"><span class="string">内部消息offset    </span>|<span class="string"> 0 </span>|<span class="string"> 1 </span>|<span class="string"> 2 </span>|<span class="string"> 3 </span>|<span class="string"> 4 </span>|</span><br></pre></td></tr></table></figure>

<p>这样做是因为生产者对一批消息压缩时，它是不知道消息的offset时（因为offset是由broker指定的），所以就简单地将offset字段从0开始依次递增来设置。</p>
<p>而broker在收到这批消息时，它知道前1个消息的offset（比如在这里就是100），也知道生产者发送过来的这批消息的数量（5），那么下一个外部消息的offset就被设置为100+5&#x3D;105。</p>
<p>消费者取得的是外部消息，当消费者通过解压得到每个消息时，可以用外部offset和内部offset计算出内部消息的绝对offset（101~105）。</p>
<h2 id="getter方法"><a href="#getter方法" class="headerlink" title="getter方法"></a>getter方法</h2><p>对这种基于字节的消息协议的实现很简单，利用<code>ByteBuffer</code>对象存储字节序列，然后用伴生对象的常量来指定某个字段的长度（length）和偏移量（offset），从而通过其字节区间[offset, offset + length)访问该字段。</p>
<p>再次注意：这里提到的偏移量指的是字节在缓冲区中的位置，不同于消息的offset。</p>
<p>在<code>Message</code>伴生对象中定义一系列常量来记录各字段的offset和length：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Message</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> <span class="type">CrcOffset</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">CrcLength</span> = <span class="number">4</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">MagicOffset</span> = <span class="type">CrcOffset</span> + <span class="type">CrcLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">MagicLength</span> = <span class="number">1</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">AttributesOffset</span> = <span class="type">MagicOffset</span> + <span class="type">MagicLength</span></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后对于<code>crc</code>和<code>magic</code>这种整型字段的getter方法直接调用<code>ByteBuffer.getInt(index)</code>方法即可（注意不能用<code>getInt()</code>方法，因为它是从内部position开始读的）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checksum</span></span>: <span class="type">Long</span> = <span class="type">ByteUtils</span>.readUnsignedInt(buffer, <span class="type">CrcOffset</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">magic</span></span>: <span class="type">Byte</span> = buffer.get(<span class="type">MagicOffset</span>)</span><br></pre></td></tr></table></figure>

<p>对于多字节的字段<code>crc</code>，使用的是Java类<code>ByteUtils</code>的相关方法，将多个字节转换成目标整型，实际上还是首先调用<code>ByteBuffer</code>的<code>getXXX(index)</code>方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">long</span> <span class="title function_">readUnsignedInt</span><span class="params">(ByteBuffer buffer, <span class="type">int</span> index)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> buffer.getInt(index) &amp; <span class="number">0xffffffffL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对于<code>key</code>和<code>payload</code>这种运行期才确定长度的字段，其编码方式是用户自定义的，所以只需要返回一个<code>ByteBuffer</code>即可，具体编解码应该在客户端进行：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">payload</span></span>: <span class="type">ByteBuffer</span> = sliceDelimited(payloadSizeOffset)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">key</span></span>: <span class="type">ByteBuffer</span> = sliceDelimited(keySizeOffset)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 由于key字段长度是动态的，所以无法在object中定义payloadSizeOffset常量，而需要在类中取得key的长度后计算而出</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">payloadSizeOffset</span> </span>= &#123;</span><br><span class="line">  <span class="keyword">if</span> (magic == <span class="type">MagicValue_V0</span>) <span class="type">KeyOffset_V0</span> + max(<span class="number">0</span>, keySize)</span><br><span class="line">  <span class="keyword">else</span> <span class="type">KeyOffset_V1</span> + max(<span class="number">0</span>, keySize)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sliceDelimited</span></span>(start: <span class="type">Int</span>): <span class="type">ByteBuffer</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> size = buffer.getInt(start) <span class="comment">// 取得前4个字节表示的长度</span></span><br><span class="line">  <span class="keyword">if</span>(size &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="literal">null</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 拷贝一份，防止影响buffer的position，注意这里的拷贝并没拷贝内部的字节序列</span></span><br><span class="line">    <span class="keyword">var</span> b = buffer.duplicate()</span><br><span class="line">    <span class="comment">// 跳过表示长度的4个字节，回顾协议，key和payload之前都有4个字节表示长度</span></span><br><span class="line">    b.position(start + <span class="number">4</span>)</span><br><span class="line">    <span class="comment">// 取得buffer从position开始的子序列，并重置长度和position</span></span><br><span class="line">    <span class="comment">// 之后b就是指向key或payload字段并且长度合适的ByteBuffer了</span></span><br><span class="line">    b = b.slice()</span><br><span class="line">    b.limit(size)</span><br><span class="line">    b.rewind</span><br><span class="line">    b</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h2><p>Kafka的消息格式在0.10.0的一个重要变化是加入了时间戳字段，见<a target="_blank" rel="noopener" href="https://kafka.apache.org/11/documentation.html#upgrade_10_performance_impact">upgrade to 0.10.0.0</a>，为了保持旧消息的兼容，才有了<code>magic</code>标识是否使用时间戳，并且支持对API版本的请求：<a target="_blank" rel="noopener" href="https://kafka.apache.org/protocol.html#api_versions">Retrieving Supported API versions</a>。值得一看的是<code>timestamp</code>的getter：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timestamp</span></span>: <span class="type">Long</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (magic == <span class="type">MagicValue_V0</span>) <span class="comment">// v0版本的消息不使用时间戳</span></span><br><span class="line">    <span class="type">Message</span>.<span class="type">NoTimestamp</span></span><br><span class="line">  <span class="comment">// 对v1版本的消息，有以下3种Case：</span></span><br><span class="line">  <span class="comment">// 1. 外部消息的时间戳及其类型都为None；</span></span><br><span class="line">  <span class="comment">// 2. 外部消息的时间戳类型为LogAppendTime且时间戳非None；</span></span><br><span class="line">  <span class="comment">// 3. 外部消息的时间戳类型为CreateTime且时间戳非None。</span></span><br><span class="line">  <span class="comment">// Case 2</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (wrapperMessageTimestampType.exists(_ == <span class="type">TimestampType</span>.<span class="type">LOG_APPEND_TIME</span>) &amp;&amp; wrapperMessageTimestamp.isDefined)</span><br><span class="line">    wrapperMessageTimestamp.get</span><br><span class="line">  <span class="keyword">else</span> <span class="comment">// Case 1, 3</span></span><br><span class="line">    buffer.getLong(<span class="type">Message</span>.<span class="type">TimestampOffset</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>后2种Case都代表当前消息是内部消息，也就是说和其他内部消息一起被压缩了，只有时间戳类型为<code>LogAppendTime</code>时才使用外部消息的时间戳。</p>
<h2 id="辅助构造器"><a href="#辅助构造器" class="headerlink" title="辅助构造器"></a>辅助构造器</h2><p>一般不会直接传入<code>ByteBuffer</code>，而是传入消息协议的各个字段来构造，也就是辅助构造器</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(bytes: <span class="type">Array</span>[<span class="type">Byte</span>], </span><br><span class="line">         key: <span class="type">Array</span>[<span class="type">Byte</span>],</span><br><span class="line">         timestamp: <span class="type">Long</span>,</span><br><span class="line">         timestampType: <span class="type">TimestampType</span>,</span><br><span class="line">         codec: <span class="type">CompressionCodec</span>, </span><br><span class="line">         payloadOffset: <span class="type">Int</span>, </span><br><span class="line">         payloadSize: <span class="type">Int</span>,</span><br><span class="line">         magicValue: <span class="type">Byte</span>) = &#123;</span><br><span class="line">  <span class="comment">// 计算总长度，分配对应大小的ByteBuffer</span></span><br><span class="line">  <span class="keyword">this</span>(<span class="type">ByteBuffer</span>.allocate(<span class="type">Message</span>.<span class="type">CrcLength</span> +</span><br><span class="line">                           <span class="type">Message</span>.<span class="type">MagicLength</span> +</span><br><span class="line">                           <span class="type">Message</span>.<span class="type">AttributesLength</span> +</span><br><span class="line">                           (<span class="keyword">if</span> (magicValue == <span class="type">Message</span>.<span class="type">MagicValue_V0</span>) <span class="number">0</span></span><br><span class="line">                            <span class="keyword">else</span> <span class="type">Message</span>.<span class="type">TimestampLength</span>) +</span><br><span class="line">                           <span class="type">Message</span>.<span class="type">KeySizeLength</span> + </span><br><span class="line">                           (<span class="keyword">if</span>(key == <span class="literal">null</span>) <span class="number">0</span> <span class="keyword">else</span> key.length) + </span><br><span class="line">                           <span class="type">Message</span>.<span class="type">ValueSizeLength</span> + </span><br><span class="line">                           (<span class="keyword">if</span>(bytes == <span class="literal">null</span>) <span class="number">0</span> </span><br><span class="line">                            <span class="keyword">else</span> <span class="keyword">if</span>(payloadSize &gt;= <span class="number">0</span>) payloadSize </span><br><span class="line">                            <span class="keyword">else</span> bytes.length - payloadOffset)))</span><br><span class="line">  <span class="comment">// 验证magic和timestamp是否对应：</span></span><br><span class="line">  <span class="comment">// 1. magic只能为0或1；</span></span><br><span class="line">  <span class="comment">// 2. 时间戳必须为非负数或-1（代表不使用时间戳）；</span></span><br><span class="line">  <span class="comment">// 3. magic为0时timestamp必须为-1，因为v0版本不支持时间戳；</span></span><br><span class="line">  validateTimestampAndMagicValue(timestamp, magicValue)</span><br><span class="line">  <span class="comment">// skip crc, we will fill that in at the end</span></span><br><span class="line">  <span class="comment">// 跳过CRC字段，先填充后面的部分</span></span><br><span class="line">  buffer.position(<span class="type">MagicOffset</span>)</span><br><span class="line">  buffer.put(magicValue) <span class="comment">// 填充 magic</span></span><br><span class="line">  <span class="comment">// 根据压缩类型和时间戳类型计算 attribute 并填充</span></span><br><span class="line">  <span class="keyword">val</span> attributes: <span class="type">Byte</span> = <span class="type">LegacyRecord</span>.computeAttributes(magicValue, <span class="type">CompressionType</span>.forId(codec.codec), timestampType)</span><br><span class="line">  buffer.put(attributes)</span><br><span class="line">  <span class="comment">// Only put timestamp when &quot;magic&quot; value is greater than 0</span></span><br><span class="line">  <span class="keyword">if</span> (magic &gt; <span class="type">MagicValue_V0</span>) <span class="comment">// 仅当magic大于0才可以填充时间戳</span></span><br><span class="line">    buffer.putLong(timestamp)</span><br><span class="line">  <span class="keyword">if</span>(key == <span class="literal">null</span>) &#123; <span class="comment">// key为空则将keylen填充为-1，代表key不存在</span></span><br><span class="line">    buffer.putInt(<span class="number">-1</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则填充 keylen 和 key</span></span><br><span class="line">    buffer.putInt(key.length)</span><br><span class="line">    buffer.put(key, <span class="number">0</span>, key.length)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 类似key，若bytes为空，填充len为-1，否则填充 bytes 的指定部分</span></span><br><span class="line">  <span class="comment">// payloadOffset指定起始偏移量，payloadSize指定填充字节数(若&lt;0则填充偏移量之后的所有字节)</span></span><br><span class="line">  <span class="keyword">val</span> size = <span class="keyword">if</span>(bytes == <span class="literal">null</span>) <span class="number">-1</span></span><br><span class="line">             <span class="keyword">else</span> <span class="keyword">if</span>(payloadSize &gt;= <span class="number">0</span>) payloadSize </span><br><span class="line">             <span class="keyword">else</span> bytes.length - payloadOffset</span><br><span class="line">  buffer.putInt(size)</span><br><span class="line">  <span class="keyword">if</span>(bytes != <span class="literal">null</span>)</span><br><span class="line">    buffer.put(bytes, payloadOffset, size)</span><br><span class="line">  buffer.rewind() <span class="comment">// 重置position为初始，以便之后getXXX()读取</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// now compute the checksum and fill it in</span></span><br><span class="line">  <span class="comment">// 后面字段填充完了，计算CRC校验值并填充到前4个字节，完成后position为4，</span></span><br><span class="line">  <span class="comment">// 也就是对内部buffer调用slice()方法返回的是magic字段至末尾的部分而不包含CRC字段</span></span><br><span class="line">  <span class="type">ByteUtils</span>.writeUnsignedInt(buffer, <span class="type">CrcOffset</span>, computeChecksum)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其他辅助构造器都是基于这个辅助构造器构造的，代码就不一一贴出。</p>
<h2 id="Record类"><a href="#Record类" class="headerlink" title="Record类"></a>Record类</h2><p><code>class Message</code>的<code>asRecord()</code>方法和<code>object Message</code>的<code>fromRecord()</code>方法提供了<code>Message</code>类和Java的<code>LegacyRecord</code>类的互相转化：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// object Message</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fromRecord</span></span>(record: <span class="type">LegacyRecord</span>): <span class="type">Message</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> wrapperTimestamp: <span class="type">Option</span>[<span class="type">Long</span>] = <span class="keyword">if</span> (record.wrapperRecordTimestamp == <span class="literal">null</span>) <span class="type">None</span> <span class="keyword">else</span> <span class="type">Some</span>(record.wrapperRecordTimestamp)</span><br><span class="line">  <span class="keyword">val</span> wrapperTimestampType = <span class="type">Option</span>(record.wrapperRecordTimestampType)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Message</span>(record.buffer, wrapperTimestamp, wrapperTimestampType)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// class Message</span></span><br><span class="line"><span class="keyword">private</span>[message] <span class="function"><span class="keyword">def</span> <span class="title">asRecord</span></span>: <span class="type">LegacyRecord</span> = wrapperMessageTimestamp <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="keyword">new</span> <span class="type">LegacyRecord</span>(buffer)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Some</span>(timestamp) =&gt; <span class="keyword">new</span> <span class="type">LegacyRecord</span>(buffer, timestamp, wrapperMessageTimestampType.orNull)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可见两者的构造器完全一致，其实去看实现的话大多数方法也是一致的。只不过<code>Record</code>提供了一系列<code>write()</code>方法可以将内部存储的字节写入到<code>DataOutputStream</code>类中，而<code>Message</code>本身没有，因此要将<code>Message</code>写入数据流时需要调用<code>asRecord</code>转换成Record对象再调用<code>write()</code>方法。</p>
<p>此外<code>LegacyRecord</code>还提供了<code>writeCompressedRecordHeader()</code>方法在创建消息集（Message Set）时会使用，到时候再去阅读。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文内容比较简单，主要是阅读Kafka的消息格式的实现，Java&#x2F;Scala使用<code>ByteBuffer</code>来实现基于字节的消息协议。Kafka在0.10.0中做出了较大改变，添加了时间戳字段，因此使用了<code>magic</code>字段来区分不同版本的消息。最后，Scala类<code>Message</code>也提供了与Java类<code>LegacyRecord</code>的转换方法，从而实现向数据流的写入。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/10/14/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB05-%E6%B6%88%E6%81%AF%E5%8D%8F%E8%AE%AE%E9%98%85%E8%AF%BB%E4%B9%8BMessage/" data-id="cl1qn406y000b4c1ugdo6bhyy" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Kafka源码阅读04-API层之Handler和Apis" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/10/08/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB04-API%E5%B1%82%E4%B9%8BHandler%E5%92%8CApis/" class="article-date">
  <time datetime="2019-10-08T04:14:48.000Z" itemprop="datePublished">2019-10-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/08/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB04-API%E5%B1%82%E4%B9%8BHandler%E5%92%8CApis/">Kafka源码阅读04-API层之Handler和Apis</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>之前通过网络层的阅读，我们知道了和客户端直接进行读写的是<code>Processor</code>，但是它会将请求通过<code>RequestChannel</code>发送给<code>KafkaRequestHandler</code>，同时也会接收<code>KafkaApis</code>通过<code>RequestChannel</code>回复的响应。因此从本篇开始阅读API层，也就是Handler和Apis，它们都是位于<code>server</code>包内。</p>
<h2 id="Handler线程的创建"><a href="#Handler线程的创建" class="headerlink" title="Handler线程的创建"></a>Handler线程的创建</h2><p>回顾请求的调用链</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="module-access"><span class="module"><span class="identifier">Processor</span>.</span></span>processCompleteReceives</span><br><span class="line">  \-- requestChannel.send<span class="constructor">Request(<span class="params">request</span>)</span></span><br><span class="line">    \-- requestQueue.put(request)</span><br></pre></td></tr></table></figure>

<p><code>Processor</code>的<code>requestChannel</code>字段调用<code>sendRequest()</code>方法，该方法将请求放入其<code>requestQueue</code>字段中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> requestQueue = <span class="keyword">new</span> <span class="type">ArrayBlockingQueue</span>[<span class="type">BaseRequest</span>](queueSize)</span><br></pre></td></tr></table></figure>

<p>既然有入队，就肯定有出队，找到其<code>poll()</code>方法的调用处：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 取得下一个请求，或者阻塞直到超时  </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receiveRequest</span></span>(timeout: <span class="type">Long</span>): <span class="type">RequestChannel</span>.<span class="type">BaseRequest</span> =</span><br><span class="line">  requestQueue.poll(timeout, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br></pre></td></tr></table></figure>

<p>继续找到该方法的调用处，在<code>KafkaRequestHandler.run()</code>方法中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> req = requestChannel.receiveRequest(<span class="number">300</span>) <span class="comment">// 300ms超时</span></span><br></pre></td></tr></table></figure>

<p><code>KafkaRequestHandler</code>实现了<code>Runnable</code>接口，也就是说，它在调用<code>start()</code>方法时就会启动线程，执行<code>run()</code>方法，查找使用它的地方，为<code>KafkaRequestHandlerPool</code>的字段：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> runnables = <span class="keyword">new</span> mutable.<span class="type">ArrayBuffer</span>[<span class="type">KafkaRequestHandler</span>](numThreads)</span><br></pre></td></tr></table></figure>

<p>Poll类管理了Handler线程，它默认创建了<code>numThreads</code>个Handler线程。</p>
<p>PS：这里使用了<code>ArrayBuffer</code>而非固定大小的<code>Array</code>，和之前提到的<code>Processor</code>和<code>Acceptor</code>使用<code>ConcurrentHashMap</code>保存一样，都是为了支持<code>resize</code>操作。</p>
<p>再看看<code>Pool</code>类的使用处，它是<code>KafkaServer</code>的字段</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> requestHandlerPool: <span class="type">KafkaRequestHandlerPool</span> = <span class="literal">null</span></span><br></pre></td></tr></table></figure>

<p><code>KafkaServer</code>才是真正的Kafka服务器的类，而之前介绍的<code>SocketServer</code>类只是它用来管理网络的部分，也是其中的一个字段：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> socketServer: <span class="type">SocketServer</span> = <span class="literal">null</span></span><br></pre></td></tr></table></figure>

<p>再看看<code>requestHandlerPool</code>的使用处，位于<code>KafkaServer</code>的<code>startup()</code>方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">requestHandlerPool = <span class="keyword">new</span> <span class="type">KafkaRequestHandlerPool</span>(config.brokerId,</span><br><span class="line">                                                 socketServer.requestChannel,</span><br><span class="line">                                                 apis, time, config.numIoThreads)</span><br></pre></td></tr></table></figure>

<p>第1个参数为配置的<code>broker.id</code>，第2个参数为<code>RequestChannel</code>对象，第3个参数为<code>KafkaApis</code>对象，第4个参数为<code>KafkaServer</code>的构造参数，为<code>SystemTime</code>对象，位于<code>common.util</code>包内。</p>
<p>第5个参数为Handler线程的数量，为<code>config.numIoThreads</code>，对应配置文件的<code>num.io.threads</code>，默认值为8（见<code>KafkaConfig.scala</code>的<code>Defaults</code>伴生对象）。</p>
<p>而Pool类中创建Handler线程代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">0</span> until numThreads) &#123;</span><br><span class="line">  createHandler(i)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createHandler</span></span>(id: <span class="type">Int</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  runnables += <span class="keyword">new</span> <span class="type">KafkaRequestHandler</span>(id, brokerId, aggregateIdleMeter, threadPoolSize, requestChannel, apis, time)</span><br><span class="line">  <span class="type">KafkaThread</span>.daemon(<span class="string">&quot;kafka-request-handler-&quot;</span> + id, runnables(id)).start()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>id</code>为Handler线程的编号（从0开始），<code>aggregateIdleMeter</code>为度量指标相关（配合<code>time</code>字段计算Handler线程闲置的时间，我们依旧忽略之），<code>threadPoolSize</code>为线程池大小（即线程数量）。剩余参数都是Pool类的构造参数。</p>
<p>至此，我们知道了<code>KafkaServer</code>管理了Handler线程池，会根据配置的<code>num.io.threads</code>创建对应数量的Handler线程，并且多个Handler线程共享了<code>KafkaApis</code>对象和<code>RequestChannel</code>对象。</p>
<h2 id="Handler线程实现"><a href="#Handler线程实现" class="headerlink" title="Handler线程实现"></a>Handler线程实现</h2><p>忽略了日志和度量指标的部分：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  <span class="keyword">while</span> (!stopped) &#123;</span><br><span class="line">    <span class="comment">// 从requestChannel中取得请求，timeout为300ms</span></span><br><span class="line">    <span class="keyword">val</span> req = requestChannel.receiveRequest(<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">    req <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="comment">// Shutdown类型的请求，直接退出Handler线程</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">ShutdownRequest</span> =&gt;</span><br><span class="line">        debug(<span class="string">s&quot;Kafka request handler <span class="subst">$id</span> on broker <span class="subst">$brokerId</span> received shut down command&quot;</span>)</span><br><span class="line">        shutdownComplete.countDown()</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 正常请求</span></span><br><span class="line">      <span class="keyword">case</span> request: <span class="type">RequestChannel</span>.<span class="type">Request</span> =&gt;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          request.requestDequeueTimeNanos = endTime</span><br><span class="line">          <span class="comment">// 交给apis处理</span></span><br><span class="line">          apis.handle(request)</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;  <span class="comment">// 处理api.handle()可能抛出的异常</span></span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">FatalExitError</span> =&gt;</span><br><span class="line">            shutdownComplete.countDown()</span><br><span class="line">            <span class="type">Exit</span>.exit(e.statusCode)</span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">&quot;Exception when handling request&quot;</span>, e)</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          request.releaseBuffer()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> <span class="literal">null</span> =&gt; <span class="comment">// continue</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  shutdownComplete.countDown()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>逻辑很简单，Handler线程反复地从<code>requestChannel</code>中取得请求，交由<code>apis</code>进行处理，如果处理出错会捕获异常，并以异常中包含的错误码退出当前线程。这也解释了前一篇的疑问：为何请求的发送对象是Handler线程，而响应却来自于Apis。</p>
<p>值得注意的地方是，这里还有个<code>ShutdownRequest</code>，是用来退出Handler线程的，找到它的调用处：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendShutdownRequest</span></span>(): <span class="type">Unit</span> = requestQueue.put(<span class="type">ShutdownRequest</span>)</span><br></pre></td></tr></table></figure>

<p><code>RequestChannel</code>对象调用该方法将Shutdown请求加入队列中，而该方法的调用处位于<code>KafkaRequestHandler</code>内：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initiateShutdown</span></span>(): <span class="type">Unit</span> = requestChannel.sendShutdownRequest()</span><br></pre></td></tr></table></figure>

<p>进一步往上找，会发现位于<code>KafkaRequestHandler</code>的<code>shutdown()</code>方法内，用于Handler线程的正常退出（相对而言，<code>apis.handle()</code>抛出异常则是异常退出，退出码不为0）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shutdown</span></span>(): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  info(<span class="string">&quot;shutting down&quot;</span>)</span><br><span class="line">  <span class="keyword">for</span> (handler &lt;- runnables)</span><br><span class="line">    handler.initiateShutdown()</span><br><span class="line">  <span class="keyword">for</span> (handler &lt;- runnables)</span><br><span class="line">    handler.awaitShutdown()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>至于<code>awaitShutdown()</code>方法，则是Java线程退出的惯用法，即调用了<code>CountDownLatch</code>对象的<code>await()</code>方法，等待计数归0，可以看到<code>run()</code>方法中不同的退出分支都会调用<code>shutdownComplete.countDown()</code>方法，即将<code>CountDownLatch</code>对象<code>shutdownComplete</code>的计数减1，而其初始计数为1：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> shutdownComplete = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Apis"><a href="#Apis" class="headerlink" title="Apis"></a>Apis</h2><p><code>KafkaApis</code>对象的创建在<code>KafkaRequestHandlerPool</code>创建之前，其构造参数有18个，因此暂时不详细列出，最为关键的还是<code>requestChannel</code>。看看关键的<code>handle()</code>方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    request.header.apiKey <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">PRODUCE</span> =&gt; handleProduceRequest(request)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">FETCH</span> =&gt; handleFetchRequest(request)</span><br><span class="line">      <span class="comment">// 其他类型的的ApiKeys...</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">FatalExitError</span> =&gt; <span class="keyword">throw</span> e</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; handleError(request, e)</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    request.apiLocalCompleteTimeNanos = time.nanoseconds</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>取得请求头的<code>apiKey</code>（见前一篇的<strong>请求头的解析</strong>一节），根据类型调用不同的<code>handle*()</code>方法进行处理，这里看一个比较简单的例子，是对<code>LIST_OFFSETS</code>请求的处理：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleListOffsetRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> version = request.header.apiVersion()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 根据请求头的API版本进行不同的处理</span></span><br><span class="line">  <span class="keyword">val</span> mergedResponseMap = <span class="keyword">if</span> (version == <span class="number">0</span>)</span><br><span class="line">    handleListOffsetRequestV0(request)</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    handleListOffsetRequestV1AndAbove(request)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 参数2为将requestThrottleMs作为输入的函数，会根据该输入创建ListOffsetResponse对象</span></span><br><span class="line">  <span class="comment">// 并且在sendResponseMaybeThrottle类根据requestThrottleMs判断是否创建该对象并发送</span></span><br><span class="line">  sendResponseMaybeThrottle(request, requestThrottleMs =&gt; <span class="keyword">new</span> <span class="type">ListOffsetResponse</span>(requestThrottleMs, mergedResponseMap.asJava))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>进一步的分析略过，总之Apis在处理完请求后，如果判断需要发送，则会创建响应的响应（<code>*Response</code>）类型，并调用<code>sendResponse()</code>方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>, responseOpt: <span class="type">Option</span>[<span class="type">AbstractResponse</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 对响应的每个非0错误码更新度量指标</span></span><br><span class="line">  responseOpt.foreach(response =&gt; requestChannel.updateErrorMetrics(request.header.apiKey, response.errorCounts.asScala))</span><br><span class="line"></span><br><span class="line">  responseOpt <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(response) =&gt;</span><br><span class="line">      <span class="comment">// 若响应存在，则构造响应的Send，并调用requestChannel的sendResponse()方法发送</span></span><br><span class="line">      <span class="keyword">val</span> responseSend = request.context.buildResponse(response)</span><br><span class="line">      <span class="comment">// 如果RequestChannel伴生对象的isRequestloggingEnabled则构造该字符串</span></span><br><span class="line">      <span class="keyword">val</span> responseString =</span><br><span class="line">        <span class="keyword">if</span> (<span class="type">RequestChannel</span>.isRequestLoggingEnabled) <span class="type">Some</span>(response.toString(request.context.apiVersion))</span><br><span class="line">        <span class="keyword">else</span> <span class="type">None</span></span><br><span class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, <span class="type">Some</span>(responseSend), <span class="type">SendAction</span>, responseString))</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, <span class="type">None</span>, <span class="type">NoOpAction</span>, <span class="type">None</span>))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可见实际上，还是利用<code>requestChannel.sendResponse()</code>方法发送响应（参见前一篇的<strong>处理响应</strong>一节，会将响应加入<code>Processor</code>的响应队列中）。这里的<code>Send</code>接口表示的是待发送的数据，而<code>String</code>则是用于调试的：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">RequestChannel</span> <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> requestLogger = <span class="type">Logger</span>(<span class="string">&quot;kafka.request.logger&quot;</span>)</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isRequestLoggingEnabled</span></span>: <span class="type">Boolean</span> = requestLogger.underlying.isDebugEnabled</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里需要额外说明下，Kafka的日志系统使用的是<code>SLF4J</code>，它本身只是日志的抽象层，而没有具体的实现，因此在编译运行Kafka时会提示警告：</p>
<blockquote>
<p>SLF4J: Failed to load class “org.slf4j.impl.StaticLoggerBinder”. SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See <a target="_blank" rel="noopener" href="http://www.slf4j.org/codes.html#StaticLoggerBinder">http://www.slf4j.org/codes.html#StaticLoggerBinder</a> for further details.</p>
</blockquote>
<p>只有将具体的日志jar包放入classpath中，才会成功打印日志，因此从Kafka源码中是无法确定<code>isRequestLoggingEnabled</code>在哪里设置为<code>true</code>，取决于实际日志包的配置。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>API层其实还是很简单的，创建<code>num.io.threads</code>个Handler线程，从共享的<code>RequestChannel</code>中取出请求（使用<code>ArrayBlockingQueue</code>请求队列保证线程安全并且限制最大请求数），如果不是Handler调用<code>shutdown()</code>方法加入的关闭请求，则将其交给Apis对象进行处理，处理完请求后会构造响应对象，通过<code>RequestChannel</code>加入到<code>Processor</code>内部的响应队列（使用<code>LinkedBlockingQueue</code>响应队列保证线程安全，并且不限制最大响应数量）。</p>
<p>实际的请求的解析和响应的构造则集中于<code>KafkaApis</code>类中，接下来则是通过不同的<code>ApiKey</code>类依次看看Kafka支持哪些请求，并且内部是怎样处理这些请求。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/10/08/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB04-API%E5%B1%82%E4%B9%8BHandler%E5%92%8CApis/" data-id="cl1qn4070000d4c1u1shy4m62" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Kafka源码阅读03-网络层阅读之RequestChannel" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/09/23/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB03-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8BRequestChannel/" class="article-date">
  <time datetime="2019-09-23T12:01:56.000Z" itemprop="datePublished">2019-09-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/23/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB03-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8BRequestChannel/">Kafka源码阅读03: 网络层阅读之RequestChannel</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>前2篇分析了<code>SocketServer</code>的启动以及<code>Acceptor</code>&#x2F;<code>Processor</code>，对配置<code>listener</code>的网络地址，都会创建1个<code>Acceptor</code>和N个<code>Processor</code>，其中N为配置<code>num.network.thread</code>。每个<code>Acceptor</code>会创建1个默认的NIO <code>Selector</code>，每个<code>Processor</code>则都会创建1个Kafka自行实现<code>Selector</code>接口的<code>KSelector</code>。</p>
<p>socket都会被封装成<code>Channel</code>，即通道，代表socket两端的连接。<code>Acceptor</code>会创建一个<code>Channel</code>监听网络地址，并在其<code>Selector</code>注册读事件，然后负责将所有客户端的连接转换成<code>Channel</code>均衡地发送给<code>Processor</code>。</p>
<p><code>Processor</code>则在其<code>Selector</code>上注册从<code>Acceptor</code>收到的<code>Channel</code>的读&#x2F;写&#x2F;关闭连接等事件，并分别处理。但是<code>Processor</code>只负责读取请求(Request)和写入响应(Response)，对于已完成的请求，会将其作为参数传给<code>requestChannel</code>调用<code>sendRequest()</code>。另一方面，<code>Processor</code>内部的响应队列，则是由<code>requestChannel</code>调用<code>sendResponse()</code>得到的。</p>
<p>而<code>RequestChannel</code>包含<code>requestQueue</code>字段缓存请求，另外它也和<code>SocketServer</code>一样保存了所有<code>Processor</code>的id和自身组成的<code>ConcurrentHashMap</code>。</p>
<h2 id="处理请求"><a href="#处理请求" class="headerlink" title="处理请求"></a>处理请求</h2><h3 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h3><p>在<code>Processor.processCompletedReceives()</code>方法中，会将封装了网络地址信息的请求传递给<code>sendRequest()</code>方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> header = <span class="type">RequestHeader</span>.parse(receive.payload)</span><br><span class="line"><span class="keyword">val</span> context = <span class="keyword">new</span> <span class="type">RequestContext</span>(header, receive.source, channel.socketAddress,</span><br><span class="line">  channel.principal, listenerName, securityProtocol)</span><br><span class="line"><span class="keyword">val</span> req = <span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Request</span>(processor = id, context = context,</span><br><span class="line">  startTimeNanos = time.nanoseconds, memoryPool, receive.payload, requestChannel.metrics)</span><br><span class="line">requestChannel.sendRequest(req)</span><br></pre></td></tr></table></figure>

<p><code>sendRequest()</code>方法的实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 发送待处理的请求, requestQueue 有容量上限, 由 queue.max.requests 配置, 若达到了上限则会阻塞。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">  requestQueue.put(request)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>“发送”只是将请求放到了内部的请求队列中，而出队方法是在<code>server.KafkaRequestHandler</code>中调用的，不属于网络层的事情，暂时不管。因此看看<code>Request</code>类型的构造，传入了<code>header</code>和<code>context</code>。</p>
<h3 id="请求头的解析"><a href="#请求头的解析" class="headerlink" title="请求头的解析"></a>请求头的解析</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> RequestHeader <span class="title function_">parse</span><span class="params">(ByteBuffer buffer)</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 前2个字节为 Api Key, 代表请求的类型</span></span><br><span class="line">        <span class="type">short</span> <span class="variable">apiKey</span> <span class="operator">=</span> buffer.getShort();</span><br><span class="line">        <span class="comment">// 后2个字节为 Api Version, 即客户端使用的API版本</span></span><br><span class="line">        <span class="type">short</span> <span class="variable">apiVersion</span> <span class="operator">=</span> buffer.getShort();</span><br><span class="line">        <span class="comment">// 通过上述字段创建 Schema 对象, 即完整的消息头</span></span><br><span class="line">        <span class="type">Schema</span> <span class="variable">schema</span> <span class="operator">=</span> schema(apiKey, apiVersion);</span><br><span class="line">        <span class="comment">// ByteBuffer.getXXX() 会修改内部偏移量, 因此需要将偏移量重置为最开始以便从头读取 buffer</span></span><br><span class="line">        <span class="comment">// 从头读取 buffer, 进而用 scheme.read() 构造请求头</span></span><br><span class="line">        buffer.rewind();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RequestHeader</span>(schema.read(buffer));</span><br><span class="line">    &#125;  <span class="comment">// 异常处理(略)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Api Key的类型参考<a target="_blank" rel="noopener" href="https://kafka.apache.org/protocol.html#protocol_api_keys">Api Key</a>，消息协议类型参考<a target="_blank" rel="noopener" href="https://kafka.apache.org/protocol.html#protocol_messages">消息协议</a>：</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Request Header <span class="operator">=</span>&gt; api_key api_version correlation_id client_id </span><br><span class="line">  api_key <span class="operator">=</span>&gt; INT16</span><br><span class="line">  api_version <span class="operator">=</span>&gt; INT16</span><br><span class="line">  correlation_id <span class="operator">=</span>&gt; INT32</span><br><span class="line">  client_id <span class="operator">=</span>&gt; NULLABLE_STRING</span><br></pre></td></tr></table></figure>

<p>这个头部即<code>Schema</code>类，其<code>read()</code>方法会把后面的correlation id和client id给读入，构造消息头。</p>
<h3 id="请求上下文的构造"><a href="#请求上下文的构造" class="headerlink" title="请求上下文的构造"></a>请求上下文的构造</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> context = <span class="keyword">new</span> <span class="type">RequestContext</span>(header, receive.source, channel.socketAddress,  channel.principal,</span><br><span class="line">                                 listenerName, securityProtocol)</span><br></pre></td></tr></table></figure>

<p>其实就是简单地将对应参数赋值给内部字段：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> RequestHeader header;  <span class="comment">// 消息头</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> String connectionId; <span class="comment">// 连接id，包含本地和远程的地址和表示连接的index</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> InetAddress clientAddress; <span class="comment">// 客户端地址</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> KafkaPrincipal principal; <span class="comment">// Channel的principal字段，用于信息认证</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> ListenerName listenerName; <span class="comment">// 配置 listeners 的名字部分(比如PLAINTEXT) </span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> SecurityProtocol securityProtocol; <span class="comment">// 安全协议, 根据listenerName解析的</span></span><br></pre></td></tr></table></figure>

<p>消息头上一小节刚看完，连接id也是阅读源码至今一直见到的用于标识一条TCP连接的字符串，最后2个字段均为解析<code>listener</code>配置时解析出的<code>EndPoint</code>类的字段。</p>
<h3 id="请求对象的创建"><a href="#请求对象的创建" class="headerlink" title="请求对象的创建"></a>请求对象的创建</h3><p><code>RequestChannel.Request</code>字段比较多就不一一解释了（很多都是metric相关的），核心是请求body（0.10版本是字段现在是方法）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">body</span></span>[<span class="type">T</span> &lt;: <span class="type">AbstractRequest</span>](<span class="keyword">implicit</span> classTag: <span class="type">ClassTag</span>[<span class="type">T</span>], nn: <span class="type">NotNothing</span>[<span class="type">T</span>]): <span class="type">T</span> = &#123;</span><br><span class="line">  bodyAndSize.request <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> r: <span class="type">T</span> =&gt; r</span><br><span class="line">    <span class="keyword">case</span> r =&gt;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ClassCastException</span>(<span class="string">s&quot;Expected request with type <span class="subst">$&#123;classTag.runtimeClass&#125;</span>, but found <span class="subst">$&#123;r.getClass&#125;</span>&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该方法仅仅是检查请求类型T是否合法，若不合法则抛出异常。</p>
<p>关键部分是<code>bodyAndSize</code>进行类型匹配，该字段初始化：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> bodyAndSize: <span class="type">RequestAndSize</span> = context.parseRequest(buffer)</span><br></pre></td></tr></table></figure>

<p><code>context</code>解析请求的方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> RequestAndSize <span class="title function_">parseRequest</span><span class="params">(ByteBuffer buffer)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (isUnsupportedApiVersionsRequest()) &#123;</span><br><span class="line">        <span class="comment">// 未支持的 ApiVersion 被视为v0请求并且不被处理</span></span><br><span class="line">        <span class="type">ApiVersionsRequest</span> <span class="variable">apiVersionsRequest</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ApiVersionsRequest</span>((<span class="type">short</span>) <span class="number">0</span>, header.apiVersion());</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RequestAndSize</span>(apiVersionsRequest, <span class="number">0</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">ApiKeys</span> <span class="variable">apiKey</span> <span class="operator">=</span> header.apiKey();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">short</span> <span class="variable">apiVersion</span> <span class="operator">=</span> header.apiVersion();</span><br><span class="line">            <span class="comment">// 根据API版本将字节缓存解析成Struct的各个字段</span></span><br><span class="line">            <span class="type">Struct</span> <span class="variable">struct</span> <span class="operator">=</span> apiKey.parseRequest(apiVersion, buffer);</span><br><span class="line">            <span class="comment">// 根据请求类型/API版本/Struct字段创建实际的请求类型</span></span><br><span class="line">            <span class="type">AbstractRequest</span> <span class="variable">body</span> <span class="operator">=</span> AbstractRequest.parseRequest(apiKey, apiVersion, struct);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RequestAndSize</span>(body, struct.sizeOf());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable ex) &#123;</span><br><span class="line">            <span class="comment">// 异常处理(略)</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 类 AbstractRequest 的方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> AbstractRequest <span class="title function_">parseRequest</span><span class="params">(ApiKeys apiKey, <span class="type">short</span> apiVersion, Struct struct)</span> &#123;</span><br><span class="line">    <span class="keyword">switch</span> (apiKey) &#123;</span><br><span class="line">        <span class="keyword">case</span> PRODUCE: </span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ProduceRequest</span>(struct, apiVersion);</span><br><span class="line">        <span class="keyword">case</span> FETCH:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">FetchRequest</span>(struct, apiVersion);</span><br><span class="line">        <span class="comment">// 其他类型的请求...(略)</span></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="comment">// 异常处理(略)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这部分代码都是Java实现的，为了能根据不同请求类型&#x2F;API版本得到对应的请求类型的示例，实现得较为复杂，细节也不深入去看，总之，在Kafka中可以像这样调用<code>body()</code>方法得到实际的请求对象：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将请求的 ByteBuffer 解析成 MetadataRequest 对象</span></span><br><span class="line"><span class="keyword">val</span> metadataRequest = request.body[<span class="type">MetadataRequest</span>]</span><br></pre></td></tr></table></figure>

<h3 id="取出请求"><a href="#取出请求" class="headerlink" title="取出请求"></a>取出请求</h3><p>之前介绍了<code>Processor</code>仅仅是将请求加入阻塞队列<code>requestQueue</code>中，那么何时取出呢？找到其<code>poll()</code>方法的调用处：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 取得下个请求, 或者阻塞直到超时</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receiveRequest</span></span>(timeout: <span class="type">Long</span>): <span class="type">RequestChannel</span>.<span class="type">BaseRequest</span> =</span><br><span class="line">  requestQueue.poll(timeout, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br></pre></td></tr></table></figure>

<p>再看看上述方法的调用处：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 类 KafkaRequestHandler 的方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  <span class="keyword">while</span> (!stopped) &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">val</span> req = requestChannel.receiveRequest(<span class="number">300</span>) <span class="comment">// 300ms超时</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    req <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">ShutdownRequest</span> =&gt;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">      <span class="keyword">case</span> request: <span class="type">RequestChannel</span>.<span class="type">Request</span> =&gt;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">      <span class="keyword">case</span> <span class="literal">null</span> =&gt; <span class="comment">// continue</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于是API层的代码，所以略去了其他代码，只保留了<code>req</code>相关的。可以看到请求<code>Handler</code>线程会反复地从请求队列中取出请求，然后根据请求地类型进行不同处理。</p>
<h3 id="多线程取出请求安全吗？"><a href="#多线程取出请求安全吗？" class="headerlink" title="多线程取出请求安全吗？"></a>多线程取出请求安全吗？</h3><p>由于<code>ArrayBlockingQueue</code>是线程安全的，所以多个<code>Handler</code>线程从中取出请求是线程安全的。另一方面，关于顺序性，即来自同一个客户端的多个请求，必须保证取出的顺序也一致。《Apache Kafka源码剖析》书上给出了解释：<code>Processor.run()</code>方法通过多处注册&#x2F;取消 读&#x2F;写事件 来保证每个连接上只有一个请求和一个对应的响应来实现的。</p>
<p>具体而言，可以回顾我上一篇源码分析中<code>Processor</code>的部分：</p>
<ol>
<li>在<code>processCompletedReceives()</code>中，一旦接收到完整的请求<code>req</code>，在调用<code>sendRequest(req)</code>后会取消监听该<code>Channel</code>的读事件；</li>
<li>在<code>processCompleteSends()</code>中，只有当响应成功返回客户端（将响应从缓存的<code>inflightResponses</code>移除）后，才会重新注册该<code>Channel</code>的读事件；</li>
<li>在<code>processNewResponses()</code>中判断请求类型是<code>SendAction</code>时，会注册<code>Channel</code>的写事件；</li>
<li>在<code>poll()</code>中向底层socket发送数据时，如果判断数据完毕，则会取消注册<code>Channel</code>的写事件。</li>
</ol>
<h2 id="处理响应"><a href="#处理响应" class="headerlink" title="处理响应"></a>处理响应</h2><p><code>Processor</code>自己维护了响应队列，并在<code>processNewResponses()</code>中调用<code>dequeueResponse()</code>方法依次出队， 那么，可以找到其对应方法<code>enqueueResponse()</code>的调用处：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (isTraceEnabled) &#123;</span><br><span class="line">    <span class="comment">// 判断响应类型并打印日志(略)</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> processor = processors.get(response.processor)</span><br><span class="line">  <span class="comment">// 如果 processor 已经关闭了, 可能会被移出 processors (此时返回null), 因此直接丢掉响应</span></span><br><span class="line">  <span class="keyword">if</span> (processor != <span class="literal">null</span>) &#123;</span><br><span class="line">    processor.enqueueResponse(response)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>值得注意的是这里对<code>processor != null</code>的判断，Kafka 1.1.0的<code>SocketServer</code>支持<code>resizeThreadPoll()</code>方法来改变网络线程数量（也就是<code>Acceptor</code>对应<code>Processor</code>的数量），如果网络线程数减少的话，那么多出的<code>Processor</code>会调用<code>shutdown()</code>方法关闭，并通过<code>connectionId</code>将其从<code>Acceptor</code>和<code>RequestChannel</code>中的<code>processors</code>字段移除。</p>
<p>继续找到该方法的调用处，位于<code>KafkaApis</code>的<code>sendResponse()</code>方法中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>, responseOpt: <span class="type">Option</span>[<span class="type">AbstractResponse</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 更新metrics(略)</span></span><br><span class="line"></span><br><span class="line">  responseOpt <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(response) =&gt;</span><br><span class="line">      <span class="keyword">val</span> responseSend = request.context.buildResponse(response)</span><br><span class="line">      <span class="keyword">val</span> responseString =</span><br><span class="line">        <span class="keyword">if</span> (<span class="type">RequestChannel</span>.isRequestLoggingEnabled) <span class="type">Some</span>(response.toString(request.context.apiVersion))</span><br><span class="line">        <span class="keyword">else</span> <span class="type">None</span></span><br><span class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, <span class="type">Some</span>(responseSend), <span class="type">SendAction</span>, responseString))</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, <span class="type">None</span>, <span class="type">NoOpAction</span>, <span class="type">None</span>))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>此时<code>RequestChannel</code>只是将响应转发给了<code>Processor</code>，它本身并不维护响应队列（在0.10.0.1版本中则是维护了多个响应队列），真正维护响应队列的是<code>Processor</code>本身。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>关于Kafka网络层的阅读至此就告一段落，不得不说但作为Kafka的基础设施的Java NIO实现的部分更为复杂（<code>KafkaChannel</code>和<code>KafkaSelector</code>），但阅读源码不应太陷入细节（感觉我已经有些陷进去了……）。对于Kafka，最重要的还是它的业务层，也就是对<a target="_blank" rel="noopener" href="https://kafka.apache.org/protocol.html">Kafka协议</a>的实现。</p>
<p><code>RequestChannel</code>的作用很简单：</p>
<ul>
<li>维护请求队列，接收来自<code>Processor</code>的请求，并转发给<code>KafkaRequestHandler</code>进行处理；</li>
<li>从<code>KafkaApis</code>获取响应，发送给<code>Processor</code>。</li>
</ul>
<p>加上文章开始总结的<code>Acceptor</code>&#x2F;<code>Processor</code>，以及统筹全局的<code>SocketServer</code>，构成了Kafka的网络层，简单描述：</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">|<span class="string">             Network Layer                 </span>|<span class="string">       API Layer        </span>|</span><br><span class="line">|<span class="string"> Acceptor -&gt; Processors &lt;-&gt; RequestChannel </span>|<span class="string"> -&gt; KafkaRequestHandler </span>|</span><br><span class="line">|<span class="string">                                           </span>|<span class="string"> &lt;- KafkaApis           </span>|</span><br><span class="line">|<span class="string"> Client -&gt; SocketChannel -&gt; Acceptor       </span>|<span class="string">                        </span>|</span><br><span class="line">|<span class="string"> Client &lt;-&gt; KafkaChannel &lt;-&gt; Processor     </span>|<span class="string">                        </span>|</span><br></pre></td></tr></table></figure>

<p>可以发现不管是什么<code>Channel</code>，都是起到了连接的作用。<code>Acceptor</code>通过最简单的<code>SocketChannel</code>与监听套接字连接，监听连接事件，并将接受的连接转发给<code>Processor</code>，之后<code>Processor</code>通过比较复杂的<code>KafkaChannel</code>与客户端连接，监听读&#x2F;写事件并和客户端进行数据的交互。</p>
<p>数据分为来自客户端的请求和来自服务端的响应，<code>Processor</code>不负责这部分，而是通过<code>RequestChannel</code>将请求发送给<code>KafkaRequestHandler</code>，再从<code>RequestChannel</code>接收响应。</p>
<p>问题来了，而实际发送响应给<code>RequestChannel</code>的却是<code>KafkaApis</code>，因此<strong>请求</strong>&#x3D;&gt;<strong>响应</strong>的过程是由它们共同完成的，也就是接下来要阅读的API层。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/09/23/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB03-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8BRequestChannel/" data-id="cl1qn406y000a4c1u6czebwkc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Kafka源码阅读02-网络层阅读之Acceptor和Processor" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/09/20/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB02-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8BAcceptor%E5%92%8CProcessor/" class="article-date">
  <time datetime="2019-09-20T03:38:31.000Z" itemprop="datePublished">2019-09-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/20/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB02-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8BAcceptor%E5%92%8CProcessor/">Kafka源码阅读02: 网络层阅读之Acceptor和Processor</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="AbstractServerThread"><a href="#AbstractServerThread" class="headerlink" title="AbstractServerThread"></a>AbstractServerThread</h2><p><code>Acceptor</code>和<code>Processor</code>的抽象基类，封装了一些辅助的变量和方法（这里重新组织了下代码顺序）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> startupLatch = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> shutdownLatch = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> alive = <span class="keyword">new</span> <span class="type">AtomicBoolean</span>(<span class="literal">true</span>)</span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">isRunning</span></span>: <span class="type">Boolean</span> = alive.get</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shutdown</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 如果线程仍在运行, 则将 alive 置为true表示线程之后会关闭, 然后调用抽象方法 wakeup()</span></span><br><span class="line">  <span class="keyword">if</span> (alive.getAndSet(<span class="literal">false</span>))</span><br><span class="line">    wakeup()</span><br><span class="line">  shutdownLatch.await()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等待线程完全启动</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">awaitStartup</span></span>(): <span class="type">Unit</span> = startupLatch.await</span><br><span class="line"></span><br><span class="line"><span class="comment">// 标识线程已经启动, 这样就可以等待停止操作了, 因此将 shutdownLatch 指向倒计时为1的对象</span></span><br><span class="line"><span class="comment">// 这样做是为了防止启动时抛出异常, 比如绑定正在使用的地址, 此时应该在处理异常之后仍然能 shutdown,</span></span><br><span class="line"><span class="comment">// 此时 shutdownComplete 的调用会因为异常而被跳过, 如果计数初始化为1会一直阻塞</span></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">startupComplete</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// Replace the open latch with </span></span><br><span class="line">  shutdownLatch = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br><span class="line">  startupLatch.countDown()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 标识线程已经关闭</span></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">shutdownComplete</span></span>(): <span class="type">Unit</span> = shutdownLatch.countDown()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(channel: <span class="type">SocketChannel</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (channel != <span class="literal">null</span>) &#123;</span><br><span class="line">    debug(<span class="string">&quot;Closing connection from &quot;</span> + channel.socket.getRemoteSocketAddress())</span><br><span class="line">    <span class="comment">// 减少 channel 对应地址的连接计数</span></span><br><span class="line">    connectionQuotas.dec(channel.socket.getInetAddress)</span><br><span class="line">    <span class="comment">// 关闭 socket 连接以及 channel 本身, 吞下异常, 也就是说关闭出错不是什么严重错误, 写入日志以供分析就行</span></span><br><span class="line">    <span class="type">CoreUtils</span>.swallow(channel.socket().close(), <span class="keyword">this</span>, <span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line">    <span class="type">CoreUtils</span>.swallow(channel.close(), <span class="keyword">this</span>, <span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Acceptor-run"><a href="#Acceptor-run" class="headerlink" title="Acceptor.run()"></a>Acceptor.run()</h2><p>由于循环嵌套还是有点深的，先忽略对Channels的处理部分</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  serverChannel.register(nioSelector, <span class="type">SelectionKey</span>.<span class="type">OP_ACCEPT</span>) <span class="comment">// 注册OP_ACCEPT事件</span></span><br><span class="line">  <span class="comment">// 标识启动完成, 之后 acceptor.awaitStartup() 才会返回, 回顾 createAcceptorAndProcessors()</span></span><br><span class="line">  <span class="comment">// 也就是说 Server 启动时, 必须等到 acceptor 注册 OP_ACCEPT 事件后才会执行后续步骤:</span></span><br><span class="line">  <span class="comment">//   将acceptor加入acceptors, addProcessors, 创建下个acceptor ...</span></span><br><span class="line">  startupComplete()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> currentProcessor = <span class="number">0</span> <span class="comment">// 记录当前processor的id</span></span><br><span class="line">    <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 轮询Selector直到有channels准备好I/O, 或者超时(500ms)</span></span><br><span class="line">        <span class="keyword">val</span> ready = nioSelector.select(<span class="number">500</span>)</span><br><span class="line">        <span class="keyword">if</span> (ready &gt; <span class="number">0</span>) &#123;  <span class="comment">// 有ready个channels准备好I/O</span></span><br><span class="line">          <span class="comment">// <span class="doctag">TODO:</span> 处理准备好I/O的channels</span></span><br><span class="line">        &#125;  <span class="comment">// else: ready &lt;= 0</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// 假设有特定的channel在select时出错, 或者收到bad request, 我们不想要让其他channels受到影响</span></span><br><span class="line">        <span class="comment">// 因此遇到异常只需要打印错误即可。</span></span><br><span class="line">        <span class="comment">// 但是scala会通过ControlThrowable来进行流程控制, 所以此时需要继续将异常往上抛(这是安全的)</span></span><br><span class="line">        <span class="comment">// 在scala 2.13中可以用 case NonFatal(e) 来避免ControlThrowable被捕获</span></span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">ControlThrowable</span> =&gt; <span class="keyword">throw</span> e</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">&quot;Error occurred&quot;</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// Acceptor线程结束后的清理工作</span></span><br><span class="line">    debug(<span class="string">&quot;Closing server socket and selector.&quot;</span>)</span><br><span class="line">    <span class="type">CoreUtils</span>.swallow(serverChannel.close(), <span class="keyword">this</span>, <span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line">    <span class="type">CoreUtils</span>.swallow(nioSelector.close(), <span class="keyword">this</span>, <span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line">    shutdownComplete()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>外层<code>try-finally</code>块没有<code>catch</code>，也就是说一切异常都在<code>while</code>循环体内进行处理，循环体内则是一个大的<code>try-catch</code>，注意重抛<code>ControlThrowable</code>的手法，可以参考<a target="_blank" rel="noopener" href="https://www.scala-lang.org/api/current/scala/util/control/ControlThrowable.html">Scala 2.13 ControlThrowable</a>和<a target="_blank" rel="noopener" href="https://www.scala-lang.org/api/2.12.10/scala/util/control/ControlThrowable.html">Scala 2.12 ControlThrowable</a>。</p>
<p><code>Selector</code>的处理和Linux的<code>epoll_wait</code>如出一辙，所以这里还是很熟悉的，不同的是没有处理<code>ready &lt;= 0</code>的情况，接口文档里写的是</p>
<blockquote>
<p>@return  The number of keys, possibly zero, whose ready-operation sets were update</p>
</blockquote>
<p><code>select()</code>方法不会返回负值，像<code>epoll_wait</code>返回-1的情况，<code>Selector</code>是直接抛出异常了，文档里也写了3种异常：</p>
<ul>
<li><code>IOException</code>: If an I&#x2F;O error occurs;</li>
<li><code>ClosedSelectorException</code>: If this selector is closed;</li>
<li><code>IllegalArgumentException</code>: If the value of the timeout argument is negative.</li>
</ul>
<p>接下来看<code>ready &gt; 0</code>时的代码，也是核心的处理逻辑：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">// 遍历所有的key, 类型为SelectionKey</span></span><br><span class="line">  <span class="keyword">val</span> key = iter.next</span><br><span class="line">  iter.remove() <span class="comment">// 从集合中移除该key, 防止</span></span><br><span class="line">  <span class="keyword">if</span> (key.isAcceptable) &#123;  <span class="comment">// 该key的channel可以接受新的socket连接</span></span><br><span class="line">    <span class="comment">// round robin算法, 将连接均衡分配给计算出的下标对应的processor</span></span><br><span class="line">    <span class="comment">// 比如3个processors, 接收了7个连接, 则分配的processor下标依次为: 0,1,2,0,1,2,0,1</span></span><br><span class="line">    <span class="keyword">val</span> processor = synchronized &#123;</span><br><span class="line">      currentProcessor = currentProcessor % processors.size</span><br><span class="line">      processors(currentProcessor)</span><br><span class="line">    &#125;</span><br><span class="line">    accept(key, processor)</span><br><span class="line">  &#125; <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">&quot;Unrecognized key state for acceptor thread.&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// round robin算法, 迭代</span></span><br><span class="line">  currentProcessor = currentProcessor + <span class="number">1</span></span><br><span class="line">&#125; <span class="keyword">catch</span> &#123; <span class="comment">// 遍历keys及处理每个key时的异常在此打印</span></span><br><span class="line">  <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">&quot;Error while accepting connection&quot;</span>, e)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>思路很简单，就是用round robin算法简单做下负载均衡，调用<code>accept()</code>方法将key对应的连接分配给指定processor，因此核心其实是<code>accept()</code>方法。</p>
<p>PS：一个细节，外层<code>catch</code>处理了<code>ControlThrowable</code>，而内层<code>catch</code>并没处理，因为该异常是实现流程控制的，在迭代器到达末尾时才会抛出该异常，所以迭代循环中不会抛出该异常。另一个细节，这里每次迭代都把迭代器移除，这里大概是Java不会像C++一样，对象销毁的时候自动析构吧，而且Jave的<code>Set</code>移除迭代器之后不影响继续遍历。</p>
<p>看看<code>accept()</code>的实现（删掉了日志语句）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(key: <span class="type">SelectionKey</span>, processor: <span class="type">Processor</span>) &#123;</span><br><span class="line">  <span class="comment">// key.channel()向下转型, 从抽象类 SelectableChannel 转型为派生类 ServerSocketChannel</span></span><br><span class="line">  <span class="keyword">val</span> serverSocketChannel = key.channel().asInstanceOf[<span class="type">ServerSocketChannel</span>]</span><br><span class="line">  <span class="keyword">val</span> socketChannel = serverSocketChannel.accept() <span class="comment">// socket accept, 返回表示连接的 SocketChannel</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 将远程地址对应的连接数加1, 如果超过了配置的最大连接数限额, connectionQuotas会抛出 TooManyConnectionsException</span></span><br><span class="line">    connectionQuotas.inc(socketChannel.socket().getInetAddress)</span><br><span class="line">    socketChannel.configureBlocking(<span class="literal">false</span>) <span class="comment">// socket设为非阻塞模式</span></span><br><span class="line">    socketChannel.socket().setTcpNoDelay(<span class="literal">true</span>) <span class="comment">// socket设置TCP_NODELAY选项, 禁止Nagle算法</span></span><br><span class="line">    socketChannel.socket().setKeepAlive(<span class="literal">true</span>) <span class="comment">// socket设置保活模式, 长时间没有发送心跳则发出RST包重置连接</span></span><br><span class="line">    <span class="comment">// 配置的 socket.send.buffer.bytes 不为默认值, 则设置 SO_SNDBUF 选项重置发送缓冲区大小</span></span><br><span class="line">    <span class="keyword">if</span> (sendBufferSize != <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>)</span><br><span class="line">      socketChannel.socket().setSendBufferSize(sendBufferSize)</span><br><span class="line"></span><br><span class="line">    processor.accept(socketChannel)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">TooManyConnectionsException</span> =&gt;</span><br><span class="line">      close(socketChannel)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>跟socket编程里一样的套路，只不过检查了同一个IP的最大连接数是否超限，并且给表示连接的socket设置了一些选项，然后实际上还是调用了<code>Processor.accept()</code>方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(socketChannel: <span class="type">SocketChannel</span>) &#123;</span><br><span class="line">  newConnections.add(socketChannel)</span><br><span class="line">  wakeup()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里就很简单了，把配置好的<code>SocketChannel</code>给加入<code>Processor</code>内部的并发队列<code>newConnections</code>中，其类型前一篇提过，是<code>ConcurrentLinkedQueue</code>。</p>
<h2 id="Acceptor-run-总结"><a href="#Acceptor-run-总结" class="headerlink" title="Acceptor.run()总结"></a>Acceptor.run()总结</h2><p>抛开一些程序设计上的细节性知识，其实<code>Acceptor</code>线程的逻辑就是：</p>
<ol>
<li>循环，从<code>Selector</code>中等待I&#x2F;O事件就绪；</li>
<li>遍历所有的I&#x2F;O事件，将<code>isAcceptable</code>的套接字取出，并调用socket的<code>accept()</code>取得新连接；</li>
<li>检查最大连接数，没超限的话进行一些socket选项配置；</li>
<li>将配置后的socket存入<code>Processor</code>的内部队列中。</li>
</ol>
<p>可以看到<code>Acceptor</code>仅仅做了中介的作用，它是直接和客户端的连接请求打交道的，将成功的连接处理后传递给<code>Processor</code>，这样<code>Processor</code>就可以专心去处理网络数据的读写。</p>
<p>另一方面，我们可以看到<code>Channel</code>（在这里是<code>SocketChannel</code>类）其实就是对socket句柄的封装。</p>
<h2 id="Processor-run"><a href="#Processor-run" class="headerlink" title="Processor.run()"></a>Processor.run()</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  startupComplete()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        configureNewConnections() <span class="comment">// 处理缓存的新连接</span></span><br><span class="line">        processNewResponses() <span class="comment">// 处理缓存的响应</span></span><br><span class="line">        poll() <span class="comment">// 轮询, 从 Selector 中获取准备好I/O的事件</span></span><br><span class="line">        <span class="comment">// 处理已完成的接收/发送以及断开的channels</span></span><br><span class="line">        processCompletedReceives()</span><br><span class="line">        processCompletedSends()</span><br><span class="line">        processDisconnected()</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// 这里吞下了所有异常, 因为让 processor 退出对 broker 的影响可能会很大, 但值得商榷的是,</span></span><br><span class="line">        <span class="comment">// 是否存在需要让整个 broker 停止的异常。</span></span><br><span class="line">        <span class="comment">// 通常抛出的异常都是和特定socket或者bad request相关的, 这些异常被捕获, 然后会被独立的方法处理, 因此不会在这里</span></span><br><span class="line">        <span class="comment">// 被捕获, 所以可能这里只会看到 ControlThrowable (仅仅是可见, 没有地方会抛出)</span></span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; processException(<span class="string">&quot;Processor got uncaught exception.&quot;</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// 将异常信息写入日志(略)</span></span><br><span class="line">    shutdownComplete()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>只用照着<code>try</code>作用域内的方法一个个地看下来就行。</p>
<h3 id="1-configureNewConnections"><a href="#1-configureNewConnections" class="headerlink" title="1. configureNewConnections"></a>1. configureNewConnections</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">configureNewConnections</span></span>() &#123;</span><br><span class="line">  <span class="keyword">while</span> (!newConnections.isEmpty) &#123;</span><br><span class="line">    <span class="comment">// newConnections的SocketChannel依次出队</span></span><br><span class="line">    <span class="keyword">val</span> channel = newConnections.poll()</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 调用链: selector.registerChannel =&gt; selector.buildAndAttachKafkaChannel =&gt; channelBuilder.buildChannel()</span></span><br><span class="line">      <span class="comment">// channel 会注册 OP_READ 事件(返回 SelectionKey)到 selector 上, 然后和 connectionId, SelectionKey 一起构造</span></span><br><span class="line">      <span class="comment">// KafkaChannel 对象, 以 connectionId 作为key组成键值对加入 selector.channels 中</span></span><br><span class="line">      selector.register(connectionId(channel.socket), channel)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// 捕获所有异常, 关闭 对应的socket防止socket泄漏</span></span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        close(channel)</span><br><span class="line">        <span class="comment">// 将异常信息写入日志(略)</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可见<code>Acceptor</code>仅仅将表示连接的<code>SocketChannel</code>交给<code>Processor</code>，而<code>Processor</code>则会为其注册读事件，同时交给<code>selector</code>管理时会将其包装为<code>KafkaChannel</code>，这个包装过程是由<code>ChannelBuilder</code>接口完成的，而接口指向的实际对象是在<code>Processor.createSelector()</code>中<code>ChannelBuilders.serverChannelBuilder()</code>方法创建的，对<code>PLAINTEXT</code>协议，即<code>PlaintextChannelBuilder</code>，其<code>buildChannel()</code>方法的调用和实现依次为：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// id: SocketChannel.connectionId</span></span><br><span class="line"><span class="comment">// key: SocketChannel.register() 返回的 SelectionKey</span></span><br><span class="line"><span class="comment">// maxReceiveSize: config.socketRequestMaxBytes, 即配置&quot;socket.request.max.bytes&quot;</span></span><br><span class="line"><span class="comment">// memoryPool: SocketServer.memoryPool</span></span><br><span class="line"><span class="type">KafkaChannel</span> channel = channelBuilder.buildChannel(id, key, maxReceiveSize, memoryPool);</span><br><span class="line">key.attach(channel);  <span class="comment">// key原本是attach之前的SocketChannel的, 现在改变attach的对象</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> KafkaChannel <span class="title function_">buildChannel</span><span class="params">(String id, SelectionKey key, <span class="type">int</span> maxReceiveSize, MemoryPool memoryPool)</span> <span class="keyword">throws</span> KafkaException &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">PlaintextTransportLayer</span> <span class="variable">transportLayer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PlaintextTransportLayer</span>(key);</span><br><span class="line">        <span class="type">PlaintextAuthenticator</span> <span class="variable">authenticator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PlaintextAuthenticator</span>(configs, transportLayer);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">KafkaChannel</span>(id, transportLayer, authenticator, maxReceiveSize,</span><br><span class="line">                memoryPool != <span class="literal">null</span> ? memoryPool : MemoryPool.NONE);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// 异常处理(略)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">PlaintextTransportLayer</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="built_in">this</span>.key = key;</span><br><span class="line">    <span class="built_in">this</span>.socketChannel = (SocketChannel) key.channel();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以发现<code>key</code>和<code>channel: SocketChannel</code>被存到了<code>KafkaChannel.transportLayer</code>字段中，因此在后面的源码中，给<code>KafkaChannel</code>注册和取消读&#x2F;写事件到<code>Selector</code>上时是使用<code>transportLayer</code>的<code>addInterestOps()</code>和<code>removeInterestOps()</code>方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addInterestOps</span><span class="params">(<span class="type">int</span> ops)</span> &#123;</span><br><span class="line">    key.interestOps(key.interestOps() | ops);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">removeInterestOps</span><span class="params">(<span class="type">int</span> ops)</span> &#123;</span><br><span class="line">    key.interestOps(key.interestOps() &amp; ~ops);</span><br><span class="line">   </span><br></pre></td></tr></table></figure>

<p>其实也就是调用了<code>SelectionKey</code>的<code>interestOps()</code>方法，不过包装了位运算<code>|</code>和<code>&amp;~</code>来表示添加和移除。</p>
<h3 id="2-processNewResponses"><a href="#2-processNewResponses" class="headerlink" title="2. processNewResponses"></a>2. processNewResponses</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processNewResponses</span></span>() &#123;</span><br><span class="line">  <span class="keyword">var</span> curr: <span class="type">RequestChannel</span>.<span class="type">Response</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">while</span> (&#123;curr = dequeueResponse(); curr != <span class="literal">null</span>&#125;) &#123;</span><br><span class="line">    <span class="comment">// 将响应从 responseQueue 中依次出队, 这里取得 connectionId 作为 channelId</span></span><br><span class="line">    <span class="keyword">val</span> channelId = curr.request.context.connectionId</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 根据响应的类型进行不同操作</span></span><br><span class="line">      curr.responseAction <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">NoOpAction</span> =&gt;</span><br><span class="line">          <span class="comment">// 无操作: 无需发送响应给客户端, 因此需要读取更多请求到服务端的socket buffer中</span></span><br><span class="line">          <span class="comment">// 调用链: selector.unmute() =&gt; channel.unmute()</span></span><br><span class="line">          <span class="comment">// 会将 channel 从 selector.explicitlyMutedChannels 中移除,</span></span><br><span class="line">          <span class="comment">// 如果该channel处于连接状态, 会在 channel.transportLayer 注册 OP_READ 事件。</span></span><br><span class="line">          updateRequestMetrics(curr)</span><br><span class="line">          trace(<span class="string">&quot;Socket server received empty response to send, registering for read: &quot;</span> + curr)</span><br><span class="line">          openOrClosingChannel(channelId).foreach(c =&gt; selector.unmute(c.id))</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">SendAction</span> =&gt;</span><br><span class="line">          <span class="comment">// 发送: 调用链为 sendResponse() =&gt; selector.send() =&gt; channel.setSend()</span></span><br><span class="line">          <span class="comment">// 将响应加入 inflightResponses 中, 并在 channel.transportLayer 注册 OP_WRITE 事件</span></span><br><span class="line">          <span class="keyword">val</span> responseSend = curr.responseSend.getOrElse(</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s&quot;responseSend must be defined for SendAction, response: <span class="subst">$curr</span>&quot;</span>))</span><br><span class="line">          sendResponse(curr, responseSend)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">CloseConnectionAction</span> =&gt;</span><br><span class="line">          <span class="comment">// 关闭连接： 关闭channel</span></span><br><span class="line">          updateRequestMetrics(curr)</span><br><span class="line">          trace(<span class="string">&quot;Closing socket connection actively according to the response code.&quot;</span>)</span><br><span class="line">          close(channelId)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// 将异常信息写入日志(略)</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，<code>Processor</code>仅仅是对缓存在<code>responseQueue</code>中的响应进行处理，但是从请求到响应的转换并不是它的工作，查找了<code>responseQueue</code>的使用地方，可以看到实际上响应是由<code>RequestChannel.sendResponse()</code>方法发送过来的，更上一层，是<code>KafkaApis.sendResponse()</code>方法调用该方法，因此实际上是<code>KafkaApis</code>（位于<code>kafka.server</code>包内）完成对请求的处理。</p>
<p>至于<code>updateRequestMetrics()</code>方法和异常处理的部分我们不再关心。</p>
<h3 id="3-poll"><a href="#3-poll" class="headerlink" title="3. poll"></a>3. poll</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">poll</span></span>() &#123;</span><br><span class="line">  <span class="comment">// 轮询300ms, 会将读取的请求/发送的响应/断开的连接，放入 selector 的 completeReceives/completedSends/disconnected</span></span><br><span class="line">  <span class="keyword">try</span> selector.poll(<span class="number">300</span>)</span><br><span class="line">  <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e @ (_: <span class="type">IllegalStateException</span> | _: <span class="type">IOException</span>) =&gt;</span><br><span class="line">      <span class="comment">// 不会重抛异常, 这样这次轮询的所有完成的 sends/receives/connections/disconnections 事件都会被处理</span></span><br><span class="line">      error(<span class="string">s&quot;Processor <span class="subst">$id</span> poll failed due to illegal state or IO exception&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>关键是<code>selector.poll()</code>方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">poll</span><span class="params">(<span class="type">long</span> timeout)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="keyword">if</span> (timeout &lt; <span class="number">0</span>) <span class="comment">// 检查参数合法性</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;timeout should be &gt;= 0&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">madeReadProgressLastCall</span> <span class="operator">=</span> madeReadProgressLastPoll;</span><br><span class="line">    clear(); <span class="comment">// 清理前1次 poll() 中设置的一些字段 (理应在此2次 poll() 之间对它们全部进行处理)</span></span><br><span class="line"></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">dataInBuffers</span> <span class="operator">=</span> !keysWithBufferedRead.isEmpty();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在以下情形时将timeout置为0 (代表已经有一些Channel I/O就绪了, select()会立刻返回)</span></span><br><span class="line">    <span class="comment">// 1. 已经有一些接收数据的 Channel 在上一次 poll() 中读了一些数据;</span></span><br><span class="line">    <span class="comment">// 2. 有可连接但暂为完成连接的 Channels;</span></span><br><span class="line">    <span class="comment">// 3. 上次有 Channel 进行了 read() 操作, 并且 Channel 本身缓存了数据.</span></span><br><span class="line">    <span class="comment">// 最后一种情况比较特殊, 它发生的场景是某些 Channels 有数据在中间缓冲区中但却无法读取(比如因为内存不足)</span></span><br><span class="line">    <span class="keyword">if</span> (hasStagedReceives() || !immediatelyConnectedKeys.isEmpty() || (madeReadProgressLastCall &amp;&amp; dataInBuffers))</span><br><span class="line">        timeout = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 若之前内存池内存耗尽, 而现在又可用了, 将一些因为内存压力而暂时取消读事件的 Channel 重新注册读事件</span></span><br><span class="line">    <span class="keyword">if</span> (!memoryPool.isOutOfMemory() &amp;&amp; outOfMemory) &#123;</span><br><span class="line">        log.trace(<span class="string">&quot;Broker no longer low on memory - unmuting incoming sockets&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (KafkaChannel channel : channels.values()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (channel.isInMutableState() &amp;&amp; !explicitlyMutedChannels.contains(channel)) &#123;</span><br><span class="line">                channel.unmute();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        outOfMemory = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查 I/O就绪 的keys, 记录 select() 用时</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">startSelect</span> <span class="operator">=</span> time.nanoseconds();</span><br><span class="line">    <span class="type">int</span> <span class="variable">numReadyKeys</span> <span class="operator">=</span> select(timeout);</span><br><span class="line">    <span class="type">long</span> <span class="variable">endSelect</span> <span class="operator">=</span> time.nanoseconds();</span><br><span class="line">    <span class="built_in">this</span>.sensors.selectTime.record(endSelect - startSelect, time.milliseconds());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 存在 I/O就绪 的Channels; 2和3 参见之前将 timeout = 0 部分的注释</span></span><br><span class="line">    <span class="keyword">if</span> (numReadyKeys &gt; <span class="number">0</span> || !immediatelyConnectedKeys.isEmpty() || dataInBuffers) &#123;</span><br><span class="line">        Set&lt;SelectionKey&gt; readyKeys = <span class="built_in">this</span>.nioSelector.selectedKeys();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Poll 有缓存数据的 Channels (但不Poll底层socket有缓存数据的Channels)</span></span><br><span class="line">        <span class="keyword">if</span> (dataInBuffers) &#123;</span><br><span class="line">            keysWithBufferedRead.removeAll(readyKeys); <span class="comment">//so no channel gets polled twice</span></span><br><span class="line">            Set&lt;SelectionKey&gt; toPoll = keysWithBufferedRead;</span><br><span class="line">            keysWithBufferedRead = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(); <span class="comment">//poll() calls will repopulate if needed</span></span><br><span class="line">            pollSelectionKeys(toPoll, <span class="literal">false</span>, endSelect);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Poll 底层 socket 有缓存数据的 Channels</span></span><br><span class="line">        pollSelectionKeys(readyKeys, <span class="literal">false</span>, endSelect);</span><br><span class="line">        readyKeys.clear();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Poll 待连接的 Channels</span></span><br><span class="line">        pollSelectionKeys(immediatelyConnectedKeys, <span class="literal">true</span>, endSelect);</span><br><span class="line">        immediatelyConnectedKeys.clear();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        madeReadProgressLastPoll = <span class="literal">true</span>; <span class="comment">//no work is also &quot;progress&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">long</span> <span class="variable">endIo</span> <span class="operator">=</span> time.nanoseconds();</span><br><span class="line">    <span class="built_in">this</span>.sensors.ioTime.record(endIo - endSelect, time.milliseconds());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 利用 select() 结束时刻保证我们不会关闭刚刚传进 pollSelectionKeys() 的连接 (避免将其识别未过期连接)</span></span><br><span class="line">    maybeCloseOldestConnection(endSelect);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在关闭过期连接后, 将完成接收的 Channels 加入 completedReceives.</span></span><br><span class="line">    addToCompletedReceives();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这部分继续深究的话比较复杂，Kafka在这方面考虑了不少，上述分析中对一些字段也只是简单地提了下，到此为止。总之，最重要的是直到<code>poll()</code>会填充<code>Selector</code>内部维护的<strong>已完成接收</strong>&#x2F;<strong>已完成发送</strong>&#x2F;<strong>已断开</strong>的<code>Channel</code>，以便之后处理。</p>
<p>PS：在处理完成的发送时，在调用<code>send()</code>向socket写入数据的同时取消监听对应<code>Channel</code>的<code>OP_WRITE</code>事件：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 类 KafkaChannel</span></span><br><span class="line"><span class="comment">// 调用链: Selector.PollSelectionKeys() =&gt; write() =&gt; send()</span></span><br><span class="line"><span class="keyword">private</span> boolean send(<span class="type">Send</span> send) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">    send.writeTo(transportLayer);</span><br><span class="line">    <span class="keyword">if</span> (send.completed())</span><br><span class="line">        transportLayer.removeInterestOps(<span class="type">SelectionKey</span>.<span class="type">OP_WRITE</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> send.completed();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-processCompletedReceives"><a href="#4-processCompletedReceives" class="headerlink" title="4.  processCompletedReceives"></a>4.  processCompletedReceives</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processCompletedReceives</span></span>() &#123;</span><br><span class="line">  <span class="comment">// 遍历所有完成接收的 NetworkService, 具体实现在 selector.poll() 方法中, 最后会调用 addToCompletedReceives()</span></span><br><span class="line">  <span class="comment">// 如果 channel 不在 explicitlyMutedChannels 中 (即调用了unmute()方法), 则会将 channel 对应的 NetworkService 队列</span></span><br><span class="line">  <span class="comment">// 弹出队首并加入 completedReceives 中。</span></span><br><span class="line"> selector.completedReceives.asScala.foreach &#123; receive =&gt;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// NetworkServer 的 source 字段记录了连接channel的 connectionId</span></span><br><span class="line">      openOrClosingChannel(receive.source) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(channel) =&gt;</span><br><span class="line">          <span class="comment">// 解析 payload (接收到的ByteBuffer)的头部</span></span><br><span class="line">          <span class="keyword">val</span> header = <span class="type">RequestHeader</span>.parse(receive.payload)</span><br><span class="line">          <span class="comment">// 将其与 channel 的会话层信息封装成 RequestContext</span></span><br><span class="line">          <span class="keyword">val</span> context = <span class="keyword">new</span> <span class="type">RequestContext</span>(header, receive.source, channel.socketAddress,</span><br><span class="line">            channel.principal, listenerName, securityProtocol)</span><br><span class="line">          <span class="comment">// 进一步将上述信息封装成 Request 对象</span></span><br><span class="line">          <span class="keyword">val</span> req = <span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Request</span>(processor = id, context = context,</span><br><span class="line">            startTimeNanos = time.nanoseconds, memoryPool, receive.payload, requestChannel.metrics)</span><br><span class="line">          <span class="comment">// 这里仅仅是将 req 放入 requestChannel 的内部队列 requestQueue</span></span><br><span class="line">          requestChannel.sendRequest(req)</span><br><span class="line">          <span class="comment">// 取消监听该channel的 OP_READ 事件, 并添加到 explicitlyMutedChannels</span></span><br><span class="line">          selector.mute(receive.source)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">          <span class="comment">// 抛出异常(略)</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// 异常处理(略)</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-processCompleteSends"><a href="#4-processCompleteSends" class="headerlink" title="4. processCompleteSends"></a>4. processCompleteSends</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processCompletedSends</span></span>() &#123;</span><br><span class="line">  <span class="comment">// 遍历所有完成发送的 NetworkService, 具体实现在 selector.poll() 方法中</span></span><br><span class="line">  selector.completedSends.asScala.foreach &#123; send =&gt;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 将该网络地址的响应从 inflightResponses 中移除</span></span><br><span class="line">      <span class="keyword">val</span> resp = inflightResponses.remove(send.destination).getOrElse &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s&quot;Send for <span class="subst">$&#123;send.destination&#125;</span> completed, but not in `inflightResponses`&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      updateRequestMetrics(resp)</span><br><span class="line">      <span class="comment">// 将对应的 channel 从 explicitlyMutedChannels 中移除, 并且如果未断开连接, 则注册 OP_READ 事件</span></span><br><span class="line">      selector.unmute(send.destination)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// 异常处理(略)</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-processDisconnected"><a href="#5-processDisconnected" class="headerlink" title="5. processDisconnected"></a>5. processDisconnected</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processDisconnected</span></span>() &#123;</span><br><span class="line">  <span class="comment">// 遍历所有断开连接的channel的 connectionId, 具体实现在 selector.poll() 方法中</span></span><br><span class="line">  selector.disconnected.keySet.asScala.foreach &#123; connectionId =&gt;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 从 connectionId 中取得网络地址信息</span></span><br><span class="line">      <span class="keyword">val</span> remoteHost = <span class="type">ConnectionId</span>.fromString(connectionId).getOrElse &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s&quot;connectionId has unexpected format: <span class="subst">$connectionId</span>&quot;</span>)</span><br><span class="line">      &#125;.remoteHost</span><br><span class="line">      <span class="comment">// 将断开连接的网络地址的响应从 inflightResponses 中移除</span></span><br><span class="line">      inflightResponses.remove(connectionId).foreach(updateRequestMetrics)</span><br><span class="line">      <span class="comment">// the channel has been closed by the selector but the quotas still need to be updated</span></span><br><span class="line">      <span class="comment">// 更新 quotas 的信息, 即将该网络地址上的连接数减1</span></span><br><span class="line">      connectionQuotas.dec(<span class="type">InetAddress</span>.getByName(remoteHost))</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// 异常处理(略)</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Processor-run-总结"><a href="#Processor-run-总结" class="headerlink" title="Processor.run()总结"></a>Processor.run()总结</h2><p><code>Processor</code>使用了Kafka自己实现的<code>Selector</code>（别名为<code>KSelector</code>），比<code>Acceptor</code>使用的NIO默认的<code>Selector</code>（别名为<code>NSelector</code>）有更多的功能，因为<code>Processor</code>要维护监听socket的读&#x2F;写事件状态，即<code>OP_READ</code>和<code>OP_WRITE</code>。</p>
<p>一些具体的实现在<code>org.apache.kafka.common</code>的<code>network</code>包和<code>request</code>包中（Java实现），这里暂时不细看。</p>
<p>归结其流程为：</p>
<ol>
<li>从将<code>Acceptor</code>收到的新连接全部注册<code>OP_READ</code>事件，因为Kafka服务端不主动向客户端发送请求，只被动响应客户端的请求；</li>
<li>根据响应类型处理缓存的响应：<code>NoOpAction</code>&#x3D;&gt;重新注册<code>Channel</code>的读事件，<code>SendAction</code>&#x3D;&gt;注册<code>Channel</code>的写事件，将响应缓存，并交由<code>RequestChannel</code>发送，<code>CloseConnectionAction</code>&#x3D;&gt;关闭<code>Channel</code>；</li>
<li>轮询<code>Selector</code>得到就绪的I&#x2F;O事件（可读&#x2F;可写&#x2F;断开）；</li>
<li>对所有完成接收的数据（请求），封装后给<code>RequestChannel</code>发送；</li>
<li>对所有完成发送的数据（响应），从缓存中移除，并重新监听对应<code>Channel</code>的读事件；</li>
<li>对所有断开的连接，更新<code>connectionQuotas</code>维护的网络地址&#x3D;&gt;连接数的映射。</li>
</ol>
<p><code>Processor</code>本身只是做完成读&#x2F;写&#x2F;断开三种事件的处理，发送和接收实际上都是通过<code>RequestChannel</code>。至于<code>Processor</code>是由<code>SocketServer.newProcessor()</code>方法创建的，其内部的<code>requestChannel</code>字段就是<code>SocketServer</code>的同名字段。</p>
<p>因此，接下来就是阅读<code>RequestChannel</code>。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/09/20/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB02-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8BAcceptor%E5%92%8CProcessor/" data-id="cl1qn407v002z4c1uh197acj8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Kafka源码阅读01-网络层阅读之服务器的启动" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/09/18/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB01-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%90%AF%E5%8A%A8/" class="article-date">
  <time datetime="2019-09-18T11:47:06.000Z" itemprop="datePublished">2019-09-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/18/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB01-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%90%AF%E5%8A%A8/">Kafka源码阅读01: 网络层阅读之服务器的启动</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天正式开始阅读Kafka源码，作为阅读笔记的第一篇，先简单地介绍下背景。</p>
<p>阅读的Kafka版本是1.1.0，服务端源码在<code>core.main.scala.kafka</code>目录下，该目录下的源码文件仅有<code>Kafka.scala</code>，也就是服务端的启动入口，其他的若干个模块都阻止在各子目录下，这里首先阅读的是网络层，也就是<code>network</code>子目录下的代码。</p>
<p>阅读思路是直接看公用方法，然后再给一些逻辑以及用到的字段作注释，否则单看某些字段不看语境也不知道做什么。注释里会给英文两边加空格，逗号也使用英文逗号，方便vim快捷键按词前进&#x2F;后退。</p>
<p>使用Intellij Idea阅读的，之前用得比较少，也很折腾了下配置过程，记录一些阅读源码的方法：</p>
<ul>
<li>光标选中+单击鼠标左键：跳转至变量&#x2F;函数定义处；</li>
<li>Navigate菜单栏的Back和Forward，快捷键是<code>Ctrl+Alt+Left/Right</code>：后退&#x2F;前进到前&#x2F;后一次阅读的地方，一般时配合跳转功能回退；</li>
<li>光标选中+鼠标右键，选择Find Usages，快捷键是<code>Alt+Shift+F7</code>：查看变量&#x2F;函数所有使用的地方；</li>
<li>快捷键<code>Alt+F7</code>：查看类的所有字段和方法。</li>
</ul>
<p>对应我阅读C&#x2F;C++源码时vim的<code>Ctrl+J</code>（<code>YCM</code>）&#x2F;<code>Ctrl+]</code>（<code>ctags</code>）跳转，<code>Ctrl+O</code>回退，<code>LeaderF</code>查看类的字段和方法。之前vim一直没配置查找所有调用处的功能，一直是手动写个简单脚本用<code>egrep</code>在当前目录下递归搜关键词的……</p>
<p>不过IDE优点就是功能更大更全，上手新语言时直接使用，不必每接触一门语言旧学习怎么定制功能。</p>
<h2 id="SocketServer"><a href="#SocketServer" class="headerlink" title="SocketServer"></a>SocketServer</h2><p>注释表明了它是一个NIO套接字服务器，其线程模型是：</p>
<ul>
<li>1个Acceptor线程处理新连接；</li>
<li>Acceptor有N个Processor线程，其中每个都有自己的Selector从套接字中读取请求；</li>
<li>M个Handler线程，处理请求，并将回应发给Processor线程用于写入。</li>
</ul>
<p><code>SocketServer</code>的主构造器有以下参数：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> config: <span class="type">KafkaConfig</span> <span class="comment">// 配置文件</span></span><br><span class="line"><span class="keyword">val</span> metric: <span class="type">Metrics</span> <span class="comment">// 度量指标</span></span><br><span class="line"><span class="keyword">val</span> time: <span class="type">Time</span> <span class="comment">// 对象创建时间</span></span><br><span class="line"><span class="keyword">val</span> credentialProvider: <span class="type">CredentialProvider</span> <span class="comment">// 证书提供者</span></span><br></pre></td></tr></table></figure>

<p>混入了<code>Logging</code>和<code>KafkaMetricsGroup</code>特质，后者继承自前者，但并没重写<code>info()</code>等日志方法，而是将不同类型的metric（度量指标）给组织起来，提供了各种metric的工厂方法。</p>
<p>对于日志，设置了类相关的前缀表明broker id：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> logContext = <span class="keyword">new</span> <span class="type">LogContext</span>(<span class="string">s&quot;[SocketServer brokerId=<span class="subst">$&#123;config.brokerId&#125;</span>] &quot;</span>)</span><br><span class="line"><span class="keyword">this</span>.logIdent = logContext.logPrefix</span><br></pre></td></tr></table></figure>

<p>涉及到的一些字段，我添上了注释并按相关度整合了下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 每个ip的最大连接数, 配置: max.connections.per.ip</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> maxConnectionsPerIp = config.maxConnectionsPerIp</span><br><span class="line"><span class="comment">// 指定ip的最大连接数, 会覆盖 maxConnectionsPerIp, 配置: max.connections.per.ip.overrides</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> maxConnectionsPerIpOverrides = config.maxConnectionsPerIpOverrides</span><br><span class="line"><span class="comment">// 由以上参数创建</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> connectionQuotas: <span class="type">ConnectionQuotas</span> = _</span><br><span class="line"></span><br><span class="line"><span class="comment">// 请求队列的最大容量, 配置: queued.max.requests</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> maxQueuedRequests = config.queuedMaxRequests</span><br><span class="line"><span class="comment">// 内部维护了一个请求队列</span></span><br><span class="line"><span class="keyword">val</span> requestChannel = <span class="keyword">new</span> <span class="type">RequestChannel</span>(maxQueuedRequests)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 每个 Processor 拥有自己的 Selector, 用于从连接中读取请求和写回响应</span></span><br><span class="line"><span class="comment">// Processor 会将请求发送至 requestChannel, 会从 responseChannels 中读取响应</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> processors = <span class="keyword">new</span> <span class="type">ConcurrentHashMap</span>[<span class="type">Int</span>, <span class="type">Processor</span>]() <span class="comment">// key: id</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> nextProcessorId = <span class="number">0</span> <span class="comment">// 递增作为每个 processor 的id</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// key: EndPoint, 即配置 listeners 指定的 ip/port 以及其 SecurityProtocol (默认PLAINTEXT)</span></span><br><span class="line"><span class="comment">// 对每个绑定的 ip/port 都创建唯一对应的 Acceptor, 用于创建连接 Channel</span></span><br><span class="line"><span class="comment">// PS: 该字段在 network包 内可访问，实际上目前也就这个类会访问。</span></span><br><span class="line"><span class="keyword">private</span>[network] <span class="keyword">val</span> acceptors = <span class="keyword">new</span> <span class="type">ConcurrentHashMap</span>[<span class="type">EndPoint</span>, <span class="type">Acceptor</span>]()</span><br></pre></td></tr></table></figure>

<h2 id="服务器启动源码分析"><a href="#服务器启动源码分析" class="headerlink" title="服务器启动源码分析"></a>服务器启动源码分析</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">  <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">    <span class="comment">// connectionQuotas 用于限制IP的最大连接数</span></span><br><span class="line">    connectionQuotas = <span class="keyword">new</span> <span class="type">ConnectionQuotas</span>(maxConnectionsPerIp, maxConnectionsPerIpOverrides)</span><br><span class="line">    <span class="comment">// 创建 Acceptors 和 Processors</span></span><br><span class="line">    createAcceptorAndProcessors(config.numNetworkThreads, config.listeners)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 忽略了剩下的代码, 都是调用 KafkaMetricsGroup.newGauge 创建 Gauge对象, </span></span><br><span class="line">  <span class="comment">// 用于测量某些指标, 比如Processor的平均闲置百分比/内存池可用大小/内存池占用大小</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再看看 Acceptor 和 Processor 的创建：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createAcceptorAndProcessors</span></span>(processorsPerListener: <span class="type">Int</span>,</span><br><span class="line">                                        endpoints: <span class="type">Seq</span>[<span class="type">EndPoint</span>]): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// socket内部缓冲区大小，底层可用C函数 setsockopt 设置 SO_SNDBUF/SO_RCVBUF</span></span><br><span class="line">  <span class="keyword">val</span> sendBufferSize = config.socketSendBufferBytes <span class="comment">// socket.send.buffer.bytes</span></span><br><span class="line">  <span class="keyword">val</span> recvBufferSize = config.socketReceiveBufferBytes <span class="comment">// socket.receive.buffer.bytes</span></span><br><span class="line">  <span class="keyword">val</span> brokerId = config.brokerId <span class="comment">// broker.id</span></span><br><span class="line"></span><br><span class="line">  endpoints.foreach &#123; endpoint =&gt;</span><br><span class="line">    <span class="keyword">val</span> listenerName = endpoint.listenerName</span><br><span class="line">    <span class="keyword">val</span> securityProtocol = endpoint.securityProtocol</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> acceptor = <span class="keyword">new</span> <span class="type">Acceptor</span>(endpoint, sendBufferSize, recvBufferSize, brokerId, connectionQuotas)</span><br><span class="line">    <span class="type">KafkaThread</span>.nonDaemon(<span class="string">s&quot;kafka-socket-acceptor-<span class="subst">$listenerName</span>-<span class="subst">$securityProtocol</span>-<span class="subst">$&#123;endpoint.port&#125;</span>&quot;</span>, acceptor).start()</span><br><span class="line">    acceptor.awaitStartup() <span class="comment">// 等待acceptor线程完全启动</span></span><br><span class="line">    acceptors.put(endpoint, acceptor) <span class="comment">// 构建键值对 &lt;EndPoint, Acceptor&gt; 加入 acceptors</span></span><br><span class="line">    <span class="comment">// 单个 Acceptor 对应 processorsPerListener(即numNetworkThreads)个 Processors</span></span><br><span class="line">    addProcessors(acceptor, endpoint, processorsPerListener)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对每个<code>Acceptor</code>，会创建多个<code>Processor</code>，类似地，也存入<code>ConcurrentHashMap</code>中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">addProcessors</span></span>(acceptor: <span class="type">Acceptor</span>, endpoint: <span class="type">EndPoint</span>, newProcessorsPerListener: <span class="type">Int</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  <span class="keyword">val</span> listenerName = endpoint.listenerName</span><br><span class="line">  <span class="keyword">val</span> securityProtocol = endpoint.securityProtocol</span><br><span class="line">  <span class="keyword">val</span> listenerProcessors = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Processor</span>]()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (_ &lt;- <span class="number">0</span> until newProcessorsPerListener) &#123;</span><br><span class="line">    <span class="keyword">val</span> processor = newProcessor(nextProcessorId, connectionQuotas, listenerName, securityProtocol, memoryPool)</span><br><span class="line">    listenerProcessors += processor</span><br><span class="line">    <span class="comment">// 内部调用了 putIfAbsent() 方法将其加入了 requestChannel 内部维护的 ConcurrentHashMap[Int, Processor],</span></span><br><span class="line">    <span class="comment">// key为 processor.id, 使用 putIfAbsent() 方法是因为理论上 processer.id 是唯一的, 因此在插入重复的id时,</span></span><br><span class="line">    <span class="comment">// 不应插入新对象, 而是仅仅返回一个非空 Processor 并根据返回值打印日志</span></span><br><span class="line">    requestChannel.addProcessor(processor)</span><br><span class="line">    <span class="comment">// 仅在此递增 SocketServer 的 nextProcessId 字段，因此保证了对不同 Acceptor 的 Processors,</span></span><br><span class="line">    <span class="comment">// 其 id 是不同的，因此每个 Processor 在 processors 字段中都对应唯一的 key</span></span><br><span class="line">    nextProcessorId += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  listenerProcessors.foreach(p =&gt; processors.put(p.id, p))</span><br><span class="line">  <span class="comment">// 启动 listenerProcessors 的所有 Processor 线程, 并将其添加到内部维护的 processor: ArrayBuffer[Processor] 中</span></span><br><span class="line">  acceptor.addProcessors(listenerProcessors)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="RequestChannel-x2F-Acceptor-x2F-Processor的字段"><a href="#RequestChannel-x2F-Acceptor-x2F-Processor的字段" class="headerlink" title="RequestChannel&#x2F;Acceptor&#x2F;Processor的字段"></a>RequestChannel&#x2F;Acceptor&#x2F;Processor的字段</h2><p>从上述代码可知，重点是<code>RequestChannel</code>&#x2F;<code>Acceptor</code>&#x2F;<code>Processor</code>这3个类型，于是现在看看它们创建时除去传入构造器的参数外初始化的其他字段（依然忽略metrics相关的）。</p>
<p>首先是<code>RequestChannel</code>的字段：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建了固定长度的请求队列，queueSize由 queued.max.requests 决定</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> requestQueue = <span class="keyword">new</span> <span class="type">ArrayBlockingQueue</span>[<span class="type">BaseRequest</span>](queueSize)</span><br><span class="line"><span class="comment">// 之前已经提过，创建 Processors 时添加进的</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> processors = <span class="keyword">new</span> <span class="type">ConcurrentHashMap</span>[<span class="type">Int</span>, <span class="type">Processor</span>]()</span><br></pre></td></tr></table></figure>

<p>此外，配置是使用<code>kafka.server.KafkaConfig</code>类实现的，默认配置在伴生对象<code>kafka.server.Defaults</code>中（比如默认的<code>queueSize</code>为500），并在<code>KafkaConfig</code>的伴生对象的<code>configDef</code>字段创建时加载。</p>
<p>再就是<code>Acceptor</code>的字段：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NIO Selector, 用于注册 connect, read, write 等事件，并将事件分发给 Acceptor, Processors</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> nioSelector = <span class="type">NSelector</span>.open()</span><br><span class="line"><span class="comment">// 服务通道, 绑定 EndPoint, 用于接收客户端的连接, 类型为 ServerSocketChannel</span></span><br><span class="line"><span class="keyword">val</span> serverChannel = openServerSocket(endPoint.host, endPoint.port)</span><br><span class="line"><span class="comment">// 之前提过的，保存每个 Acceptor 对应的 Processors, 没有存为映射, 因为 Acceptor 要将</span></span><br><span class="line"><span class="comment">// 连接均衡地分配给 Processors, 不涉及查询操作, 更多地需要遍历, 比如round-robin算法</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> processors = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Processor</span>]()</span><br></pre></td></tr></table></figure>

<p>其中 <code>NSelector</code> 就是 <code>Selector</code> 的别名：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.nio.channels.&#123;<span class="type">Selector</span> =&gt; <span class="type">NSelector</span>&#125;</span><br></pre></td></tr></table></figure>

<p>最后是<code>Processor</code>的字段：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// SocketChannel 的并发队列, 用于管理 Acceptor 分配的socket连接</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> newConnections = <span class="keyword">new</span> <span class="type">ConcurrentLinkedQueue</span>[<span class="type">SocketChannel</span>]()</span><br><span class="line"><span class="comment">// ConnectionId 到 Response 的映射, 缓存待发送的响应</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> inflightResponses = mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">RequestChannel</span>.<span class="type">Response</span>]()</span><br><span class="line"><span class="comment">// 缓存产生的响应</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> responseQueue = <span class="keyword">new</span> <span class="type">LinkedBlockingDeque</span>[<span class="type">RequestChannel</span>.<span class="type">Response</span>]()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建的是 kafka.common.network.Selector, 也就是自己实现的 Selector</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> selector = createSelector(</span><br><span class="line">  <span class="type">ChannelBuilders</span>.serverChannelBuilder(listenerName,</span><br><span class="line">    listenerName == config.interBrokerListenerName,</span><br><span class="line">    securityProtocol,</span><br><span class="line">    config,</span><br><span class="line">    credentialProvider.credentialCache,</span><br><span class="line">    credentialProvider.tokenCache))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于生成连接的 index, 类似 SocketServer 生成 Processor.id, 不过保证了 index 非负</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> nextConnectionIndex = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>不得不说这里为何要使用 <code>ConcurrentLinkedQueue</code> 和 <code>LinkedBlockingDeque</code> 还是不清楚，但还是先不要在意细节，注意这里保存了2份<code>Response</code>，一个只是临时缓存处理后的响应，另一个则是真正待发送的响应，因为用key记录了连接信息：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 作为 inflightResponses 的key, 记录了本地地址/远程地址, 以及连接对应的索引</span></span><br><span class="line"><span class="comment">// 该索引是通过 nextConnectionIndex 自增生成的, 而且非负</span></span><br><span class="line"><span class="keyword">private</span>[network] <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">ConnectionId</span>(<span class="params">localHost: <span class="type">String</span>, localPort: <span class="type">Int</span>, remoteHost: <span class="type">String</span>, remotePort: <span class="type">Int</span>, index: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span></span>: <span class="type">String</span> = <span class="string">s&quot;<span class="subst">$localHost</span>:<span class="subst">$localPort</span>-<span class="subst">$remoteHost</span>:<span class="subst">$remotePort</span>-<span class="subst">$index</span>&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="服务器启动总结"><a href="#服务器启动总结" class="headerlink" title="服务器启动总结"></a>服务器启动总结</h2><p>总结下来，启动<code>SocketServer</code>时其实就是根据配置参数创建了1个<code>RequestChannel</code>，M个<code>Acceptor</code>，M*N个<code>Processor</code>。其中M是监听地址的数量，N是<code>num.network.thread</code>配置的Acceptor对应的Processors的数量。</p>
<p>每个监听地址除了ip和port外，还有协议类型和名称，这些共同组成了<code>EndPoint</code>类。</p>
<ul>
<li><code>SocketServer</code>保存<code>EndPoint</code>到<code>Acceptor</code>的映射和<code>Processor.id</code>到<code>Processor</code>的映射；</li>
<li><code>requestChannel</code>持有M*N个<code>Processor</code>的<code>id</code>到其自身的映射；</li>
<li>每个<code>Acceptor</code>持有1个<code>Selector</code>；</li>
<li>每个<code>Acceptor</code>持有1个监听<code>EndPoint</code>的<code>ServerSocketChannel</code>；</li>
<li>每个<code>Acceptor</code>持有N个<code>Processor</code>组成的数组；</li>
<li>每个 <code>Processor</code> 持有1个<code>Selector</code>（Kafka自己实现的<code>Selectable</code>接口）；</li>
<li>每个<code>Processor</code>持有一组socket连接；</li>
<li><code>acceptors</code>和<code>processors</code>都启动了线程（供<code>M*(N+1)</code>个）构成了整个网络层的处理。</li>
</ul>
<p>Kafka的网络层是使用Reactor模式的，使用了Java NIO，所有的socket读写都是非阻塞模式，具体框架可以参考《Apacha Kafka源码剖析》一书，我目前也是照着这本书的思路去看源码。</p>
<p>不过对Java NIO不熟悉，虽然看了眼核心还是分发事件的<code>Selector</code>（I&#x2F;O多路复用），但是封装得比较好。抽空去看看。</p>
<p>网络层运转的核心还是<code>Acceptor</code>和<code>Processor</code>的线程函数，也就是这2个类的<code>run()</code>方法，也是接下来要读的部分。</p>
<h2 id="为什么使用ConcurrentHashMap？"><a href="#为什么使用ConcurrentHashMap？" class="headerlink" title="为什么使用ConcurrentHashMap？"></a>为什么使用ConcurrentHashMap？</h2><p>《Apacha Kafka源码剖析》书中使用的是Kafka 0.10.0.1版本，其中<code>acceptors</code>和<code>processors</code>的类型是：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> processors = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Processor</span>](totalProcessorThreads)</span><br><span class="line"><span class="keyword">private</span>[network] <span class="keyword">val</span> acceptors = mutable.<span class="type">Map</span>[<span class="type">EndPoint</span>, <span class="type">Acceptor</span>]()</span><br></pre></td></tr></table></figure>

<p>而1.1.0版本就都用<code>ConcurrentHashMap</code>来保存了，看源码时我也在想为什么不用数组去存processors，因为key就是从0到N-1。搜了下这个结构在Java 8用了不同于7的实现，抽空去看看。</p>
<p>然后看到了<code>addListeners</code>&#x2F;<code>removeListeners</code>方法，前者根据新的<code>Seq[EndPoint]</code>重新创建<code>acceptors</code>和<code>processors</code>，后者则将指定的<code>Seq[EndPoint]</code>对应的<code>Acceptor</code>从<code>acceptors</code>中删除。而这两个方法在0.10.0.1版本中没有，所以就能用固定长度的数组来保存<code>processors</code>，也能用不支持并发访问的<code>mutable.Map</code>来保存<code>acceptors</code>。</p>
<p>不过还有个不明白的地方，看到直接访问<code>acceptors</code>和<code>processors</code>的都是<code>SocketServer</code>内部，而除了<code>boundPort()</code>方法和<code>stopProcessingRequests()</code>外，所在访问它们的方法都直接用<code>synchronized</code>关键字保护了，而<code>boundPort()</code>方法仅在<code>xxxTest.scala</code>中被调用了，这样的话使用<code>ConcurrentHashMap</code>是否必要？</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/09/18/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB01-%E7%BD%91%E7%BB%9C%E5%B1%82%E9%98%85%E8%AF%BB%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%90%AF%E5%8A%A8/" data-id="cl1qn406x00084c1u8e396poz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-链接选项RPATH以及在cmake和gcc中的使用" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/09/05/%E9%93%BE%E6%8E%A5%E9%80%89%E9%A1%B9RPATH%E4%BB%A5%E5%8F%8A%E5%9C%A8cmake%E5%92%8Cgcc%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/" class="article-date">
  <time datetime="2019-09-04T17:12:42.000Z" itemprop="datePublished">2019-09-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/05/%E9%93%BE%E6%8E%A5%E9%80%89%E9%A1%B9RPATH%E4%BB%A5%E5%8F%8A%E5%9C%A8cmake%E5%92%8Cgcc%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/">链接选项RPATH以及在cmake和gcc中的使用</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>注：此文已作废，本文存在若干事实性错误以及误导，在<a target="_blank" rel="noopener" href="https://bewaremypower.github.io//2020/07/14/%E9%93%BE%E6%8E%A5%E9%80%89%E9%A1%B9-rpath-%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%8E%9F%E7%90%86/">最新一篇文章</a>中将重新说明。</p>
<hr>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>毕业前帮师兄写框架程序时，以及最近折腾公司内部项目的编译，都遇到一些以前没有遇到的问题，这里简单地记一些。</p>
<p>本文要讲的也就是 <code>rpath</code> ，即 relative path 的缩写，最初遇到这个坑时是在写 <code>cmake</code> 时，直接 <code>make</code> 生成的程序能够链接到指定的动态库，但是 <code>make install</code> 之后发现就链接失效了。</p>
<h2 id="示例项目"><a href="#示例项目" class="headerlink" title="示例项目"></a>示例项目</h2><p>这里举个简单的例子来复现，目录结构为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ tree .</span><br><span class="line">.</span><br><span class="line">├── CMakeLists.txt</span><br><span class="line">├── example</span><br><span class="line">│   ├── CMakeLists.txt</span><br><span class="line">│   └── main.c</span><br><span class="line">└── src</span><br><span class="line">    ├── CMakeLists.txt</span><br><span class="line">    ├── foo.c</span><br><span class="line">    └── foo.h</span><br></pre></td></tr></table></figure>

<p>代码组织方式是： <code>src</code> 目录为库目录，其源码会编译成动态库 <code>libfoo.so</code>，<code>example</code> 为示例目录，其源码会包含 <code>src</code> 目录的头文件，并链接到动态库 <code>libfoo.so</code> 。具体代码也不长，依次贴出：</p>
<p><code>./CMakeLists.txt</code>：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.5</span>)</span><br><span class="line"><span class="keyword">project</span>(example C)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CFLAGS -g -Wall)</span><br><span class="line"><span class="keyword">add_subdirectory</span>(src)</span><br><span class="line"><span class="keyword">add_subdirectory</span>(example)</span><br></pre></td></tr></table></figure>

<p><code>./src/CMakeLists.txt</code>：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_library</span>(foo SHARED foo.c)</span><br><span class="line"><span class="keyword">install</span>(TARGETS foo LIBRARY DESTINATION lib)</span><br></pre></td></tr></table></figure>

<p><code>./src/foo.h</code>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> FOO_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> FOO_H</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">// FOO_H</span></span></span><br></pre></td></tr></table></figure>

<p><code>./src/foo.c</code>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;foo.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">()</span> &#123; <span class="built_in">printf</span>(<span class="string">&quot;foo\n&quot;</span>); &#125;</span><br></pre></td></tr></table></figure>

<p><code>./example/CMakeLists</code>：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_executable</span>(main main.c)</span><br><span class="line"><span class="keyword">include_directories</span>(../src)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(main foo)</span><br><span class="line"><span class="keyword">install</span>(TARGETS main RUNTIME DESTINATION bin)</span><br></pre></td></tr></table></figure>

<p><code>./example/main.c</code>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;foo.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  foo();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="编译、安装及测试"><a href="#编译、安装及测试" class="headerlink" title="编译、安装及测试"></a>编译、安装及测试</h2><p>老方法，新建一个临时目录用来存放中间文件，以下命令在项目根目录下执行，将动态库和可执行程序安装到根目录下的 <code>lib</code> 和 <code>bin</code> 目录，然后回到根目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake .. -DCMAKE_INSTALL_PREFIX=..</span><br><span class="line">make &amp;&amp; make install &amp;&amp; <span class="built_in">cd</span> ..</span><br></pre></td></tr></table></figure>

<p>此时目录结构为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ tree . -I build</span><br><span class="line">.</span><br><span class="line">├── bin</span><br><span class="line">│   └── main</span><br><span class="line">├── CMakeLists.txt</span><br><span class="line">├── example</span><br><span class="line">│   ├── CMakeLists.txt</span><br><span class="line">│   └── main.c</span><br><span class="line">├── lib</span><br><span class="line">│   └── libfoo.so</span><br><span class="line">└── src</span><br><span class="line">    ├── CMakeLists.txt</span><br><span class="line">    ├── foo.c</span><br><span class="line">    └── foo.h</span><br></pre></td></tr></table></figure>

<p>首先我们运行 <code>build</code> 目录下的可执行文件，并查看其连接的 <code>libfoo.so</code> 路径：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ./build/example/main </span><br><span class="line">foo</span><br><span class="line">$ ldd ./build/example/main | grep foo</span><br><span class="line">	libfoo.so =&gt; /home/xyz/RPATH/build/src/libfoo.so (0x00007f5d41c23000)</span><br></pre></td></tr></table></figure>

<p>这里 <code>/home/xyz/RPATH</code> 是我的项目根目录绝对路径，可以发现 <code>make</code> 生成的可执行文件，链接的是绝对路径，并且运行也没问题。但是再看看安装后的可执行文件和链接的库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ./bin/main </span><br><span class="line">./bin/main: error <span class="keyword">while</span> loading shared libraries: libfoo.so: cannot open shared object file: No such file or directory</span><br><span class="line">$ ldd ./bin/main | grep foo</span><br><span class="line">	libfoo.so =&gt; not found</span><br></pre></td></tr></table></figure>

<p>我们会发现可执行文件失去了链接，因此要运行 <code>main</code> ，必须手动将动态库添加到系统路径中：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ LD_LIBRARY_PATH=./lib ./bin/main </span><br><span class="line">foo</span><br></pre></td></tr></table></figure>

<h2 id="问题在哪"><a href="#问题在哪" class="headerlink" title="问题在哪"></a>问题在哪</h2><p>这个问题最初出现在我帮师兄写的框架当中，当时也找到了stackoverflow上的讨论帖：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/42695839/cmake-make-install-does-not-link-against-libraries-in-ubuntu">cmake: “make install” does not link against libraries in Ubuntu</a></p>
<p>简单翻译下：</p>
<p>系统首先会在 <code>/etc/ld.so.conf</code> 文件配置的路径中寻找动态库（在我的系统上该文件记录的是 <code>/etc/ld.so.conf.d</code> 目录下的所有 <code>*.conf</code> 文件），如果找不到，则有以下4个选项：</p>
<ol>
<li>将库安装到系统默认路径比如 <code>/lib</code> 和 <code>/usr/lib</code>（但可能因为没有权限而无法实施）；</li>
<li>编辑系统范围的搜索路径（同样可能因为没有权限而无法实施）；</li>
<li>设置 <code>LD_LIBRARY_PATH</code>（就像我们上节末尾所做的，但它会覆盖系统路径，也就是说可能会优先选择自己的库而不是系统路径的同名库）；</li>
<li>设置 <code>RPATH</code>，告诉可执行文件该到哪寻找它的库。</li>
</ol>
<p>OK，现在来看问题的产生原因：<code>RPATH</code> 在 <code>make install</code> 后会被自动地清除。为什么会这样呢？因为 <code>cmake</code> 安装的可执行文件和动态库的相对路径，可能和 <code>make</code> 生成的不一样，因此无法自动记住。</p>
<h2 id="cmake的解决方法"><a href="#cmake的解决方法" class="headerlink" title="cmake的解决方法"></a>cmake的解决方法</h2><p>当然，<code>cmake</code> 本身也提供了解决方法，参见：<a target="_blank" rel="noopener" href="https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/RPATH-handling">RPATH handling</a>。</p>
<p>不想看官网的长篇大论的话，针对本文的示例，在项目根目录的 <code>CMakeLists.txt</code> 中添加：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_INSTALL_RPATH <span class="string">&quot;$&#123;CMAKE_INSTALL_PREFIX&#125;/lib&quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_INSTALL_RPATH_USE_LINK_PATH <span class="keyword">TRUE</span>)</span><br></pre></td></tr></table></figure>

<p><code>make install</code> 安装时可以看到如下提示信息：</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- Installing: <span class="regexp">/home/</span>xyz<span class="regexp">/RPATH/</span>bin/main</span><br><span class="line">-- Set <span class="keyword">runtime</span> path of <span class="string">&quot;/home/xyz/RPATH/bin/main&quot;</span> to <span class="string">&quot;/home/xyz/RPATH/lib&quot;</span></span><br></pre></td></tr></table></figure>

<p>这种方式还是设置的绝对路径，也就是 <code>cmake</code> 安装目录下的 <code>lib</code> 子目录，然后可以发现安装后的 <code>main</code> 成功链接到了 <code>libfoo.so</code>，并且改变 <code>main</code> 路径，仍然可以链接到 <code>libfoo.so</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ldd bin/main | grep foo</span><br><span class="line">	libfoo.so =&gt; /home/xyz/RPATH/lib/libfoo.so (0x00007f60818c2000)</span><br><span class="line">$ <span class="built_in">mv</span> bin/main .</span><br><span class="line">$ ldd main | grep foo</span><br><span class="line">	libfoo.so =&gt; /home/xyz/RPATH/lib/libfoo.so (0x00007f6ff516f000)</span><br></pre></td></tr></table></figure>

<p>类似地，我们可以把 <code>CMAKE_INSTALL_RPATH</code> 指定为相对路径 <code>../lib</code>，但这样的话局限性比较大，也就是说必须保证动态库在 <code>$PWD/../lib</code> 下，比如按这种方式编译安装后：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ldd ./bin/main | grep foo</span><br><span class="line">	libfoo.so =&gt; not found</span><br><span class="line">$ <span class="built_in">cd</span> bin</span><br><span class="line">$ ldd ./main | grep foo</span><br><span class="line">	libfoo.so =&gt; ../lib/libfoo.so (0x00007f12fe0c7000)</span><br></pre></td></tr></table></figure>

<p>但这种方式也有个优点，也就是说哦，只要动态库在当前工作目录的相对路径 <code>../lib</code> 下，就能链接到该动态库，此时可以写一个脚本，和 <code>main</code> 放在同一目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">SHELL_DIR=$(<span class="built_in">cd</span> $(<span class="built_in">dirname</span> <span class="variable">$0</span>) &amp;&amp; <span class="built_in">echo</span> <span class="variable">$PWD</span>)</span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$SHELL_DIR</span> &amp;&amp; ./main</span><br></pre></td></tr></table></figure>

<p>第一行是取得脚本目录的绝对路径，第2行是进入该路径，这样只要动态库在可执行文件（以及运行脚本）的相对路径 <code>../lib</code> 下，无论从哪个目录调用该脚本，都能成功使可执行文件链接到该动态库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">ls</span> bin/</span><br><span class="line">main  run.sh</span><br><span class="line">$ <span class="built_in">ls</span> lib/</span><br><span class="line">libfoo.so</span><br><span class="line">$ ./bin/run.sh </span><br><span class="line">foo</span><br><span class="line">$ <span class="built_in">cd</span> bin/ &amp;&amp; ./run.sh &amp;&amp; <span class="built_in">cd</span> -</span><br><span class="line">foo</span><br><span class="line">/home/xyz/RPATH</span><br><span class="line">$ <span class="built_in">mkdir</span> temp</span><br><span class="line">$ <span class="built_in">mv</span> bin/ lib/ temp/</span><br><span class="line">$ ./temp/bin/run.sh </span><br><span class="line">foo</span><br></pre></td></tr></table></figure>

<p>不过既然借助了辅助脚本了，实际上在脚本里手动设置 <code>LD_LIBRARY_PATH</code> 为相对路径看起来更简单一些。</p>
<h2 id="GCC的解决方法"><a href="#GCC的解决方法" class="headerlink" title="GCC的解决方法"></a>GCC的解决方法</h2><p>为什么说到这个呢？因为我最近在使用公司内部项目的时候，发现自己的测试代码一直出错，查看日志，竟然源码路径来自其他用户的个人目录。也就是说是其他用户编译了动态库，然后使用超级权限将其安装到了系统目录。</p>
<p>对于这种情况，可以用 <code>LD_LIBRARY_PATH</code> 覆盖，但是如果修改了目录后，每次都要重新设置 <code>LD_LIBRARY_PATH</code>，此时用 <code>gcc</code> 的链接选项就行了，还是对这个项目，手动用 <code>gcc</code> 进行编译：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> src/</span><br><span class="line">$ gcc -c -fPIC foo.c </span><br><span class="line">$ gcc -shared foo.o -o libfoo.so</span><br><span class="line">$ <span class="built_in">cd</span> ../example/</span><br><span class="line">$ gcc main.c -I../src -L../src -lfoo -Wl,-rpath=../src</span><br></pre></td></tr></table></figure>

<p>注意，<code>-Wl,-rpath</code> 这个选项必不可少，它指定了 <code>RPATH</code> 的相对路径，为此，我将原来的 <code>libfoo.so</code> 放在系统目录 <code>/lib64</code> 下，然后修改 <code>foo.c</code> （打印 <code>&quot;new foo&quot;</code> 而不是 <code>&quot;foo&quot;</code>）后编译成动态库放在 <code>src</code> 目录下，测试如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> example/</span><br><span class="line">$ gcc main.c -I../src -L../src -lfoo</span><br><span class="line">$ ./a.out </span><br><span class="line">foo</span><br><span class="line">$ gcc main.c -I../src -L../src -lfoo -Wl,-rpath=../src</span><br><span class="line">$ ./a.out </span><br><span class="line">new foo</span><br><span class="line">$ <span class="built_in">cd</span> .. &amp;&amp; <span class="built_in">mkdir</span> temp &amp;&amp; <span class="built_in">mv</span> src/ example/ temp</span><br><span class="line">$ tree temp/</span><br><span class="line">temp/</span><br><span class="line">├── example</span><br><span class="line">│   ├── a.out</span><br><span class="line">│   ├── CMakeLists.txt</span><br><span class="line">│   └── main.c</span><br><span class="line">└── src</span><br><span class="line">    ├── CMakeLists.txt</span><br><span class="line">    ├── foo.c</span><br><span class="line">    ├── foo.h</span><br><span class="line">    ├── foo.o</span><br><span class="line">    └── libfoo.so</span><br><span class="line">$ ./temp/example/a.out </span><br><span class="line">foo</span><br><span class="line">$ <span class="built_in">cd</span> temp/example/ &amp;&amp; ./a.out</span><br><span class="line">new foo</span><br></pre></td></tr></table></figure>

<p>和刚才 <code>cmake</code> 设置 <code>RPATH</code> 的测试结果一样，只要当前工作目录满足和动态库所在目录的相对路径是 <code>RPATH</code>，那么运行可执行文件所链接到的动态库就是相对路径的动态库。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/09/05/%E9%93%BE%E6%8E%A5%E9%80%89%E9%A1%B9RPATH%E4%BB%A5%E5%8F%8A%E5%9C%A8cmake%E5%92%8Cgcc%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/" data-id="cl1qn407l001y4c1u6qps2gd9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%93%BE%E6%8E%A5/" rel="tag">链接</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-我的vim开发环境搭建-4-GDB升级8-0" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/26/%E6%88%91%E7%9A%84vim%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-4-GDB%E5%8D%87%E7%BA%A78-0/" class="article-date">
  <time datetime="2019-07-26T15:16:10.000Z" itemprop="datePublished">2019-07-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/26/%E6%88%91%E7%9A%84vim%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-4-GDB%E5%8D%87%E7%BA%A78-0/">我的vim开发环境搭建(4): GDB升级8.0</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>因为CentOS 6的GDB版本太老，所以在调试我自己安装的高版本GCC编译的程序时，很多时候打印不出变量来，所以需要升级GDB。</p>
<p>之前在CentOS 6上下载GDB源码编译总是出问题，网上也搜不到解决原因，不过最后自己折腾出来原因了。问题关键在于configure阶段，正确的宏没有检测出来，导致条件编译出错，比如：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_XXX</span></span><br><span class="line"><span class="comment">// 某些类型的定义或相应头文件的包含...</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>

<p>如果<code>HAVE_XXX</code>宏没有检测出来的话，本应该定义的类型就没有了。这既可能造成编译阶段找不到类型定义，也可能造成链接阶段找不到函数的定义(因为某些函数的参数是typedef别名或者宏)。</p>
<p>明白这一点后，只需要make时根据错误在对应代码中删除相应的<code>#ifdef</code>或者<code>#ifndef</code>块就行，这里以GDB 8.0的编译为例。</p>
<h2 id="1-工具和说明"><a href="#1-工具和说明" class="headerlink" title="1. 工具和说明"></a>1. 工具和说明</h2><p>有时候代码出错，提示某些类型或宏定义不存在。这时可以查找这些宏是在哪个文件中：</p>
<figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">find</span> . -name <span class="string">&quot;*.h&quot;</span> | xargs grep -<span class="built_in">n</span> <span class="string">&quot;XXX&quot;</span></span><br></pre></td></tr></table></figure>

<p>有时候不在GDB源码目录下，而是在系统头文件中，比如<code>B0</code>就是<code>termios.h</code>中的定义，此时可以利用搜索引擎搜索，并YouCompleteMe的代码跳转功能来确认，有些头文件是<code>sys/xxx.h</code>而非<code>xxx.h</code>（旧版本的系统），这些GDB源码通过条件编译判断到底是包含哪个。</p>
<p>此外，跳转功能还是要结合ctags，YCM好用在于它是基于语义的分析，但是得设置包含路径，默认包含路径只有当前目录，如果直接包含子目录头文件而不给出子目录名（编译时<code>-I</code>指定子目录路径即可）。ctags无脑找标签，所以有时候直接包含子目录的头文件，即使不做设置也可以跳转。ctags只需要在源码目录下<code>ctags -R .</code>生成tags文件，之后<code>Ctrl+]</code>就可以跳转了。</p>
<p>一般提示<code>xxx.c</code>出错，先仔细看看对应的<code>xxx.h</code>头文件，是否因为条件编译导致某些类型定义找不到。如果该头文件找不到，就可能通过上面的方法找到类型定义处，基本上一大堆宏都是在<code>config.h</code>中。</p>
<p>另外，错误提示的文件目录为GDB源码解压后的gdb子目录。</p>
<h2 id="2-出错解决"><a href="#2-出错解决" class="headerlink" title="2. 出错解决"></a>2. 出错解决</h2><h3 id="2-1-编译错误处理"><a href="#2-1-编译错误处理" class="headerlink" title="2.1. 编译错误处理"></a>2.1. 编译错误处理</h3><blockquote>
<p>In file included from inf-ptrace.c:27:0:<br>nat&#x2F;gdb_ptrace.h:150:19: error: ‘PTRACE_TYPE_ARG1’ was not declared in this scope<br>          ptrace ((PTRACE_TYPE_ARG1) request, pid, addr, data)</p>
</blockquote>
<p>仅给出其中一处代表性错误。进入<code>nat/gdb_ptrace.h</code>可以看到这样的语句：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_PTRACE_H</span></span><br><span class="line"><span class="meta"># <span class="keyword">include</span> <span class="string">&lt;ptrace.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined(HAVE_SYS_PTRACE_H)</span></span><br><span class="line"><span class="meta"># <span class="keyword">include</span> <span class="string">&lt;sys/ptrace.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>

<p>我的系统上是<code>sys/ptrace.h</code>，那么明显条件编译出问题了，删掉<code>#include &lt;sys/ptrace.h&gt;</code>的另外4行即可。</p>
<p>类似地，去掉<code>#ifndef HAVE_DECL_PTRACE</code>。然后包含<code>../config.h</code>头文件（因为在<code>gdb</code>目录下，而<code>gdb_ptrace.h</code>在<code>gdb/nat</code>目录下），这个头文件必须在<code>sys/ptrace.h</code>下方，因为相关地宏，因为其中定义地宏在后面地头文件中也可能用到。</p>
<p>修改后还有个错误</p>
<blockquote>
<p>inf-ptrace.c: In function ‘void inf_ptrace_interrupt(target_ops*, ptid_t)’:<br>inf-ptrace.c:304:34: error: ‘inferior_process_group’ was not declared in this scope<br>   kill (-inferior_process_group (), SIGINT);</p>
</blockquote>
<p>利用ctags找到该函数定义在<code>inflow.c</code>中：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">93</span> <span class="meta">#<span class="keyword">ifdef</span> PROCESS_GROUP_TYPE</span></span><br><span class="line"> <span class="number">94</span> </span><br><span class="line"> <span class="number">95</span> <span class="comment">/* Return the process group of the current inferior.  */</span></span><br><span class="line"> <span class="number">96</span> </span><br><span class="line"> <span class="number">97</span> PROCESS_GROUP_TYPE</span><br><span class="line"> <span class="number">98</span> <span class="built_in">inferior_process_group</span> (<span class="type">void</span>)</span><br><span class="line"> <span class="number">99</span> &#123;</span><br><span class="line"><span class="number">100</span>   <span class="keyword">return</span> <span class="built_in">get_inflow_inferior_data</span> (<span class="built_in">current_inferior</span> ())-&gt;process_group;</span><br><span class="line"><span class="number">101</span> &#125;</span><br><span class="line"><span class="number">102</span> <span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>

<p>嗯估计又是<code>PROCESS_GROUP_TYPE</code>找不到，该类型在<code>inflow.h</code>中定义，用条件编译宏包括起来了：</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">25 </span>#ifdef HAVE_TERMIOS</span><br><span class="line"><span class="symbol">26 </span># define PROCESS_GROUP_TYPE pid_t</span><br><span class="line"><span class="symbol">27 </span>#elif defined (HAVE_TERMIO) || defined (HAVE_SGTTY)</span><br><span class="line"><span class="symbol">28 </span># define PROCESS_GROUP_TYPE <span class="keyword">int</span></span><br><span class="line"><span class="symbol">29 </span>#endif </span><br></pre></td></tr></table></figure>

<p>原因是<code>HAVE_TERMIOS</code>没检测出来保。留第26行，其余4行删掉。可以看到上面包含了<code>gdb_termios.h</code>中（在<code>gdb/common</code>目录下），更根本的解决方法是在这个头文件中定义宏<code>HAVE_TERMIOS</code>。（也能解决后面其他和termios相关的问题）</p>
<p>下文就不详细给出错误信息和分析了，简单描述错误和给出解决方法。可能比较复杂，最简单的应该是在<code>def.h</code>中手动设置条件编译宏，不过反正能编译就行，我都是一个窗口make，另一个窗口根据make出错信息编辑代码。其实懂了出错原理后后自己应该也能找出更简单的解决方法。</p>
<h3 id="2-2-链接错误处理"><a href="#2-2-链接错误处理" class="headerlink" title="2.2. 链接错误处理"></a>2.2. 链接错误处理</h3><blockquote>
<p>value.c:3709: undefined reference to &#96;store_typed_floating(void*, type const*, double)’<br>collect2: error: ld returned 1 exit status</p>
</blockquote>
<p>打开<code>value.c</code>找到该函数，ctags跳转到<code>doublest.c</code>中，发现函数第3个参数是<code>DOUBLEST</code>，也就是没找到这个宏或者类型别名的定义。继续ctags跳转到<code>DOUBLEST</code>的定义位置，果然也被条件编译宏包含起来了。从错误信息看它应该是<code>double</code>的类型别名，因此保留<code>typedef double DOUBLEST;</code>的分支。</p>
<h3 id="2-3-其他编译错误处理"><a href="#2-3-其他编译错误处理" class="headerlink" title="2.3. 其他编译错误处理"></a>2.3. 其他编译错误处理</h3><p><code>ser-tcp.c</code>：</p>
<ul>
<li>去掉<code>HAVE_SYS_IOCTL_H</code>的<code>#ifdef</code>；</li>
<li>删除<code>typedef __socklen_t socklen_t</code>的代码。</li>
</ul>
<p><code>gregset.h</code>：</p>
<ul>
<li>去掉<code>#HAVE_SYS_PROCFS_H</code>的<code>#ifdef</code>块（使得<code>sys/procfs.h</code>被包含）；</li>
<li>第一处<code>grepset_t</code>改成<code>elf_gregset_t</code>；</li>
<li>第一处<code>fpregset_t</code>改成<code>elf_fpregset_t</code>（这两个类型都定义在<code>sys/procfs.h</code>中）；</li>
</ul>
<p><code>gdb_proc_service.h</code>：</p>
<ul>
<li>删除<code>lwpid_t</code>的定义；</li>
<li>包含<code>common/common-defs.h</code>；</li>
</ul>
<p><code>gdb/gdb_wait.h</code>：保留条件编译的<code>sys/wait.h</code>分支；</p>
<p><code>nat/amd64-linux-siginfo.c</code>：将<code>common-defs.h</code>作为第一个头文件；</p>
<p><code>gdb_curses.h</code>：保留条件编译的<code>curses.h</code>分支；</p>
<p>在下列C文件中包含<code>config.h</code>作为第一个头文件；</p>
<ul>
<li><code>auto-load.c</code></li>
<li><code>doublest.c</code></li>
<li><code>jit.c</code></li>
<li><code>main.c</code></li>
<li><code>top.c</code></li>
<li><code>utils.c</code></li>
</ul>
<p><code>common/signals.c</code>：</p>
<ul>
<li>去掉<code>HAVE_SIGNAL_H</code>的<code>#ifdef</code>块；</li>
<li>包含<code>sys/signal.h</code>；</li>
</ul>
<p><code>gdb-server/remote-utils.c</code>：把<code>USE_WIN32API</code>,<code>__QNX__</code>之外（其实都在它们前面定义了）的<code>#if</code>&#x2F;<code>#endif</code>块全部去掉。</p>
<p><code>gdb-server/linux-low.h</code>：</p>
<ul>
<li>删除<code>Elf_32_auxv_t</code>和<code>Elf64_auxv_t</code>的定义；</li>
<li>删除<code>HAVE_LINUX_REGSETS</code>的<code>#ifdef</code>块（有很多处）；</li>
<li>删除<code>USE_THREAD_DB</code>的<code>#ifdef</code>块；</li>
</ul>
<h2 id="3-安装后出错"><a href="#3-安装后出错" class="headerlink" title="3. 安装后出错"></a>3. 安装后出错</h2><blockquote>
<p>common&#x2F;filestuff.c:401: internal-error: int gdb_pipe_cloexec(int*): pipe not available on this host</p>
</blockquote>
<p>找到如下代码：</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">385 </span>#ifdef HAVE_PIPE2</span><br><span class="line"><span class="symbol">386 </span>  result = pipe2 (filedes, O_CLOEXEC);</span><br><span class="line"><span class="symbol">387 </span>  <span class="keyword">if</span> (result != -<span class="number">1</span>)</span><br><span class="line"><span class="symbol">388 </span>    &#123;</span><br><span class="line"><span class="symbol">389 </span>      maybe_mark_cloexec (filedes[<span class="number">0</span>]);</span><br><span class="line"><span class="symbol">390 </span>      maybe_mark_cloexec (filedes[<span class="number">1</span>]);</span><br><span class="line"><span class="symbol">391 </span>    &#125;</span><br><span class="line"><span class="symbol">392 </span>#<span class="keyword">else</span></span><br><span class="line"><span class="symbol">393 </span>#ifdef HAVE_PIPE</span><br><span class="line"><span class="symbol">394 </span>  result = pipe (filedes);</span><br><span class="line"><span class="symbol">395 </span>  <span class="keyword">if</span> (result != -<span class="number">1</span>)</span><br><span class="line"><span class="symbol">396 </span>    &#123;</span><br><span class="line"><span class="symbol">397 </span>      mark_cloexec (filedes[<span class="number">0</span>]);</span><br><span class="line"><span class="symbol">398 </span>      mark_cloexec (filedes[<span class="number">1</span>]);</span><br><span class="line"><span class="symbol">399 </span>    &#125;</span><br><span class="line"><span class="symbol">400 </span>#<span class="keyword">else</span> /* HAVE_PIPE */</span><br><span class="line"><span class="symbol">401 </span>  gdb_assert_not_reached (_(<span class="string">&quot;pipe not available on this host&quot;</span>));</span><br><span class="line"><span class="symbol">402 </span>#endif /* HAVE_PIPE */</span><br><span class="line"><span class="symbol">403 </span>#endif /* HAVE_PIPE2 */</span><br></pre></td></tr></table></figure>

<p>还是条件编译宏的问题，触发了<code>gdb_assert_not_reached</code>，这里保留<code>HAVE_PIPE</code>分支就行了。重新编译安装就OK。</p>
<p>安装时会有个警告导致出错：</p>
<blockquote>
<p>gdb-8.0&#x2F;missing: line 81: makeinfo: command not found</p>
</blockquote>
<p>但是并不影响GDB的正常使用，也没必要特地安装<code>makeinfo</code>。至于环境变量和prefix这种东西，就不多讲了。</p>
<h2 id="4-启用termdebug"><a href="#4-启用termdebug" class="headerlink" title="4. 启用termdebug"></a>4. 启用termdebug</h2><p>要求vim 8.1和GDB 7.12以上，命令<code>:packadd termdebug</code>加载termdebug插件即可。然后在vim中就可启动termdebug调试程序：<code>:Termdebug &lt;your-program&gt;</code>。</p>
<p>但是默认是横向切分窗口，很不喜欢，vim中<code>:help termdebug</code>可以查看文档，默认会打开gdb窗口和程序窗口，搜索vertical就可以找到配置，只需要在<code>~/.vimrc</code>中设置如下属性即可：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> g:<span class="attr">termdebug_wide</span> = <span class="number">163</span> <span class="comment"># 列宽，可调整</span></span><br></pre></td></tr></table></figure>

<p>运行效果如下：</p>
<p><img src="/2019/07/26/%E6%88%91%E7%9A%84vim%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-4-GDB%E5%8D%87%E7%BA%A78-0/termdebug%E7%A4%BA%E4%BE%8B.jpg" alt="termdebug示例"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/26/%E6%88%91%E7%9A%84vim%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-4-GDB%E5%8D%87%E7%BA%A78-0/" data-id="cl1qn407i001r4c1u4a1yg7qu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vim/" rel="tag">vim</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%90%AD%E7%8E%AF%E5%A2%83/" rel="tag">搭环境</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Linux-C-mktime进行时间转换的陷阱" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/22/Linux-C-mktime%E8%BF%9B%E8%A1%8C%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%E7%9A%84%E9%99%B7%E9%98%B1/" class="article-date">
  <time datetime="2019-07-22T14:10:36.000Z" itemprop="datePublished">2019-07-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/22/Linux-C-mktime%E8%BF%9B%E8%A1%8C%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%E7%9A%84%E9%99%B7%E9%98%B1/">Linux C mktime进行时间转换的陷阱</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近做的一个小程序，需要对时间戳和对应日期字符串进行相互转换，于是二话不说直接翻看<em>The Linux Programming Interface</em>(<em>TLPI</em>)查API。翻到了下面这张图：</p>
<p><img src="/2019/07/22/Linux-C-mktime%E8%BF%9B%E8%A1%8C%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%E7%9A%84%E9%99%B7%E9%98%B1/%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2%E5%87%BD%E6%95%B0.JPG" alt="时间格式转换函数"></p>
<p>我的时间戳是自epoch(UTC)以来的毫秒数表示，拟定转换的是年月日时分秒，外加个毫秒，思路就很简单：</p>
<ol>
<li>输入字符串：用<code>strptime</code>转换成<code>struct tm</code>类型，再用<code>sscanf</code>读取毫秒，最后用<code>mktime</code>将<code>tm</code>对象转换成<code>time_t</code>（自epoch(UTC)以来的秒数）乘以1000加上毫秒数；</li>
<li>输入时间戳：除以1000得到秒数，模1000得到毫秒数，然后用<code>strftime</code>将秒数格式化，再用<code>snprintf</code>将毫秒数格式化和’.’一起添加到末尾。</li>
</ol>
<p>当然，输入字符串的情况下，考虑健壮性的话需要对<code>tm</code>对象的各字段进行合法性检查，这里就不详述了。</p>
<h2 id="奇妙的BUG"><a href="#奇妙的BUG" class="headerlink" title="奇妙的BUG"></a>奇妙的BUG</h2><p>但是写完后进行测试，输入字符串，转换成时间戳，然后再转换回字符串。发现一个十分奇葩的错误，就是转换回去后比原来要少了1给小时，比如”2000-02-29 10:01:20.094”会变成”2000-02-29 09:01:20.094”，也就是说其他的功能都没错。</p>
<p>在此之前我已经考虑到了时区的问题，因此确认过<code>mktime</code>的输入参数是本地时区，因此<code>strftime</code>的输入参数需要用<code>localtime</code>而非<code>gmtime</code>。</p>
<p>为了复现这个BUG，以及描述问题的原因，可以编译运行下面这段代码（忽略了返回值检查）：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (argc &lt; <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;Usage: %s yyyy-mm-dd hh:mm:dd\n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;before: %s\n&quot;</span>, argv[<span class="number">1</span>]);</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">tm</span> tm_;</span><br><span class="line">  <span class="built_in">strptime</span>(argv[<span class="number">1</span>], <span class="string">&quot;%F %T&quot;</span>, &amp;tm_);</span><br><span class="line">  <span class="keyword">auto</span> dump_tm = [](<span class="type">const</span> <span class="keyword">struct</span> tm* tmp, <span class="type">const</span> <span class="type">char</span>* msg) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s: %04d-%02d-%02d %02d:%02d:%02d\n&quot;</span>, msg, tmp-&gt;tm_year + <span class="number">1900</span>,</span><br><span class="line">           tmp-&gt;tm_mon + <span class="number">1</span>, tmp-&gt;tm_mday, tmp-&gt;tm_hour, tmp-&gt;tm_min,</span><br><span class="line">           tmp-&gt;tm_sec);</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="built_in">dump_tm</span>(&amp;tm_, <span class="string">&quot;before mktime&quot;</span>);</span><br><span class="line">  <span class="keyword">auto</span> timestamp = <span class="built_in">mktime</span>(&amp;tm_);</span><br><span class="line">  <span class="built_in">dump_tm</span>(&amp;tm_, <span class="string">&quot;after mktime&quot;</span>);</span><br><span class="line">  <span class="type">char</span> buf[<span class="number">128</span>];</span><br><span class="line">  <span class="built_in">strftime</span>(buf, <span class="built_in">sizeof</span>(buf), <span class="string">&quot;%F %T&quot;</span>, <span class="built_in">localtime</span>(&amp;timestamp));</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;after: %s\n&quot;</span>, buf);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>设置几个时间，运行结果如下：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ./a.out &quot;2001-02-28 01:00:00&quot;</span></span><br><span class="line"><span class="attribute">before</span>: <span class="number">2001</span>-<span class="number">02</span>-<span class="number">28</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">before</span> mktime: <span class="number">2001</span>-<span class="number">02</span>-<span class="number">28</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">after</span> mktime: <span class="number">2001</span>-<span class="number">02</span>-<span class="number">28</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">after</span>: <span class="number">2001</span>-<span class="number">02</span>-<span class="number">28</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="comment"># ./a.out &quot;2000-02-29 01:00:00&quot;</span></span><br><span class="line"><span class="attribute">before</span>: <span class="number">2000</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">before</span> mktime: <span class="number">2000</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">after</span> mktime: <span class="number">2000</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">after</span>: <span class="number">2000</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="comment"># ./a.out &quot;2004-02-29 01:00:00&quot;</span></span><br><span class="line"><span class="attribute">before</span>: <span class="number">2004</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">before</span> mktime: <span class="number">2004</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">after</span> mktime: <span class="number">2004</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attribute">after</span>: <span class="number">2004</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br></pre></td></tr></table></figure>

<p>可以发现中间的输入结果有误，一开始怀疑是闰年的缘故，但是2004年和2000年的结果并不相同，而它们都是闰年。此外实测发现”2000-01-29 01:00:00”也出错。</p>
<h2 id="原因及解决方法"><a href="#原因及解决方法" class="headerlink" title="原因及解决方法"></a>原因及解决方法</h2><p>其实问题的关键出在<code>struct tm</code>结构的<code>tm_idst</code>字段，可以发现无论结果是否转换错误，<code>mktime</code>始终把<code>tm_idst</code>重置为0，而调用之前<code>tm_idst</code>为非零值。</p>
<p>这个字段即DST，Daylight Saving Time。若大于0则将该时间视为夏令时，若为0则将该时间视为标准间(忽略夏令时)，若小于0则试图使用时区信息和系统数据库来确定设置。而mktime()在进行转换时会对时区进行设置，若DST未生效，则将<code>tm_idst</code>置为0，若DST生效，则会将其置为正值。</p>
<p>因此就是<strong>夏令时</strong>的问题，<a target="_blank" rel="noopener" href="https://blog.csdn.net/duyiwuer2009/article/details/42459677">struct tm中的tm_idst以及mktime</a>的测试中2001年以前的时间使用DST则会比其他情况晚1小时，当然，这个测试和我的略有出入，但我测试的2001年之后的确实也没出现这问题。</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/dongzhiquan/archive/2011/11/05/2237075.html">mktime 夏令时</a>则使用了一种叫较为复杂的方法。</p>
<p>这个问题确实造成了不少人的困扰，最简单的方法就是在<code>mktime</code>之前将<code>tm_idst</code>设为-1，让系统为你解决这个问题。但实际上并非如此，比如<a target="_blank" rel="noopener" href="https://www.cnblogs.com/dongzhiquan/archive/2011/11/05/2237075.html">mktime 夏令时</a>文中就提到了：</p>
<blockquote>
<p>俄罗斯时间2008年10月26日2:30由于夏令时的跳变会经过2次，这2次所代表的日历时间明显不同。</p>
</blockquote>
<p>stackoverflow上也有讨论：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/8558919/mktime-and-tm-isdst">mktime-and-tm-isdst</a>，其中Rich Jahn也提到了即使设为-1也不代表能“自动推断是否使用夏令时：</p>
<blockquote>
<p>-1 is a possible input, but I would think of it as meaning “Unknown”. Don’t think of it as meaning “determine automatically”, because in general, mktime() can’t always determine it automatically.</p>
<p>The explicit DST status (0 or 1) should come from something external to the software, for example store it in the file or database, or prompt the user.</p>
</blockquote>
<p>最好的解决方法还是在时间后面加上UTC，比如：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">tm</span> tm_;</span><br><span class="line"><span class="type">char</span>* p = <span class="built_in">strptime</span>(<span class="string">&quot;2004-02-29 01:00:00.039 UTC&quot;</span>, <span class="string">&quot;%F %T&quot;</span>, &amp;tm_);</span><br></pre></td></tr></table></figure>

<p>调用完毕后返回值<code>p</code>指向的是<code>&quot;.039 UTC&quot;</code>，后缀<code>UTC</code>并不影响返回值，因此仍然可以对<code>p</code>进行<code>sscanf</code>或者<code>strtol</code>操作获取毫秒数。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/22/Linux-C-mktime%E8%BF%9B%E8%A1%8C%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%E7%9A%84%E9%99%B7%E9%98%B1/" data-id="cl1qn4076000q4c1uc91pae29" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/" rel="tag">C++</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-我的vim开发环境搭建-3-Go开发配置" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/06/21/%E6%88%91%E7%9A%84vim%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-3-Go%E5%BC%80%E5%8F%91%E9%85%8D%E7%BD%AE/" class="article-date">
  <time datetime="2019-06-20T16:00:49.000Z" itemprop="datePublished">2019-06-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/06/21/%E6%88%91%E7%9A%84vim%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-3-Go%E5%BC%80%E5%8F%91%E9%85%8D%E7%BD%AE/">我的vim开发环境搭建(3): Go开发配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Go的安装"><a href="#1-Go的安装" class="headerlink" title="1. Go的安装"></a>1. Go的安装</h2><p>嗯因为Go的官网被墙了所以需要自行准备梯子。Linux安装Go很简单，即使是CentOS 6，直接去<a target="_blank" rel="noopener" href="https://golang.org/dl/">golang下载页</a>下载二进制文件解压即可，比如我写这篇博客时的最新版本是1.12.6，下载解压即可：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https:<span class="regexp">//</span>dl.google.com<span class="regexp">/go/g</span>o1.<span class="number">12.6</span>.linux-amd64.tar.gz</span><br><span class="line">tar zxvf go1.<span class="number">12.6</span>.linux-amd64.tar.gz -C ~<span class="regexp">/local/</span></span><br><span class="line">cd ~<span class="regexp">/local/g</span>o</span><br><span class="line">mkdir gopath</span><br></pre></td></tr></table></figure>

<p>我这里依旧是解压到<code>~/local</code>目录，另外新建了<code>gopath</code>目录。然后在<code>~/.bashrc</code>中添加环境变量：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> <span class="attribute">PATH</span>=<span class="variable">$LOCAL</span>/go/bin:$PATH</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">GOROOT</span>=<span class="variable">$LOCAL</span>/go</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">GOPATH</span>=<span class="variable">$GOROOT</span>/gopath</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">GOBIN</span>=<span class="variable">$GOPATH</span>/bin</span><br></pre></td></tr></table></figure>

<p><code>GOROOT</code>指的是Go的安装目录，而<code>GOPATH</code>则是自定义路径，不一定要在<code>GOROOT</code>下，而且可以有多个路径，每个路径代表Go的一个工作区，一般的工作区由<code>src</code>、<code>pkg</code>、<code>bin</code>三个目录组成，比如<code>go get</code>远程下载的项目，而<code>GOBIN</code>则是安装的二进制文件的路径。</p>
<h2 id="2-重新编译YCM"><a href="#2-重新编译YCM" class="headerlink" title="2. 重新编译YCM"></a>2. 重新编译YCM</h2><p>之前安装的YCM能够对C&#x2F;C++进行补全，要对Go进行补全需要加上<code>--go-completer</code>选项重新编译，不过由于已经存放过编译的中间文件了，所以这次编译会很快。</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CC=<span class="string">&quot;$LOCAL/gcc-5.4.0/bin/gcc&quot;</span> CXX=<span class="string">&quot;$LOCAL/gcc-5.4.0/bin/g++&quot;</span> <span class="string">./install.py</span>  \</span><br><span class="line">  <span class="params">--clang-completer</span> <span class="params">--system-libclang</span> <span class="params">--go-completer</span></span><br></pre></td></tr></table></figure>

<p>编译完毕后基本的补全功能已经有了，如下图所示：</p>
<p><img src="/2019/06/21/%E6%88%91%E7%9A%84vim%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-3-Go%E5%BC%80%E5%8F%91%E9%85%8D%E7%BD%AE/YCM%E5%AF%B9Go%E7%9A%84%E8%A1%A5%E5%85%A8.jpg" alt="YCM对Go的补全"></p>
<p>Go的编码规范建议使用TAB而非空格表示缩进，因此之前的vim配置中<code>set expandtab</code>最好注释掉，防止把TAB扩展成空格。</p>
<p>YCM对Go的补全无需像C++一样通过<code>.ycm_extra.conf.py</code>脚本来指定头文件包含目录的，它是通过直接分析处于<code>$GOROOT/pkg</code>或<code>GOPATH/pkg</code>下的静态库<code>.a</code>文件来获取补全信息的。</p>
<p>由于Go标准库的静态库已经编译好，位于<code>$GOROOT/pkg/$GOOS_$GOARCH</code>目录下，环境变量可通过<code>go env</code>命令来查询。而对于<code>go get</code>或者<code>$GOPATH/src</code>下的项目，如果没有编译成静态库，YCM是无法补全的，因此要用到某些包时需要首先进入包所在目录<code>go install</code>。</p>
<p>如果使用了本地包比如<code>import &quot;./local&quot;</code>，那么需要把<code>local.a</code>文件拷贝到和当前<code>.go</code>文件同一目录。</p>
<h2 id="3-vim-go"><a href="#3-vim-go" class="headerlink" title="3. vim-go"></a>3. vim-go</h2><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plug &#x27;fatih/vim-go&#x27;, &#123; &#x27;do&#x27;: &#x27;:GoUpdateBinaries&#x27; &#125;</span><br></pre></td></tr></table></figure>

<p>安装、使用可参考<a target="_blank" rel="noopener" href="https://github.com/fatih/vim-go">vim-go</a>的README，某些二进制文件地址被墙了，所以需要去镜像站下载。</p>
<p>然而打开.go文件时会提示</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim-go: could <span class="keyword">not</span> <span class="built_in">find</span> <span class="string">&#x27;gopls&#x27;</span>. <span class="built_in">Run</span> :GoInstallBinaries <span class="keyword">to</span> fix it</span><br></pre></td></tr></table></figure>

<p>然而用<code>:GoInstallBinaries</code>会失败，因为某些二进制文件被墙了，打开vim-go项目目录下的<code>plugin/go.vim</code>可以找到：</p>
<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot; these packages are used by vim-go and can be automatically installed if</span></span><br><span class="line"><span class="string">&quot;</span> needed <span class="keyword">by</span> the user <span class="keyword">with</span> GoInstallBinaries.</span><br><span class="line"><span class="keyword">let</span> s:packages = &#123;</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;asmfmt&#x27;</span>:        [<span class="string">&#x27;github.com/klauspost/asmfmt/cmd/asmfmt&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;dlv&#x27;</span>:           [<span class="string">&#x27;github.com/go-delve/delve/cmd/dlv&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;errcheck&#x27;</span>:      [<span class="string">&#x27;github.com/kisielk/errcheck&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;fillstruct&#x27;</span>:    [<span class="string">&#x27;github.com/davidrjenni/reftools/cmd/fillstruct&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;gocode&#x27;</span>:        [<span class="string">&#x27;github.com/mdempsky/gocode&#x27;</span>, &#123;<span class="string">&#x27;windows&#x27;</span>: [<span class="string">&#x27;-ldflags&#x27;</span>, <span class="string">&#x27;-H=windowsgui&#x27;</span>]&#125;],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;gocode-gomod&#x27;</span>:  [<span class="string">&#x27;github.com/stamblerre/gocode&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;godef&#x27;</span>:         [<span class="string">&#x27;github.com/rogpeppe/godef&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;gogetdoc&#x27;</span>:      [<span class="string">&#x27;github.com/zmb3/gogetdoc&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;goimports&#x27;</span>:     [<span class="string">&#x27;golang.org/x/tools/cmd/goimports&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;golint&#x27;</span>:        [<span class="string">&#x27;golang.org/x/lint/golint&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;gopls&#x27;</span>:         [<span class="string">&#x27;golang.org/x/tools/cmd/gopls&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;gometalinter&#x27;</span>:  [<span class="string">&#x27;github.com/alecthomas/gometalinter&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;golangci-lint&#x27;</span>: [<span class="string">&#x27;github.com/golangci/golangci-lint/cmd/golangci-lint&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;gomodifytags&#x27;</span>:  [<span class="string">&#x27;github.com/fatih/gomodifytags&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;gorename&#x27;</span>:      [<span class="string">&#x27;golang.org/x/tools/cmd/gorename&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;gotags&#x27;</span>:        [<span class="string">&#x27;github.com/jstemmer/gotags&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;guru&#x27;</span>:          [<span class="string">&#x27;golang.org/x/tools/cmd/guru&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;impl&#x27;</span>:          [<span class="string">&#x27;github.com/josharian/impl&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;keyify&#x27;</span>:        [<span class="string">&#x27;honnef.co/go/tools/cmd/keyify&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;motion&#x27;</span>:        [<span class="string">&#x27;github.com/fatih/motion&#x27;</span>],</span><br><span class="line">      <span class="string">\</span> <span class="string">&#x27;iferr&#x27;</span>:         [<span class="string">&#x27;github.com/koron/iferr&#x27;</span>],</span><br><span class="line"><span class="string">\</span> &#125;</span><br></pre></td></tr></table></figure>

<p>如注释所言，<code>:GoInstallBinaries</code>实际上是把这些二进制文件安装到本地，由于<code>golang.org</code>被墙了，所以相关工具无法下载。即使是github上的项目，克隆速度也慢得感人，所以还是手动下载安装。</p>
<h3 id="3-1-手动安装二进制文件"><a href="#3-1-手动安装二进制文件" class="headerlink" title="3.1 手动安装二进制文件"></a>3.1 手动安装二进制文件</h3><p>以<code>fillstruct</code>为例：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$GOPATH</span><span class="regexp">/src/gi</span>thub.com/davidrjenni</span><br><span class="line">cd <span class="variable">$GOPATH</span><span class="regexp">/src/gi</span>thub.com/davidrjenni</span><br><span class="line">git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/davidrjenni/</span>reftools.git </span><br><span class="line">cd reftools<span class="regexp">/cmd/</span>fillstruct</span><br><span class="line">go install</span><br></pre></td></tr></table></figure>

<p>注意<code>go.vim</code>中的<code>cmd/fillstruct</code>后缀指的是克隆的项目的子目录，因此流程是先克隆项目本身，再进入相应子目录安装。<code>go install</code>安装完后会发现<code>$GOPATH/bin</code>下多了二进制文件<code>fillstruct</code>。</p>
<p>实际上上述流程是手动进行了<code>go get</code>的流程，但是能够判断出错到底是<code>git clone</code>还是<code>go install</code>，前者出错可能就是访问太慢甚至无法访问，后者则是可能项目里引用了未安装的包。</p>
<h3 id="3-2-安装依赖包"><a href="#3-2-安装依赖包" class="headerlink" title="3.2 安装依赖包"></a>3.2 安装依赖包</h3><p>并非所有项目都像<code>fillstruct</code>那么顺利，比如在安装<code>errcheck</code>时就提示：</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ go install</span><br><span class="line">internal<span class="regexp">/errcheck/</span>errcheck.go:<span class="number">19</span>:<span class="number">2</span>: cannot <span class="keyword">find</span> <span class="keyword">package</span> <span class="string">&quot;golang.org/x/tools/go/packages&quot;</span> in <span class="keyword">any</span> of:</span><br><span class="line">    <span class="regexp">/home/</span>xyz<span class="regexp">/local/g</span>o<span class="regexp">/src/g</span>olang.org<span class="regexp">/x/</span>tools<span class="regexp">/go/</span>packages (<span class="keyword">from</span> $GOROOT)</span><br><span class="line">    <span class="regexp">/home/</span>xyz<span class="regexp">/local/g</span>o<span class="regexp">/gopath/</span>src<span class="regexp">/golang.org/</span>x<span class="regexp">/tools/g</span>o/packages (<span class="keyword">from</span> $GOPATH)</span><br></pre></td></tr></table></figure>

<p>其中<code>/home/xyz</code>是我的HOME目录，出现这个错误就是因为<code>&quot;golang.org/x/tools/go/packages&quot;</code>包没有安装，而由于<code>golang.org</code>被墙了，<code>go get</code>安装会失败，不过好在可以从<a target="_blank" rel="noopener" href="https://github.com/golang">golang的github镜像站</a>去找到对应的项目，然后下载安装，以此为例：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd <span class="variable">$GOPATH</span></span><br><span class="line">mkdir -p src<span class="regexp">/golang.org/</span>x</span><br><span class="line">cd src<span class="regexp">/golang.org/</span>x</span><br><span class="line">git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/golang/</span>tools.git</span><br></pre></td></tr></table></figure>

<p>然后再重新在<code>errcheck</code>目录下<code>go install</code>即可。</p>
<h3 id="3-3-特别操作"><a href="#3-3-特别操作" class="headerlink" title="3.3 特别操作"></a>3.3 特别操作</h3><ol>
<li><code>stamblerre/gocode</code>，由于生成的是<code>gocode-gomod</code>而非默认的<code>gocode</code>，因此需要指定二进制名称（似乎<code>go install</code>无法做到）：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">go build -o gocode-gomod</span><br><span class="line"><span class="built_in">mv</span> gocode-gomod <span class="variable">$GOPATH</span>/bin</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><code>honnef.co/go/tools/cmd/keyify</code>，在github上有<a target="_blank" rel="noopener" href="https://github.com/dominikh/go-tools">镜像</a>：</li>
</ol>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> $GOPATH/src</span><br><span class="line"><span class="built_in">mkdir</span> -<span class="keyword">p</span> honnef.<span class="keyword">co</span>/<span class="keyword">go</span></span><br><span class="line">git clone https://github.<span class="keyword">com</span>/dominikh/<span class="keyword">go</span>-tools.git honnef.<span class="keyword">co</span>/<span class="keyword">go</span>/tools</span><br><span class="line"><span class="keyword">cd</span> honnef.<span class="keyword">co</span>/<span class="keyword">go</span>/tools/cmd/keyify</span><br><span class="line"><span class="keyword">go</span> install</span><br></pre></td></tr></table></figure>

<h3 id="3-4-最终安装结果"><a href="#3-4-最终安装结果" class="headerlink" title="3.4 最终安装结果"></a>3.4 最终安装结果</h3><p>安装的二进制文件如下：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$</span> <span class="built_in">ls</span> <span class="variable">$GOBIN</span></span><br><span class="line">asmfmt    fillstruct    godef      golangci<span class="literal">-lint</span>  gomodifytags  gotags  impl</span><br><span class="line">dlv       gocode        gogetdoc   golint         gopls         guru    keyify</span><br><span class="line">errcheck  gocode<span class="literal">-gomod</span>  goimports  gometalinter   gorename      iferr   motion</span><br></pre></td></tr></table></figure>

<p>从golang的github镜像上分别克隆了3个项目：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">ls</span> <span class="variable">$GOPATH</span>/src/golang.org/x</span><br><span class="line">lint  <span class="built_in">sync</span>  tools</span><br></pre></td></tr></table></figure>

<h3 id="3-5-其他说明"><a href="#3-5-其他说明" class="headerlink" title="3.5 其他说明"></a>3.5 其他说明</h3><p>vim-go的具体使用方式，参考<a target="_blank" rel="noopener" href="https://github.com/fatih/vim-go/wiki/Tutorial">vim-go Tutorial</a>。</p>
<p>打开go文件时会出现下列错误</p>
<figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">vim</span><span class="literal">-</span><span class="comment">go: Features that rely on gopls will not work correctly in a null</span> <span class="comment">module</span><span class="string">.</span></span><br></pre></td></tr></table></figure>

<p>解决方法参考<a target="_blank" rel="noopener" href="https://github.com/fatih/vim-go/issues/2301">#2301</a>，在<code>.vimrc</code>中添加下列代码即可：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> g:<span class="attr">go_null_module_warning</span> = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>此外<code>GoRename</code>命令只有在项目目录在<code>$GOPATH/src</code>下时才能使用，否则会出现<code>can&#39;t find package containing</code>错误。</p>
<h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><p>由于是在之前的基础上进行，所以Go开发环境的搭建较为简单，安装Go、重新编译YCM，Ultisnip已经有了，剩下的就是vim-go的安装了。其实最重要的还是YCM的补全功能。</p>
<p>虽然我vim-go用得也不多，主要就是用了下将gofmt集成进vim的<code>:GoFmt</code>命令，毕竟上手Go的时间也不长。话说才发现现在保存文件时就会自动格式化了，无需手动输入<code>:GoFmt</code>命令。</p>
<p>安装vim-go的主要难点在于各种远程包，在我的电脑上几乎是全程开代理下载，有时候git代理不太好使就直接在VPS上克隆完毕后，打包、FTP下载、FTP上传、解压。</p>
<p>之前实习时安装vim-go去解决各种<code>go get</code>的问题了，<code>go get</code>虽然方便，但是出错的话难以及时发现错误在哪，感觉在国内这个网络环境下，还不如手动克隆、安装。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/06/21/%E6%88%91%E7%9A%84vim%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-3-Go%E5%BC%80%E5%8F%91%E9%85%8D%E7%BD%AE/" data-id="cl1qn407i001p4c1u9xuy7sp8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/golang/" rel="tag">golang</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vim/" rel="tag">vim</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%90%AD%E7%8E%AF%E5%A2%83/" rel="tag">搭环境</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/2/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/4/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Go/" rel="tag">Go</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pulsar/" rel="tag">Pulsar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scala/" rel="tag">Scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/" rel="tag">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/golang/" rel="tag">golang</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/thread/" rel="tag">thread</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/" rel="tag">vim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%90%AD%E7%8E%AF%E5%A2%83/" rel="tag">搭环境</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" rel="tag">网络编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E6%8E%A5/" rel="tag">链接</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/C/" style="font-size: 20px;">C++</a> <a href="/tags/Go/" style="font-size: 10px;">Go</a> <a href="/tags/Java/" style="font-size: 16.67px;">Java</a> <a href="/tags/Kafka/" style="font-size: 18.33px;">Kafka</a> <a href="/tags/Pulsar/" style="font-size: 13.33px;">Pulsar</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Scala/" style="font-size: 10px;">Scala</a> <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/golang/" style="font-size: 10px;">golang</a> <a href="/tags/thread/" style="font-size: 10px;">thread</a> <a href="/tags/vim/" style="font-size: 15px;">vim</a> <a href="/tags/%E6%90%AD%E7%8E%AF%E5%A2%83/" style="font-size: 16.67px;">搭环境</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" style="font-size: 10px;">网络编程</a> <a href="/tags/%E9%93%BE%E6%8E%A5/" style="font-size: 11.67px;">链接</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/05/14/Pulsar-AVRO-schema-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E5%88%9D%E8%AF%86/">Pulsar AVRO schema 源码阅读：初识</a>
          </li>
        
          <li>
            <a href="/2022/04/08/Python-lambda-%E5%AE%9E%E7%8E%B0%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/">Python lambda 实现回调函数</a>
          </li>
        
          <li>
            <a href="/2022/02/27/Java-Stream-%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/">Java Stream 简单学习</a>
          </li>
        
          <li>
            <a href="/2022/02/06/Java-Executor-%E5%AD%A6%E4%B9%A0/">Java Executor 学习</a>
          </li>
        
          <li>
            <a href="/2021/10/03/%E9%87%8D%E6%96%B0%E5%AD%A6%E4%B9%A0-Golang/">重新学习 Golang</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 XYZ, aka BewareMyPower<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>